{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accumulated Sum by Category\n",
    "This notebook is a throw back in all my previous baselines. The main objective here is to be 100% sure that I'm not leaking in any part of my pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0v.zip\r\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import read_data, process_time, merge_data, promo_detector, promo_detector_fixed, promotionAggregation, dataset_builder\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "import sys\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from datetime import datetime\n",
    "\n",
    "NUMBER_OF_LAGS = 4\n",
    "\n",
    "sys.path.append(\"../../main/datasets/\")\n",
    "!ls  ../../main/datasets/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline_score function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_score(prediction, target, simulatedPrice):\n",
    "    prediction = prediction.astype(int)\n",
    "\n",
    "    return np.sum((prediction - np.maximum(prediction - target, 0) * 1.6)  * simulatedPrice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feval(prediction, dtrain):\n",
    "    \n",
    "    prediction = prediction.astype(int)\n",
    "    target = dtrain.get_label()\n",
    "\n",
    "    simulatedPrice = dtrain.get_weight()\n",
    "    \n",
    "    return 'feval', np.sum((prediction - np.maximum(prediction - target, 0) * 1.6)  * simulatedPrice), True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(predt, dtrain):\n",
    "    y = dtrain.get_label()\n",
    "    sp = dtrain.get_weight()\n",
    "    return -2 * (predt - np.maximum(predt - y, 0) * 1.6) * (1 - (predt > y) * 1.6) * sp\n",
    "\n",
    "def hessian(predt, dtrain):\n",
    "    y = dtrain.get_label()\n",
    "    sp = dtrain.get_weight() \n",
    "    return -2 * ((1 - (predt > y) * 1.6) ** 2) * sp\n",
    "\n",
    "def objective(predt, dtrain):\n",
    "    grad = gradient(predt, dtrain)\n",
    "    hess = hessian(predt, dtrain)\n",
    "    return grad, hess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building our dataset\n",
    "This notebook makes this step cleaner than the previous versions. So It'll be tidier and shorter than before!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity checks... (10463, 3) (10463, 8) (2181955, 5)\n"
     ]
    }
   ],
   "source": [
    "infos, items, orders = read_data(\"../../main/datasets/\")\n",
    "print(\"Sanity checks...\", infos.shape, items.shape, orders.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing our time signatures\n",
    "process_time(orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset_builder(orders, items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main objective here is to create a feature that represents the cummulative sales mean grouped by category (I'll call it cummulative sale). Apparently, Category 3 is the most important on model evaluation, so this feature tries to indicate to our model how important a certain item is inside Its group in Category 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumulative_sale_by_category(df):\n",
    "    \"\"\"\n",
    "    This function add the percentage_acum_cat_3 in our dataset, which tries to describe how \n",
    "    important a certain item is inside Its group on category 3.\n",
    "\n",
    "    Parameters: orders -> Orders DataFrame after \"process_time\" and \"dataset_builder\"\n",
    "\n",
    "    Returns: our orders Dataframe with a new column (percentage_acum_cat_3)\n",
    "    \"\"\"\n",
    "    acum = pd.DataFrame()\n",
    "    for i in range(12, 0, -1):\n",
    "\n",
    "        orders_per_item = df.loc[df.group_backwards > i].groupby(\n",
    "            ['itemID', 'category3'], as_index=False).agg({'orderSum': 'sum'})\n",
    "        orders_per_cat = df.loc[df.group_backwards > i].groupby(\n",
    "            ['category3'], as_index=False).agg({'orderSum': 'sum'})\n",
    "\n",
    "        # Mergin' the amount of sales by category\n",
    "        # with the accumulated sales\n",
    "        # of an item grouped by category\n",
    "        # of the previous weeks\n",
    "        cum_sum_mean = pd.merge(orders_per_item, orders_per_cat,\n",
    "                                left_on='category3', right_on='category3', validate=\"m:1\")\n",
    "\n",
    "        # Calculating the mean of the accumulated sales...\n",
    "        cum_sum_mean['percentage_accum_cat_3'] = cum_sum_mean['orderSum_x'] / \\\n",
    "            cum_sum_mean['orderSum_y'] * 100\n",
    "\n",
    "        # These columns won't be useful anymore,\n",
    "        # since they were used just to calculate our mean\n",
    "        cum_sum_mean.drop(columns=['orderSum_x', 'orderSum_y'], inplace=True)\n",
    "\n",
    "        feature_merge = pd.merge(df.loc[df.group_backwards == i], cum_sum_mean.drop(\n",
    "            columns=['category3']), left_on='itemID', right_on='itemID')\n",
    "        acum = pd.concat([acum, feature_merge])\n",
    "\n",
    "    week_13 = df.loc[df.group_backwards == 13].copy()\n",
    "    week_13['percentage_accum_cat_3'] = 0\n",
    "    acum = pd.concat([week_13, acum])\n",
    "\n",
    "    assert (acum.loc[acum.group_backwards == 13]['percentage_accum_cat_3'].sum(\n",
    "    ) == 0), (\"The values on week 13 should all be zero. Verify your inputs\")\n",
    "    \n",
    "    acum.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return acum"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "language": "python",
   "name": "python38164bitb3ebfd1fa0594a1c9d5c617333c2c1a4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
