{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM Without Promotion\n",
    "This notebook is an experiment about training a LGBM model without the promotion related features..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0v.zip\r\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import read_data, process_time, merge_data, promo_detector, promo_detector_fixed, promotionAggregation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "import sys\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from datetime import datetime\n",
    "\n",
    "NUMBER_OF_LAGS = 4\n",
    "\n",
    "sys.path.append(\"../../main/datasets/\")\n",
    "!ls  ../../main/datasets/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline_score function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_score(prediction, target, simulatedPrice):\n",
    "    prediction = prediction.astype(int)\n",
    "\n",
    "    return np.sum((prediction - np.maximum(prediction - target, 0) * 1.6)  * simulatedPrice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feval(prediction, dtrain):\n",
    "    \n",
    "    prediction = prediction.astype(int)\n",
    "    target = dtrain.get_label()\n",
    "\n",
    "    simulatedPrice = dtrain.get_weight()\n",
    "    \n",
    "    return 'feval', np.sum((prediction - np.maximum(prediction - target, 0) * 1.6)  * simulatedPrice), True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(predt, dtrain):\n",
    "    y = dtrain.get_label()\n",
    "    sp = dtrain.get_weight()\n",
    "    return -2 * (predt - np.maximum(predt - y, 0) * 1.6) * (1 - (predt > y) * 1.6) * sp\n",
    "\n",
    "def hessian(predt, dtrain):\n",
    "    y = dtrain.get_label()\n",
    "    sp = dtrain.get_weight() \n",
    "    return -2 * ((1 - (predt > y) * 1.6) ** 2) * sp\n",
    "\n",
    "def objective(predt, dtrain):\n",
    "    grad = gradient(predt, dtrain)\n",
    "    hess = hessian(predt, dtrain)\n",
    "    return grad, hess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing our dataset\n",
    "These steps were already seen on ```../pre-processing-features``` notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity checks... (10463, 3) (10463, 8) (2181955, 5)\n"
     ]
    }
   ],
   "source": [
    "infos, items, orders = read_data(\"../../main/datasets/\")\n",
    "print(\"Sanity checks...\", infos.shape, items.shape, orders.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:red'>We'll use the ```promo_detector_fixed``` instead of ```promo_detector``` function</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing our time signatures, \n",
    "# adding our promotion feature \n",
    "# and aggregating our data by weeks...\n",
    "process_time(orders)\n",
    "orders = promo_detector_fixed(orders)\n",
    "df = promotionAggregation(orders,\n",
    "                          items,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_backwards</th>\n",
       "      <th>itemID</th>\n",
       "      <th>orderSum</th>\n",
       "      <th>promotion_mean</th>\n",
       "      <th>salesPrice_mean</th>\n",
       "      <th>brand</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>customerRating</th>\n",
       "      <th>category1</th>\n",
       "      <th>category2</th>\n",
       "      <th>category3</th>\n",
       "      <th>recommendedRetailPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.430000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>140</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.040000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>15.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.100000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.44</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>40.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.480000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.390000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25429</th>\n",
       "      <td>13</td>\n",
       "      <td>9887</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1397.550000</td>\n",
       "      <td>178</td>\n",
       "      <td>225</td>\n",
       "      <td>4.50</td>\n",
       "      <td>8</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>1155.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25430</th>\n",
       "      <td>13</td>\n",
       "      <td>9938</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1451.670000</td>\n",
       "      <td>178</td>\n",
       "      <td>225</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>671.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25431</th>\n",
       "      <td>13</td>\n",
       "      <td>9986</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>187</td>\n",
       "      <td>234</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>45.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25432</th>\n",
       "      <td>13</td>\n",
       "      <td>9999</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.890000</td>\n",
       "      <td>182</td>\n",
       "      <td>227</td>\n",
       "      <td>5.00</td>\n",
       "      <td>8</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>38.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25433</th>\n",
       "      <td>13</td>\n",
       "      <td>10000</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.549433</td>\n",
       "      <td>182</td>\n",
       "      <td>227</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8</td>\n",
       "      <td>47</td>\n",
       "      <td>8</td>\n",
       "      <td>36.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25434 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       group_backwards  itemID  orderSum  promotion_mean  salesPrice_mean  \\\n",
       "0                    1       1         3             0.0         3.430000   \n",
       "1                    1       3       140             0.0        14.040000   \n",
       "2                    1       4       145             0.0        14.100000   \n",
       "3                    1       5         1             1.0         7.480000   \n",
       "4                    1       7         1             0.0        34.390000   \n",
       "...                ...     ...       ...             ...              ...   \n",
       "25429               13    9887        12             0.0      1397.550000   \n",
       "25430               13    9938        20             0.0      1451.670000   \n",
       "25431               13    9986         2             0.0        12.020000   \n",
       "25432               13    9999         7             0.0        59.890000   \n",
       "25433               13   10000       200             0.0        28.549433   \n",
       "\n",
       "       brand  manufacturer  customerRating  category1  category2  category3  \\\n",
       "0          0             1            4.38          1          1          1   \n",
       "1          0             3            5.00          1          3          1   \n",
       "2          0             2            4.44          1          2          1   \n",
       "3          0             2            2.33          1          1          1   \n",
       "4          0             3            4.00          1          3          1   \n",
       "...      ...           ...             ...        ...        ...        ...   \n",
       "25429    178           225            4.50          8         44          8   \n",
       "25430    178           225            0.00          8         44          8   \n",
       "25431    187           234            0.00          8         44          8   \n",
       "25432    182           227            5.00          8         44          8   \n",
       "25433    182           227            0.00          8         47          8   \n",
       "\n",
       "       recommendedRetailPrice  \n",
       "0                        8.84  \n",
       "1                       15.89  \n",
       "2                       40.17  \n",
       "3                       17.04  \n",
       "4                       26.40  \n",
       "...                       ...  \n",
       "25429                 1155.00  \n",
       "25430                  671.79  \n",
       "25431                   45.54  \n",
       "25432                   38.57  \n",
       "25433                   36.87  \n",
       "\n",
       "[25434 rows x 12 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['promotion_mean'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareOrders(orders, items):\n",
    "    \"\"\"This function is responsible for adding in our 'orders' dataframe\n",
    "    the items that were not sold. THIS IS NOT MODULARIZED, THUS YOU\n",
    "    SHOULD CHANGE THE CODE TO BETTER SUIT YOUR DATASET FEATURES\n",
    "    \"\"\"\n",
    "    \n",
    "    df = orders.copy()\n",
    "    \n",
    "    # Getting the IDs that were never sold\n",
    "    not_sold_items = items[np.logical_not(\n",
    "        items.itemID.isin(sorted(orders['itemID'].unique())))]\n",
    "\n",
    "    new_rows = []\n",
    "    weeks_database = orders['group_backwards'].unique()\n",
    "\n",
    "    for idd in df['itemID'].unique():\n",
    "        orders_id = df[df.itemID == idd]\n",
    "        example = orders_id.iloc[0]\n",
    "\n",
    "        # finding weeks without itemID sales\n",
    "        weeks_id = orders_id['group_backwards'].unique()\n",
    "        weeks_without_id = np.setdiff1d(weeks_database, weeks_id)\n",
    "\n",
    "        # creating new row\n",
    "        for w in weeks_without_id:\n",
    "            new_rows.append({'itemID': idd,\n",
    "                             'group_backwards': w,\n",
    "                             'salesPrice_mean': 0,\n",
    "                             'customerRating': example['customerRating'],\n",
    "                             'category1': example['category1'],\n",
    "                             'category2': example['category2'],\n",
    "                             'category3': example['category3'],\n",
    "                             'recommendedRetailPrice': example['recommendedRetailPrice'],\n",
    "                             'orderSum': 0,\n",
    "                             'manufacturer': example['manufacturer'],\n",
    "                             'brand': example['brand'],\n",
    "                             })\n",
    "    #  Adding rows in every week with the IDs of the\n",
    "    # items that were never sold.\n",
    "    df = df.append(new_rows)\n",
    "    not_sold_orders = pd.DataFrame()\n",
    "    for i in range(1, 14):\n",
    "        aux = not_sold_items.copy()\n",
    "        aux['group_backwards'] = i\n",
    "        aux['orderSum'] = 0\n",
    "        not_sold_orders = pd.concat([not_sold_orders, aux], axis=0)\n",
    "    df = pd.concat([df, not_sold_orders], axis=0).sort_values(\n",
    "        ['group_backwards', 'itemID'], ascending=[False, True], ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepareOrders(df, items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell lags and diffs our feature 'orderSum'\n",
    "\n",
    "shifting = df.copy()\n",
    "\n",
    "for i in range(1, NUMBER_OF_LAGS + 1):\n",
    "    # Carrying the data of weeks t-1\n",
    "    shifting[f'orderSum_{i}'] = shifting.groupby('itemID')['orderSum'].shift(i)\n",
    "    \n",
    "    # Getting the difference of the orders and promotions between weeks t-1 and t-2...\n",
    "    shifting[f'orderSum_diff_{i}'] = shifting.groupby('itemID')[f'orderSum_{i}'].diff()\n",
    "    \n",
    "shifting.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum error\n",
    "The maximum error we could get in this dataset would be just guessing the mean of our sales from weeks 1 to 12, and that's what the cell below is computing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guessing the mean of 'orderSum' for all items in target 89.43043385194576\n"
     ]
    }
   ],
   "source": [
    "worst_possible_prediction = shifting.loc[shifting.group_backwards < 13]['orderSum'].mean()\n",
    "prediction = np.full(shifting.loc[shifting.group_backwards == 13]['orderSum'].shape, worst_possible_prediction) # Array filled with the mean...\n",
    "target = shifting.loc[shifting.group_backwards == 13]['orderSum']\n",
    "print(\"Guessing the mean of 'orderSum' for all items in target\", mse(target, prediction) ** 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Splitting\n",
    "All my experiments will use weeks 13 to 3 as a train set, week 2 as our validation set and week 1 as a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = shifting.loc[shifting.group_backwards >= 3]\n",
    "val = shifting.loc[shifting.group_backwards == 2]\n",
    "test = shifting.loc[shifting.group_backwards == 1]\n",
    "\n",
    "weights = infos.set_index('itemID')['simulationPrice'].to_dict()\n",
    "\n",
    "w_train = train['itemID'].map(weights)\n",
    "w_val = val['itemID'].map(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I recommend to the other members of the team keeping the\n",
    "# datatypes of our datasets as Pandas DataFrames instead of Numpy,\n",
    "# since It will easier to use Boosting Analysis frameworks\n",
    "y_train = train['orderSum']\n",
    "y_val = val['orderSum']\n",
    "X_train = train.drop(columns=[\"orderSum\"])\n",
    "X_val = val.drop(columns=[\"orderSum\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joaopedromattos/.local/lib/python3.8/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[20]\ttraining's rmse: 29.5565\ttraining's feval: 3.74619e+06\tvalid_1's rmse: 35.0916\tvalid_1's feval: 487612\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's rmse: 29.5597\ttraining's feval: 3.75251e+06\tvalid_1's rmse: 35.0945\tvalid_1's feval: 492433\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "#           \"objective\" : \"poisson\",\n",
    "          \"objective\" : \"l1\",\n",
    "          \"metric\" :\"rmse\",\n",
    "          \"learning_rate\" : 0.1,\n",
    "          'verbosity': 1,\n",
    "          'max_depth': 6,\n",
    "          'num_leaves': 15,\n",
    "          \"min_data_in_leaf\":2000\n",
    "         }\n",
    "\n",
    "lgbtrain = lgb.Dataset(X_train, label = y_train, weight=w_train, categorical_feature=[8, 9, 10])\n",
    "lgbvalid = lgb.Dataset(X_val, label = y_val, weight=w_val, categorical_feature=[8, 9, 10])\n",
    "\n",
    "num_round = 1000\n",
    "model = lgb.train(params,\n",
    "                  lgbtrain,\n",
    "                  num_round,\n",
    "                  valid_sets = [lgbtrain, lgbvalid], \n",
    "                  verbose_eval=20,\n",
    "                  early_stopping_rounds=20,\n",
    "#                   fobj=objective,\n",
    "                  feval=feval\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predicting at test time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test['orderSum']\n",
    "X_test = test.drop(columns=[\"orderSum\"])\n",
    "final_predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions[final_predictions < 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baseline calculation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_score(final_predictions, y_test.values, infos['simulationPrice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating our Kaggle CSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.Series(0, index=np.arange(1, len(items)+1))\n",
    "final[items.itemID] = final_predictions.astype(int)\n",
    "\n",
    "final.to_csv(\"lgbm_kaggle_df.csv\", header=[\"demandPrediction\"],\n",
    "            index_label=\"itemID\", sep=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saving our model in disk**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now().strftime(\"%d-%m-%Y-%Hh%Mm%Ss\")\n",
    "modelName = 'lgbm-' + now\n",
    "xgb.save_model(modelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "language": "python",
   "name": "python38164bitb3ebfd1fa0594a1c9d5c617333c2c1a4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
