{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost Baseline\n",
    "This notebook is being created after the addition of Promotion feature to the dataset and the main goal is to submit the predictions of this notebook in our private Kaggle Leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0v.zip\r\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import read_data, process_time, merge_data, promo_detector, promotionAggregation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "import sys\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from datetime import datetime\n",
    "from catboost import CatBoostRegressor, Pool, cv\n",
    "\n",
    "NUMBER_OF_LAGS = 4\n",
    "\n",
    "sys.path.append(\"../../main/datasets/\")\n",
    "!ls  ../../main/datasets/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing our dataset\n",
    "These steps were already seen on ```../pre-processing-features``` notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity checks... (10463, 3) (10463, 8) (2181955, 5)\n"
     ]
    }
   ],
   "source": [
    "infos, items, orders = read_data(\"../../main/datasets/\")\n",
    "print(\"Sanity checks...\", infos.shape, items.shape, orders.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing our time signatures, \n",
    "# adding our promotion feature \n",
    "# and aggregating our data by weeks...\n",
    "process_time(orders)\n",
    "orders = promo_detector(orders)\n",
    "df = promotionAggregation(orders, items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareOrders(orders, items):\n",
    "    \"\"\"This function is responsible for adding in our 'orders' dataframe\n",
    "    the items that were not sold. THIS IS NOT MODULARIZED, THUS YOU\n",
    "    SHOULD CHANGE THE CODE TO BETTER SUIT YOUR DATASET FEATURES\n",
    "    \"\"\"\n",
    "    \n",
    "    df = orders.copy()\n",
    "    \n",
    "    # Getting the IDs that were never sold\n",
    "    not_sold_items = items[np.logical_not(\n",
    "        items.itemID.isin(sorted(orders['itemID'].unique())))]\n",
    "\n",
    "    new_rows = []\n",
    "    weeks_database = orders['group_backwards'].unique()\n",
    "\n",
    "    for idd in df['itemID'].unique():\n",
    "        orders_id = df[df.itemID == idd]\n",
    "        example = orders_id.iloc[0]\n",
    "\n",
    "        # finding weeks without itemID sales\n",
    "        weeks_id = orders_id['group_backwards'].unique()\n",
    "        weeks_without_id = np.setdiff1d(weeks_database, weeks_id)\n",
    "\n",
    "        # creating new row\n",
    "        for w in weeks_without_id:\n",
    "            new_rows.append({'itemID': idd,\n",
    "                             'group_backwards': w,\n",
    "                             'salesPrice_mean': 0,\n",
    "                             'customerRating': example['customerRating'],\n",
    "                             'category1': example['category1'],\n",
    "                             'category2': example['category2'],\n",
    "                             'category3': example['category3'],\n",
    "                             'recommendedRetailPrice': example['recommendedRetailPrice'],\n",
    "                             'orderSum': 0,\n",
    "                             'manufacturer': example['manufacturer'],\n",
    "                             'brand': example['brand'],\n",
    "                             'promotion_mean': 0\n",
    "                             })\n",
    "    #  Adding rows in every week with the IDs of the\n",
    "    # items that were never sold.\n",
    "    df = df.append(new_rows)\n",
    "    not_sold_orders = pd.DataFrame()\n",
    "    for i in range(1, 14):\n",
    "        aux = not_sold_items.copy()\n",
    "        aux['group_backwards'] = i\n",
    "        aux['salesPrice_mean'] = 0\n",
    "        aux['promotion_mean'] = 0\n",
    "        aux['orderSum'] = 0\n",
    "        not_sold_orders = pd.concat([not_sold_orders, aux], axis=0)\n",
    "    df = pd.concat([df, not_sold_orders], axis=0).sort_values(\n",
    "        ['group_backwards', 'itemID'], ascending=[False, True], ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepareOrders(df, items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_backwards</th>\n",
       "      <th>itemID</th>\n",
       "      <th>orderSum</th>\n",
       "      <th>promotion_mean</th>\n",
       "      <th>salesPrice_mean</th>\n",
       "      <th>brand</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>customerRating</th>\n",
       "      <th>category1</th>\n",
       "      <th>category2</th>\n",
       "      <th>...</th>\n",
       "      <th>orderSum_diff_2</th>\n",
       "      <th>promotion_mean_diff_2</th>\n",
       "      <th>orderSum_3</th>\n",
       "      <th>promotion_mean_3</th>\n",
       "      <th>orderSum_diff_3</th>\n",
       "      <th>promotion_mean_diff_3</th>\n",
       "      <th>orderSum_4</th>\n",
       "      <th>promotion_mean_4</th>\n",
       "      <th>orderSum_diff_4</th>\n",
       "      <th>promotion_mean_diff_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136014</th>\n",
       "      <td>1</td>\n",
       "      <td>10459</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>180.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136015</th>\n",
       "      <td>1</td>\n",
       "      <td>10460</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136016</th>\n",
       "      <td>1</td>\n",
       "      <td>10461</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136017</th>\n",
       "      <td>1</td>\n",
       "      <td>10462</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>180.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136018</th>\n",
       "      <td>1</td>\n",
       "      <td>10463</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136019 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        group_backwards  itemID  orderSum  promotion_mean  salesPrice_mean  \\\n",
       "0                    13       1         0             0.0             0.00   \n",
       "1                    13       2         0             0.0             0.00   \n",
       "2                    13       3         1             0.0            14.04   \n",
       "3                    13       4         0             0.0             0.00   \n",
       "4                    13       5         2             0.0             7.84   \n",
       "...                 ...     ...       ...             ...              ...   \n",
       "136014                1   10459         0             0.0             0.00   \n",
       "136015                1   10460         0             0.0             0.00   \n",
       "136016                1   10461         0             0.0             0.00   \n",
       "136017                1   10462         0             0.0             0.00   \n",
       "136018                1   10463         0             0.0             0.00   \n",
       "\n",
       "        brand  manufacturer  customerRating  category1  category2  ...  \\\n",
       "0         0.0           1.0            4.38        1.0        1.0  ...   \n",
       "1         0.0           2.0            3.00        1.0        2.0  ...   \n",
       "2         0.0           3.0            5.00        1.0        3.0  ...   \n",
       "3         0.0           2.0            4.44        1.0        2.0  ...   \n",
       "4         0.0           2.0            2.33        1.0        1.0  ...   \n",
       "...       ...           ...             ...        ...        ...  ...   \n",
       "136014  180.0         253.0            0.00        8.0       44.0  ...   \n",
       "136015    0.0         253.0            0.00        8.0       44.0  ...   \n",
       "136016    0.0         253.0            0.00        8.0       44.0  ...   \n",
       "136017  180.0         253.0            0.00        8.0       44.0  ...   \n",
       "136018    0.0         253.0            0.00        8.0       44.0  ...   \n",
       "\n",
       "        orderSum_diff_2  promotion_mean_diff_2  orderSum_3  promotion_mean_3  \\\n",
       "0                   inf                    inf         inf               inf   \n",
       "1                   inf                    inf         inf               inf   \n",
       "2                   inf                    inf         inf               inf   \n",
       "3                   inf                    inf         inf               inf   \n",
       "4                   inf                    inf         inf               inf   \n",
       "...                 ...                    ...         ...               ...   \n",
       "136014             -1.0                    0.0         1.0               0.0   \n",
       "136015              0.0                    0.0         0.0               0.0   \n",
       "136016              0.0                    0.0         0.0               0.0   \n",
       "136017              0.0                    0.0         0.0               0.0   \n",
       "136018              1.0                    0.0         0.0               0.0   \n",
       "\n",
       "        orderSum_diff_3  promotion_mean_diff_3  orderSum_4  promotion_mean_4  \\\n",
       "0                   inf                    inf         inf               inf   \n",
       "1                   inf                    inf         inf               inf   \n",
       "2                   inf                    inf         inf               inf   \n",
       "3                   inf                    inf         inf               inf   \n",
       "4                   inf                    inf         inf               inf   \n",
       "...                 ...                    ...         ...               ...   \n",
       "136014              1.0                    0.0         0.0               0.0   \n",
       "136015              0.0                    0.0         0.0               0.0   \n",
       "136016              0.0                    0.0         0.0               0.0   \n",
       "136017             -1.0                    0.0         1.0               0.0   \n",
       "136018              0.0                    0.0         0.0               0.0   \n",
       "\n",
       "        orderSum_diff_4  promotion_mean_diff_4  \n",
       "0                   inf                    inf  \n",
       "1                   inf                    inf  \n",
       "2                   inf                    inf  \n",
       "3                   inf                    inf  \n",
       "4                   inf                    inf  \n",
       "...                 ...                    ...  \n",
       "136014              0.0                    0.0  \n",
       "136015             -1.0                    0.0  \n",
       "136016              0.0                    0.0  \n",
       "136017              1.0                    0.0  \n",
       "136018              0.0                    0.0  \n",
       "\n",
       "[136019 rows x 28 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This cell lags and diffs our features 'orderSum' and \"promotion\"\n",
    "\n",
    "shifting = df.copy()\n",
    "\n",
    "for i in range(1, NUMBER_OF_LAGS + 1):\n",
    "    # Carrying the data of weeks t-1\n",
    "    shifting[f'orderSum_{i}'] = shifting.groupby('itemID')['orderSum'].shift(i)\n",
    "    shifting[f'promotion_mean_{i}'] = shifting.groupby('itemID')['promotion_mean'].shift(i)\n",
    "    \n",
    "    # Getting the difference of the orders and promotions between weeks t-1 and t-2...\n",
    "    shifting[f'orderSum_diff_{i}'] = shifting.groupby('itemID')[f'orderSum_{i}'].diff()\n",
    "    shifting[f'promotion_mean_diff_{i}'] = shifting.groupby('itemID')[f'promotion_mean_{i}'].diff()\n",
    "shifting.fillna(np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum error\n",
    "The maximum error we could get in this dataset would be just guessing the mean of our sales from weeks 1 to 12, and that's what the cell below is computing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guessing the mean of 'orderSum' for all items in target 90.29706562119341\n"
     ]
    }
   ],
   "source": [
    "worst_possible_prediction = shifting.loc[shifting.group_backwards < 13]['orderSum'].mean()\n",
    "prediction = np.full(shifting.loc[shifting.group_backwards == 13]['orderSum'].shape, worst_possible_prediction) # Array filled with the mean...\n",
    "target = shifting.loc[shifting.group_backwards == 13]['orderSum']\n",
    "print(\"Guessing the mean of 'orderSum' for all items in target\", mse(target, prediction) ** 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Splitting\n",
    "All my experiments will use weeks 13 to 3 as a train set, week 2 as our validation set and week 1 as a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBoost requires that all columns should\n",
    "stringColumns = shifting.columns[3:]\n",
    "shifting[stringColumns] = shifting[stringColumns].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datatype conversion required by Catboost\n",
    "train = shifting.loc[shifting.group_backwards >= 3]\n",
    "val = shifting.loc[shifting.group_backwards == 2]\n",
    "test = shifting.loc[shifting.group_backwards == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I recommend to the other members of the team keeping the\n",
    "# datatypes of our datasets as Pandas DataFrames instead of Numpy,\n",
    "# since It will easier to use Boosting Analysis frameworks\n",
    "y_train = train['orderSum']\n",
    "y_val = val['orderSum']\n",
    "X_train = train.drop(columns=[\"orderSum\"])\n",
    "X_val = val.drop(columns=[\"orderSum\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize Pool\n",
    "train_pool = Pool(X_train, \n",
    "                  y_train, \n",
    "                  cat_features=[8,9,10])\n",
    "\n",
    "val_pool = Pool(X_val, \n",
    "                  y_val, \n",
    "                  cat_features=[8,9,10])\n",
    "# test_pool = Pool(test_data.astype(str), \n",
    "#                  cat_features=[8,9,10]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 100.9859886\ttest: 105.3582307\tbest: 105.3582307 (0)\ttotal: 46.7ms\tremaining: 46.6s\n",
      "1:\tlearn: 99.1420325\ttest: 102.6691635\tbest: 102.6691635 (1)\ttotal: 86.9ms\tremaining: 43.3s\n",
      "2:\tlearn: 97.5669743\ttest: 99.9306748\tbest: 99.9306748 (2)\ttotal: 130ms\tremaining: 43.2s\n",
      "3:\tlearn: 96.3491044\ttest: 98.5927006\tbest: 98.5927006 (3)\ttotal: 197ms\tremaining: 49s\n",
      "4:\tlearn: 95.2561185\ttest: 97.0610058\tbest: 97.0610058 (4)\ttotal: 251ms\tremaining: 49.9s\n",
      "5:\tlearn: 94.1028422\ttest: 95.5897362\tbest: 95.5897362 (5)\ttotal: 327ms\tremaining: 54.1s\n",
      "6:\tlearn: 93.3648091\ttest: 94.6871991\tbest: 94.6871991 (6)\ttotal: 390ms\tremaining: 55.3s\n",
      "7:\tlearn: 92.7853061\ttest: 93.9635375\tbest: 93.9635375 (7)\ttotal: 453ms\tremaining: 56.2s\n",
      "8:\tlearn: 92.3344020\ttest: 93.4426866\tbest: 93.4426866 (8)\ttotal: 519ms\tremaining: 57.2s\n",
      "9:\tlearn: 91.7507069\ttest: 92.7709222\tbest: 92.7709222 (9)\ttotal: 564ms\tremaining: 55.8s\n",
      "10:\tlearn: 91.3326610\ttest: 92.4095219\tbest: 92.4095219 (10)\ttotal: 637ms\tremaining: 57.3s\n",
      "11:\tlearn: 90.9733936\ttest: 92.0490267\tbest: 92.0490267 (11)\ttotal: 706ms\tremaining: 58.2s\n",
      "12:\tlearn: 90.4409174\ttest: 91.6009462\tbest: 91.6009462 (12)\ttotal: 755ms\tremaining: 57.3s\n",
      "13:\tlearn: 90.0668437\ttest: 91.2901272\tbest: 91.2901272 (13)\ttotal: 819ms\tremaining: 57.7s\n",
      "14:\tlearn: 89.8423102\ttest: 91.2110295\tbest: 91.2110295 (14)\ttotal: 928ms\tremaining: 1m\n",
      "15:\tlearn: 89.5996848\ttest: 91.0384324\tbest: 91.0384324 (15)\ttotal: 1.03s\tremaining: 1m 3s\n",
      "16:\tlearn: 89.3418966\ttest: 90.8463709\tbest: 90.8463709 (16)\ttotal: 1.1s\tremaining: 1m 3s\n",
      "17:\tlearn: 88.8340795\ttest: 90.3246600\tbest: 90.3246600 (17)\ttotal: 1.18s\tremaining: 1m 4s\n",
      "18:\tlearn: 88.5653065\ttest: 90.1594018\tbest: 90.1594018 (18)\ttotal: 1.25s\tremaining: 1m 4s\n",
      "19:\tlearn: 88.4276161\ttest: 90.0510533\tbest: 90.0510533 (19)\ttotal: 1.32s\tremaining: 1m 4s\n",
      "20:\tlearn: 87.4957858\ttest: 89.9340873\tbest: 89.9340873 (20)\ttotal: 1.4s\tremaining: 1m 5s\n",
      "21:\tlearn: 86.7207983\ttest: 89.9380360\tbest: 89.9340873 (20)\ttotal: 1.47s\tremaining: 1m 5s\n",
      "22:\tlearn: 86.4394407\ttest: 89.6552798\tbest: 89.6552798 (22)\ttotal: 1.53s\tremaining: 1m 5s\n",
      "23:\tlearn: 86.2959484\ttest: 89.6685661\tbest: 89.6552798 (22)\ttotal: 1.6s\tremaining: 1m 5s\n",
      "24:\tlearn: 86.0074542\ttest: 89.3297054\tbest: 89.3297054 (24)\ttotal: 1.66s\tremaining: 1m 4s\n",
      "25:\tlearn: 85.8967140\ttest: 89.3490180\tbest: 89.3297054 (24)\ttotal: 1.71s\tremaining: 1m 3s\n",
      "26:\tlearn: 85.7388590\ttest: 89.2377004\tbest: 89.2377004 (26)\ttotal: 1.76s\tremaining: 1m 3s\n",
      "27:\tlearn: 85.6577692\ttest: 89.2682056\tbest: 89.2377004 (26)\ttotal: 1.81s\tremaining: 1m 2s\n",
      "28:\tlearn: 85.6084714\ttest: 89.2640750\tbest: 89.2377004 (26)\ttotal: 1.86s\tremaining: 1m 2s\n",
      "29:\tlearn: 85.4885354\ttest: 89.0920772\tbest: 89.0920772 (29)\ttotal: 1.91s\tremaining: 1m 1s\n",
      "30:\tlearn: 85.3130642\ttest: 88.7915343\tbest: 88.7915343 (30)\ttotal: 1.95s\tremaining: 1m 1s\n",
      "31:\tlearn: 85.1275993\ttest: 88.6136787\tbest: 88.6136787 (31)\ttotal: 2s\tremaining: 1m\n",
      "32:\tlearn: 84.9992764\ttest: 88.6351120\tbest: 88.6136787 (31)\ttotal: 2.04s\tremaining: 59.8s\n",
      "33:\tlearn: 84.6508773\ttest: 88.6772053\tbest: 88.6136787 (31)\ttotal: 2.08s\tremaining: 59s\n",
      "34:\tlearn: 84.1305422\ttest: 88.7813036\tbest: 88.6136787 (31)\ttotal: 2.17s\tremaining: 59.7s\n",
      "35:\tlearn: 84.0114310\ttest: 88.7393317\tbest: 88.6136787 (31)\ttotal: 2.23s\tremaining: 59.6s\n",
      "36:\tlearn: 83.9483899\ttest: 88.6728180\tbest: 88.6136787 (31)\ttotal: 2.29s\tremaining: 59.5s\n",
      "Stopped by overfitting detector  (5 iterations wait)\n",
      "\n",
      "bestTest = 88.61367869\n",
      "bestIteration = 31\n",
      "\n",
      "Shrink model to first 32 iterations.\n"
     ]
    }
   ],
   "source": [
    "# specify the training parameters \n",
    "model = CatBoostRegressor(depth=6, \n",
    "                          learning_rate=0.1, \n",
    "                          loss_function='RMSE',\n",
    "                          early_stopping_rounds=5)\n",
    "\n",
    "model.fit(\n",
    "    train_pool,\n",
    "    eval_set=val_pool,\n",
    "    logging_level='Verbose',  # you can uncomment this for text output\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predicting at test time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test['orderSum']\n",
    "X_test = test.drop(columns=[\"orderSum\"])\n",
    "final_predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating our Kaggle CSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.Series(0, index=np.arange(1, len(items)+1))\n",
    "final[items.itemID] = np.rint(final_predictions)\n",
    "\n",
    "final.to_csv(\"cat_kaggle_df.csv\", header=[\"demandPrediction\"],\n",
    "            index_label=\"itemID\", sep=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saving our model in disk**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now().strftime(\"%d-%m-%Y-%Hh%Mm%Ss\")\n",
    "modelName = 'cat-' + now\n",
    "bst.save_model(modelName)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
