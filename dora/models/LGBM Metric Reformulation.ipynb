{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM Custom Metrics\n",
    "This notebook is focused on training our models with the competition metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0v  1.0v.zip\r\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import read_data, process_time, merge_data, promo_detector, promotionAggregation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "import sys\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from datetime import datetime\n",
    "\n",
    "NUMBER_OF_LAGS = 4\n",
    "\n",
    "sys.path.append(\"../../main/datasets/\")\n",
    "!ls  ../../main/datasets/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feval(prediction, dtrain):\n",
    "    \n",
    "    prediction = prediction.astype(int)\n",
    "    target = dtrain.get_label()\n",
    "    simulatedPrice = dtrain.get_weight()\n",
    "#     print(\"Prediction\", prediction.shape)\n",
    "#     print(\"Difference\", target.shape)\n",
    "#     print(\"Maximum\", np.minimum( 1 / np.exp(prediction - target),  1))\n",
    "    return 'feval', -np.sum(prediction  * simulatedPrice * np.minimum( 1 / np.exp(prediction - target),  1)), True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(predt, dtrain):\n",
    "    y = dtrain.get_label()\n",
    "    sp = dtrain.get_weight()\n",
    "    print(\"Gradient\", -1 *sp * ((predt <= y) + (predt > y)* (1-predt)/(np.e**(predt - y))))\n",
    "    return -1 *sp * ((predt <= y) + (predt > y)* (1-predt)/(np.e**(predt - y)))\n",
    "\n",
    "def hessian(predt, dtrain):\n",
    "    y = dtrain.get_label()\n",
    "    sp = dtrain.get_weight() \n",
    "    print(\"Hessian\", -1 *sp * ((predt <= y)* 0 +(predt > y)* (2 - predt)* (-1)*(np.e**(sp - predt))))\n",
    "    return -1 *sp * ((predt <= y)* 0 +(predt > y)* (2 - predt)* (-1)*(np.e**(sp - predt)))\n",
    "\n",
    "def objective(predt, dtrain):\n",
    "    grad = gradient(predt, dtrain)\n",
    "    hess = hessian(predt, dtrain)\n",
    "    return grad, hess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing our dataset\n",
    "These steps were already seen on ```../pre-processing-features``` notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity checks... (10463, 3) (10463, 8) (2181955, 5)\n"
     ]
    }
   ],
   "source": [
    "infos, items, orders = read_data(\"../../main/datasets/\")\n",
    "print(\"Sanity checks...\", infos.shape, items.shape, orders.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing our time signatures, \n",
    "# adding our promotion feature \n",
    "# and aggregating our data by weeks...\n",
    "process_time(orders)\n",
    "orders = promo_detector(orders)\n",
    "df = promotionAggregation(orders, items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareOrders(orders, items):\n",
    "    \"\"\"This function is responsible for adding in our 'orders' dataframe\n",
    "    the items that were not sold. THIS IS NOT MODULARIZED, THUS YOU\n",
    "    SHOULD CHANGE THE CODE TO BETTER SUIT YOUR DATASET FEATURES\n",
    "    \"\"\"\n",
    "    \n",
    "    df = orders.copy()\n",
    "    \n",
    "    # Getting the IDs that were never sold\n",
    "    not_sold_items = items[np.logical_not(\n",
    "        items.itemID.isin(sorted(orders['itemID'].unique())))]\n",
    "\n",
    "    new_rows = []\n",
    "    weeks_database = orders['group_backwards'].unique()\n",
    "\n",
    "    for idd in df['itemID'].unique():\n",
    "        orders_id = df[df.itemID == idd]\n",
    "        example = orders_id.iloc[0]\n",
    "\n",
    "        # finding weeks without itemID sales\n",
    "        weeks_id = orders_id['group_backwards'].unique()\n",
    "        weeks_without_id = np.setdiff1d(weeks_database, weeks_id)\n",
    "\n",
    "        # creating new row\n",
    "        for w in weeks_without_id:\n",
    "            new_rows.append({'itemID': idd,\n",
    "                             'group_backwards': w,\n",
    "                             'salesPrice_mean': 0,\n",
    "                             'customerRating': example['customerRating'],\n",
    "                             'category1': example['category1'],\n",
    "                             'category2': example['category2'],\n",
    "                             'category3': example['category3'],\n",
    "                             'recommendedRetailPrice': example['recommendedRetailPrice'],\n",
    "                             'orderSum': 0,\n",
    "                             'manufacturer': example['manufacturer'],\n",
    "                             'brand': example['brand'],\n",
    "                             'promotion_mean': 0\n",
    "                             })\n",
    "    #  Adding rows in every week with the IDs of the\n",
    "    # items that were never sold.\n",
    "    df = df.append(new_rows)\n",
    "    not_sold_orders = pd.DataFrame()\n",
    "    for i in range(1, 14):\n",
    "        aux = not_sold_items.copy()\n",
    "        aux['group_backwards'] = i\n",
    "        aux['salesPrice_mean'] = 0\n",
    "        aux['promotion_mean'] = 0\n",
    "        aux['orderSum'] = 0\n",
    "        not_sold_orders = pd.concat([not_sold_orders, aux], axis=0)\n",
    "    df = pd.concat([df, not_sold_orders], axis=0).sort_values(\n",
    "        ['group_backwards', 'itemID'], ascending=[False, True], ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepareOrders(df, items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell lags and diffs our features 'orderSum' and \"promotion\"\n",
    "\n",
    "shifting = df.copy()\n",
    "\n",
    "for i in range(1, NUMBER_OF_LAGS + 1):\n",
    "    # Carrying the data of weeks t-1\n",
    "    shifting[f'orderSum_{i}'] = shifting.groupby('itemID')['orderSum'].shift(i)\n",
    "    shifting[f'promotion_mean_{i}'] = shifting.groupby('itemID')['promotion_mean'].shift(i)\n",
    "    \n",
    "    # Getting the difference of the orders and promotions between weeks t-1 and t-2...\n",
    "    shifting[f'orderSum_diff_{i}'] = shifting.groupby('itemID')[f'orderSum_{i}'].diff()\n",
    "    shifting[f'promotion_mean_diff_{i}'] = shifting.groupby('itemID')[f'promotion_mean_{i}'].diff()\n",
    "shifting.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum error\n",
    "The maximum error we could get in this dataset would be just guessing the mean of our sales from weeks 1 to 12, and that's what the cell below is computing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guessing the mean of 'orderSum' for all items in target 90.29706562119341\n"
     ]
    }
   ],
   "source": [
    "worst_possible_prediction = shifting.loc[shifting.group_backwards < 13]['orderSum'].mean()\n",
    "prediction = np.full(shifting.loc[shifting.group_backwards == 13]['orderSum'].shape, worst_possible_prediction) # Array filled with the mean...\n",
    "target = shifting.loc[shifting.group_backwards == 13]['orderSum']\n",
    "print(\"Guessing the mean of 'orderSum' for all items in target\", mse(target, prediction) ** 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Splitting\n",
    "All my experiments will use weeks 13 to 3 as a train set, week 2 as our validation set and week 1 as a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = shifting.loc[shifting.group_backwards >= 3]\n",
    "val = shifting.loc[shifting.group_backwards == 2]\n",
    "test = shifting.loc[shifting.group_backwards == 1]\n",
    "\n",
    "weights = infos.set_index('itemID')['simulationPrice'].to_dict()\n",
    "\n",
    "w_train = train['itemID'].map(weights)\n",
    "w_val = val['itemID'].map(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I recommend to the other members of the team keeping the\n",
    "# datatypes of our datasets as Pandas DataFrames instead of Numpy,\n",
    "# since It will easier to use Boosting Analysis frameworks\n",
    "y_train = train['orderSum']\n",
    "y_val = val['orderSum']\n",
    "X_train = train.drop(columns=[\"orderSum\"])\n",
    "X_val = val.drop(columns=[\"orderSum\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-86-8b682ce94b1e>:4: RuntimeWarning: invalid value encountered in true_divide\n",
      "  print(\"Gradient\", -1 *sp * ((predt <= y) + (predt > y)* (1-predt)/(np.e**(predt - y))))\n",
      "<ipython-input-86-8b682ce94b1e>:5: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return sp * ((predt <= y) + (predt > y)* (1-predt)/(np.e**(predt - y)))\n",
      "<ipython-input-86-8b682ce94b1e>:10: RuntimeWarning: overflow encountered in power\n",
      "  print(\"Hessian\", -1 *sp * ((predt <= y)* 0 +(predt > y)* (2 - predt)* (-1)*(np.e**(sp - predt))))\n",
      "<ipython-input-86-8b682ce94b1e>:10: RuntimeWarning: invalid value encountered in multiply\n",
      "  print(\"Hessian\", -1 *sp * ((predt <= y)* 0 +(predt > y)* (2 - predt)* (-1)*(np.e**(sp - predt))))\n",
      "<ipython-input-86-8b682ce94b1e>:11: RuntimeWarning: overflow encountered in power\n",
      "  return sp * ((predt <= y)* 0 +(predt > y)* (2 - predt)* (-1)*(np.e**(sp - predt)))\n",
      "<ipython-input-86-8b682ce94b1e>:11: RuntimeWarning: invalid value encountered in multiply\n",
      "  return sp * ((predt <= y)* 0 +(predt > y)* (2 - predt)* (-1)*(np.e**(sp - predt)))\n",
      "<ipython-input-87-68a2934fdd43>:9: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return 'feval', -np.sum(prediction  * simulatedPrice * np.minimum( 1 / np.exp(prediction - target),  1)), True\n",
      "<ipython-input-87-68a2934fdd43>:9: RuntimeWarning: overflow encountered in true_divide\n",
      "  return 'feval', -np.sum(prediction  * simulatedPrice * np.minimum( 1 / np.exp(prediction - target),  1)), True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient [  -3.43000007   -9.14999962  -14.03999996 ... -190.52999878 -304.29998779\n",
      " -282.16000366]\n",
      "Hessian [-0. -0. -0. ... -0. -0. -0.]\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Gradient [  -3.43000007   -9.14999962  -14.03999996 ... -190.52999878 -304.29998779\n",
      " -282.16000366]\n",
      "Hessian [-0. -0. -0. ... -0. -0. -0.]\n",
      "Gradient [  -3.43000007   -9.14999962  -14.03999996 ... -190.52999878 -304.29998779\n",
      " -282.16000366]\n",
      "Hessian [-0. -0. -0. ... -0. -0. -0.]\n",
      "Gradient [  -3.43000007   -9.14999962  -14.03999996 ... -190.52999878 -304.29998779\n",
      " -282.16000366]\n",
      "Hessian [-0. -0. -0. ... -0. -0. -0.]\n",
      "Gradient [  -3.43000007   -9.14999962  -14.03999996 ... -190.52999878 -304.29998779\n",
      " -282.16000366]\n",
      "Hessian [-0. -0. -0. ... -0. -0. -0.]\n",
      "Gradient [  -3.43000007   -9.14999962  -14.03999996 ... -190.52999878 -304.29998779\n",
      " -282.16000366]\n",
      "Hessian [-0. -0. -0. ... -0. -0. -0.]\n",
      "Gradient [  -3.43000007   -9.14999962  -14.03999996 ... -190.52999878 -304.29998779\n",
      " -282.16000366]\n",
      "Hessian [-0. -0. -0. ... -0. -0. -0.]\n",
      "Gradient [  -3.43000007   -9.14999962  -14.03999996 ... -190.52999878 -304.29998779\n",
      " -282.16000366]\n",
      "Hessian [-0. -0. -0. ... -0. -0. -0.]\n",
      "Gradient [  -3.43000007   -9.14999962  -14.03999996 ... -190.52999878 -304.29998779\n",
      " -282.16000366]\n",
      "Hessian [-0. -0. -0. ... -0. -0. -0.]\n",
      "Gradient [  -3.43000007   -9.14999962  -14.03999996 ... -190.52999878 -304.29998779\n",
      " -282.16000366]\n",
      "Hessian [-0. -0. -0. ... -0. -0. -0.]\n",
      "Gradient [  -3.43000007   -9.14999962  -14.03999996 ... -190.52999878 -304.29998779\n",
      " -282.16000366]\n",
      "Hessian [-0. -0. -0. ... -0. -0. -0.]\n",
      "Gradient [  -3.43000007   -9.14999962  -14.03999996 ... -190.52999878 -304.29998779\n",
      " -282.16000366]\n",
      "Hessian [-0. -0. -0. ... -0. -0. -0.]\n",
      "Gradient [  -3.43000007   -9.14999962  -14.03999996 ... -190.52999878 -304.29998779\n",
      " -282.16000366]\n",
      "Hessian [-0. -0. -0. ... -0. -0. -0.]\n",
      "Gradient [  -3.43000007   -9.14999962  -14.03999996 ... -190.52999878 -304.29998779\n",
      " -282.16000366]\n",
      "Hessian [-0. -0. -0. ... -0. -0. -0.]\n",
      "Gradient [  -3.43000007   -9.14999962  -14.03999996 ... -190.52999878 -304.29998779\n",
      " -282.16000366]\n",
      "Hessian [-0. -0. -0. ... -0. -0. -0.]\n",
      "Gradient [  -3.43000007   -9.14999962  -14.03999996 ... -190.52999878 -304.29998779\n",
      " -282.16000366]\n",
      "Hessian [-0. -0. -0. ... -0. -0. -0.]\n",
      "Gradient [  -3.43000007   -9.14999962  -14.03999996 ... -190.52999878 -304.29998779\n",
      " -282.16000366]\n",
      "Hessian [-0. -0. -0. ... -0. -0. -0.]\n",
      "Gradient [  -3.43000007   -9.14999962  -14.03999996 ... -190.52999878 -304.29998779\n",
      " -282.16000366]\n",
      "Hessian [-0. -0. -0. ... -0. -0. -0.]\n",
      "Gradient [  -3.43000007   -9.14999962  -14.03999996 ... -190.52999878 -304.29998779\n",
      " -282.16000366]\n",
      "Hessian [-0. -0. -0. ... -0. -0. -0.]\n",
      "Gradient [  -3.43000007   -9.14999962  -14.03999996 ... -190.52999878 -304.29998779\n",
      " -282.16000366]\n",
      "Hessian [-0. -0. -0. ... -0. -0. -0.]\n",
      "[20]\ttraining's feval: -0\tvalid_1's feval: -0\n",
      "Gradient [  -3.43000007   -9.14999962  -14.03999996 ... -190.52999878 -304.29998779\n",
      " -282.16000366]\n",
      "Hessian [-0. -0. -0. ... -0. -0. -0.]\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's feval: -0\tvalid_1's feval: -0\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "#           \"objective\" : \"poisson\",\n",
    "#           \"metric\" :\"rmse\",\n",
    "          \"learning_rate\" : 0.1,\n",
    "          'verbosity': 2,\n",
    "          'max_depth': 6,\n",
    "          'num_leaves': 15,\n",
    "          \"min_data_in_leaf\":2000\n",
    "         }\n",
    "\n",
    "lgbtrain = lgb.Dataset(X_train, label = y_train, weight=w_train, categorical_feature=[8, 9, 10])\n",
    "lgbvalid = lgb.Dataset(X_val, label = y_val, weight=w_val, categorical_feature=[8, 9, 10])\n",
    "\n",
    "num_round = 1000\n",
    "model = lgb.train(params,\n",
    "                  lgbtrain,\n",
    "                  num_round,\n",
    "                  valid_sets = [lgbtrain, lgbvalid], \n",
    "                  verbose_eval=20,\n",
    "                  early_stopping_rounds=20,\n",
    "                  fobj=objective,\n",
    "                  feval=feval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predicting at test time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test['orderSum']\n",
    "X_test = test.drop(columns=[\"orderSum\"])\n",
    "final_predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.20043400e+01, 2.50993155e-03, 3.38431918e+01, ...,\n",
       "       2.79345936e-03, 2.79324730e-03, 2.79345936e-03])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions[final_predictions < 0]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating our Kaggle CSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.Series(0, index=np.arange(1, len(items)+1))\n",
    "final[items.itemID] = final_predictions.astype(int)\n",
    "\n",
    "final.to_csv(\"lgbm_kaggle_df.csv\", header=[\"demandPrediction\"],\n",
    "            index_label=\"itemID\", sep=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saving our model in disk**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now().strftime(\"%d-%m-%Y-%Hh%Mm%Ss\")\n",
    "modelName = 'lgbm-' + now\n",
    "bst.save_model(modelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "language": "python",
   "name": "python38164bitb3ebfd1fa0594a1c9d5c617333c2c1a4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
