{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "infos = pd.read_csv('../../data/infos.csv', sep = '|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = pd.read_csv('../../data/items.csv', sep = '|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = pd.read_csv('../../data/orders.csv', sep = '|', parse_dates=['time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Creating the structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = orders.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weekpair'] = (df.time.dt.dayofyear + 1) // 14 - 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "npairs = df.weekpair.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of items: 10463\n",
      "expected number of instances: 136019\n"
     ]
    }
   ],
   "source": [
    "n_items = items['itemID'].nunique()\n",
    "print('total number of items:', n_items)\n",
    "print('expected number of instances:', n_items * npairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi = pd.MultiIndex.from_product([range(-npairs, 0), items['itemID']], names=['weekpair', 'itemID'])\n",
    "data_temp = pd.DataFrame(index = mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_temp = data_temp.join(df.groupby(['weekpair', 'itemID'])[['order']].sum(), how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_temp.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order    13\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_temp.groupby('itemID').count().min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Creating features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gbagg(data, group_cols, targeted_cols, out_names, function, as_index = False):\n",
    "  \n",
    "    X = data.values\n",
    "    col = {c : i for i, c in enumerate(data.columns)}\n",
    "\n",
    "    # values that are going to calculated\n",
    "    new_feat = []\n",
    "    \n",
    "    # numbers of the columns\n",
    "    gcols = [col[c] for c in group_cols]\n",
    "    tcols = [col[c] for c in targeted_cols]\n",
    "    \n",
    "    interval = None\n",
    "    a = None\n",
    "    i = 0\n",
    "    while i < len(X):\n",
    "        a = X[i, gcols]\n",
    "\n",
    "        # find the whole interval of this group\n",
    "        j = i\n",
    "        while j < len(X):\n",
    "            if (X[j, gcols] != a).any():\n",
    "                break\n",
    "            j += 1\n",
    "        interval = X[i:j, tcols]\n",
    "\n",
    "        # apply function on interval, save in new feature\n",
    "        output = function(interval)\n",
    "        new_feat.append(output)\n",
    "\n",
    "        # go to next group\n",
    "        i = j\n",
    "    \n",
    "    idx = data.groupby(group_cols).size().index # this is actually fast...\n",
    "    out_df = pd.DataFrame(new_feat, columns = out_names, index = idx)\n",
    "        \n",
    "    if not as_index:\n",
    "        out_df.reset_index(inplace = True)\n",
    "        \n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gbtransf(data, group_cols, targeted_cols, out_names, function, params = dict()):\n",
    "  \n",
    "    X = data.values\n",
    "    col = {c : i for i, c in enumerate(data.columns)}\n",
    "\n",
    "    # values that are going to calculated\n",
    "    new_feat = np.zeros((len(data), len(out_names)))\n",
    "    \n",
    "    # numbers of the columns\n",
    "    gcols = [col[c] for c in group_cols]\n",
    "    tcols = [col[c] for c in targeted_cols]\n",
    "    \n",
    "    interval = None\n",
    "    a = None\n",
    "    i = 0\n",
    "    while i < len(X):\n",
    "        a = X[i, gcols]\n",
    "\n",
    "        # find the whole interval of this group\n",
    "        j = i\n",
    "        while j < len(X):\n",
    "            if (X[j, gcols] != a).any():\n",
    "                break\n",
    "            j += 1\n",
    "        interval = X[i:j, tcols]\n",
    "\n",
    "        # apply function on interval, save in new feature\n",
    "        output = function(interval, **params)\n",
    "        new_feat[i:j] = output\n",
    "\n",
    "        # go to next group\n",
    "        i = j\n",
    "    \n",
    "    out_df = pd.DataFrame(new_feat, columns = out_names, index = data.index)\n",
    "        \n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_and_2n_window(x, ws):\n",
    "#     out = pd.DataFrame(x)\n",
    "#     out = out.shift()\n",
    "#     out = out.rolling(2 ** n).mean()\n",
    "\n",
    "    shifted = np.zeros_like(x) # output\n",
    "    shifted[1:] = x[:-1] # shift\n",
    "    out = np.zeros_like(x, dtype = float)\n",
    "    \n",
    "    # rolling mean\n",
    "    total = shifted[:ws].sum()\n",
    "    out[ws - 1] = total / ws\n",
    "    for i in range(ws, len(out)):\n",
    "        total = total - shifted[i - ws] + shifted[i]\n",
    "        out[i] = total / ws\n",
    "    out[:ws] = np.NaN # maybe ws -1 should be NaN as well for receiving one NaN value when ws > 1\n",
    "    # out[0] = np.NaN # this is always NaN for a shift of 1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_temp.reset_index()\n",
    "data = pd.merge(data, items, on = 'itemID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values(['itemID', 'weekpair'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gbtransf(data, ['itemID', 'weekpair'], ['order'], ['out'], lambda x : np.ones_like(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, nan, 1.5, 2.5, 3.5, 4.5])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shift_and_2n_window(np.array([1 , 2, 3, 4, 5, 6]), 2 ** 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [('itemID', 'item')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "itemID\n"
     ]
    }
   ],
   "source": [
    "for f, name in features:\n",
    "    print(f)\n",
    "    new_feature_block = pd.DataFrame()\n",
    "    for n in range(3):\n",
    "        new_f = gbtransf(data, ['itemID'], ['order'], ['out'], shift_and_2n_window, {'ws' : 2 ** n})\n",
    "        new_feature_block['%s_%d' % (name, 2 ** n)] = new_f['out']\n",
    "#     data = pd.merge(data, new_feature_block.reset_index(), on = [f, 'weekpair'])\n",
    "    data = pd.concat([data, new_feature_block], axis =  1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "weekpair                  136019\n",
       "itemID                    136019\n",
       "order                     136019\n",
       "brand                     136019\n",
       "manufacturer              136019\n",
       "customerRating            136019\n",
       "category1                 136019\n",
       "category2                 136019\n",
       "category3                 136019\n",
       "recommendedRetailPrice    136019\n",
       "item_1                    125556\n",
       "item_2                    115093\n",
       "item_4                     94167\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count() # the larger the window, more NaN are expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist2firstvalue(x):\n",
    "    out = np.zeros_like(x, dtype = float)\n",
    "    first = np.NaN\n",
    "    for i in range(len(x)):\n",
    "        out[i] = first\n",
    "        if x[i] != 0:\n",
    "            first = i\n",
    "            break\n",
    "    if i == len(x) - 1:\n",
    "        return out\n",
    "    for j in range(int(first), len(x)):\n",
    "        out[j] = j - first\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([nan, nan, nan, nan]), array([nan, nan,  0.,  1.,  2.,  3.]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist2firstvalue(np.array([0 , 0, 0, 0])), dist2firstvalue(np.array([0 , 0, 3, 0, 5, 6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist2firstvalueLeak(x):\n",
    "    out = np.zeros_like(x, dtype = float)\n",
    "    for i in range(len(x)):\n",
    "        if x[i] != 0:\n",
    "            out[i] = 1\n",
    "            break\n",
    "#         else:\n",
    "#             out[i] = -9999\n",
    "        \n",
    "    return out\n",
    "\n",
    "# def dist2firstvalueLeakAdding(x):\n",
    "#     out = np.zeros_like(x, dtype = float)\n",
    "#     d = 1\n",
    "#     for i in range(len(x)):\n",
    "#         if x[i] != 0:\n",
    "#             out[i] = d\n",
    "#             break\n",
    "#     d += 1\n",
    "#     for j in range(i + 1, len(x)):\n",
    "#         out[j] = d\n",
    "#         d += 1\n",
    "#     return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist2firstvalueLeak(np.array([0 , 0, 3, 0, 5, 6]))\n",
    "# dist2firstvalue(np.array([0 , 0, 0, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def dist2lastpeak(x):\n",
    "#     out = np.zeros_like(x, dtype = float)\n",
    "#     peak = np.NaN\n",
    "#     peak_val = 0\n",
    "#     for i in range(0, len(x)):\n",
    "#         out[i] = i - peak\n",
    "#         if x[i] > peak_val:\n",
    "#             peak = i\n",
    "#             peak_val = x[i]\n",
    "        \n",
    "#     return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dist2lastpeak(np.array([0 , 0, 3, 0, 5, 6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values(['itemID', 'weekpair'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['dist2firstvalueLeak'] = gbtransf(data, ['itemID'], ['order'], ['out'], dist2firstvalueLeak)['out']\n",
    "# data['dist2lastpeak'] = gbtransf(data, ['itemID'], ['order'], ['out'], dist2lastpeak)['out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_cat = \"manufacturer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sla = data.groupby([\"weekpair\", the_cat])[\"dist2firstvalueLeak\"].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sla = sla.rename(columns={\"dist2firstvalueLeak\" : \"leak_cat3\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acho que mudou nada... opa, mudou sim\n",
    "data = pd.merge(data, sla, on = [\"weekpair\", the_cat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"total_new\"] = data[\"weekpair\"].map(data.groupby(\"weekpair\")[\"dist2firstvalueLeak\"].sum().to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weekpair</th>\n",
       "      <th>itemID</th>\n",
       "      <th>order</th>\n",
       "      <th>brand</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>customerRating</th>\n",
       "      <th>category1</th>\n",
       "      <th>category2</th>\n",
       "      <th>category3</th>\n",
       "      <th>recommendedRetailPrice</th>\n",
       "      <th>item_1</th>\n",
       "      <th>item_2</th>\n",
       "      <th>item_4</th>\n",
       "      <th>dist2firstvalueLeak</th>\n",
       "      <th>leak_cat3</th>\n",
       "      <th>total_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1431.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>-12</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>729.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>-11</td>\n",
       "      <td>1</td>\n",
       "      <td>313.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.84</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>371.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>-10</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.84</td>\n",
       "      <td>313.0</td>\n",
       "      <td>157.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>533.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>-9</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.84</td>\n",
       "      <td>35.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>87.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>785.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>-8</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.84</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>88.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>909.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>-7</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.84</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>88.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>716.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>-6</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.84</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>661.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>-5</td>\n",
       "      <td>1</td>\n",
       "      <td>299.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.84</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>785.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>-4</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.84</td>\n",
       "      <td>299.0</td>\n",
       "      <td>150.5</td>\n",
       "      <td>75.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>671.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>-3</td>\n",
       "      <td>1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.84</td>\n",
       "      <td>3.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>76.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>794.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.84</td>\n",
       "      <td>31.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>83.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>727.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>83.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>728.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     weekpair  itemID  order  brand  manufacturer  customerRating  category1  \\\n",
       "0         -13       1    0.0      0             1            4.38          1   \n",
       "40        -12       1    2.0      0             1            4.38          1   \n",
       "80        -11       1  313.0      0             1            4.38          1   \n",
       "120       -10       1   35.0      0             1            4.38          1   \n",
       "160        -9       1    3.0      0             1            4.38          1   \n",
       "200        -8       1    1.0      0             1            4.38          1   \n",
       "240        -7       1    1.0      0             1            4.38          1   \n",
       "280        -6       1    2.0      0             1            4.38          1   \n",
       "320        -5       1  299.0      0             1            4.38          1   \n",
       "360        -4       1    3.0      0             1            4.38          1   \n",
       "400        -3       1   31.0      0             1            4.38          1   \n",
       "440        -2       1    0.0      0             1            4.38          1   \n",
       "480        -1       1    3.0      0             1            4.38          1   \n",
       "\n",
       "     category2  category3  recommendedRetailPrice  item_1  item_2  item_4  \\\n",
       "0            1          1                    8.84     0.0     0.0    0.00   \n",
       "40           1          1                    8.84     0.0     0.0    0.00   \n",
       "80           1          1                    8.84     2.0     1.0    0.00   \n",
       "120          1          1                    8.84   313.0   157.5    0.00   \n",
       "160          1          1                    8.84    35.0   174.0   87.50   \n",
       "200          1          1                    8.84     3.0    19.0   88.25   \n",
       "240          1          1                    8.84     1.0     2.0   88.00   \n",
       "280          1          1                    8.84     1.0     1.0   10.00   \n",
       "320          1          1                    8.84     2.0     1.5    1.75   \n",
       "360          1          1                    8.84   299.0   150.5   75.75   \n",
       "400          1          1                    8.84     3.0   151.0   76.25   \n",
       "440          1          1                    8.84    31.0    17.0   83.75   \n",
       "480          1          1                    8.84     0.0    15.5   83.25   \n",
       "\n",
       "     dist2firstvalueLeak  leak_cat3  total_new  \n",
       "0                    0.0        5.0     1431.0  \n",
       "40                   1.0        4.0      729.0  \n",
       "80                   0.0        6.0      371.0  \n",
       "120                  0.0        3.0      533.0  \n",
       "160                  0.0        0.0      785.0  \n",
       "200                  0.0        1.0      909.0  \n",
       "240                  0.0        0.0      716.0  \n",
       "280                  0.0        1.0      661.0  \n",
       "320                  0.0       12.0      785.0  \n",
       "360                  0.0        1.0      671.0  \n",
       "400                  0.0        0.0      794.0  \n",
       "440                  0.0        6.0      727.0  \n",
       "480                  0.0        1.0      728.0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking if we got what we wanted\n",
    "data.query('itemID == 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  - Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = infos.set_index('itemID')['simulationPrice'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_data = data\n",
    "filtered_data = data.query(\"dist2firstvalueLeak == 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(136019, 9840)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data), len(filtered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_data.pop(\"itemID\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_week = -1\n",
    "train = filtered_data.query('-13 <= weekpair <= (@sub_week - 2)').reset_index(drop = True)\n",
    "full_train = filtered_data.query('-13 <= weekpair <= (@sub_week - 1)').reset_index(drop = True)\n",
    "val = filtered_data.query('weekpair == (@sub_week - 1)').reset_index(drop = True)\n",
    "sub = filtered_data.query('weekpair == (@sub_week)').reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8385, 727, 728)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(val), len(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train.pop('order').values\n",
    "y_full_train = full_train.pop('order').values\n",
    "y_val = val.pop('order').values\n",
    "y_sub = sub.pop('order').values\n",
    "\n",
    "w_train = train['itemID'].map(weights)\n",
    "w_full_train = full_train['itemID'].map(weights)\n",
    "w_val = val['itemID'].map(weights)\n",
    "w_sub = sub['itemID'].map(weights)\n",
    "\n",
    "train.pop(\"itemID\")\n",
    "full_train.pop(\"itemID\")\n",
    "val.pop(\"itemID\")\n",
    "sub.pop(\"itemID\")\n",
    "\n",
    "X_train = train.values\n",
    "X_full_train = full_train.values\n",
    "X_val = val.values\n",
    "X_sub = sub.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Min Expected Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(prediction, target, simulationPrice):\n",
    "    return np.sum((prediction - np.maximum(prediction - target, 0) * 1.6)  * simulationPrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max expected rmse\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "# pred = data.loc[1:12].groupby('itemID')['order'].mean().sort_index()\n",
    "# target_week = data.loc[13:, 'order'].reset_index(level = 0, drop = True).sort_index()\n",
    "# mse(target_week, pred) ** .5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.0'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom objective\n",
    "\n",
    "def gradient(prediction, dtrain):\n",
    "    y = dtrain.get_label()\n",
    "#     prediction.astype(int)\n",
    "#     prediction = np.minimum(prediction.astype(int), 1)\n",
    "    return -2 * (prediction - np.maximum(prediction - y, 0) * 1.6) * (1 - (prediction > y) * 1.6)\n",
    "\n",
    "def hessian(prediction, dtrain):\n",
    "    y = dtrain.get_label()\n",
    "#     prediction.prediction(int)\n",
    "#     prediction = np.minimum(prediction.astype(int), 1)\n",
    "    return -2 * (1 - (prediction > y) * 1.6) ** 2\n",
    "\n",
    "def objective(prediction, dtrain):\n",
    "    w = dtrain.get_weight()\n",
    "    grad = gradient(prediction, dtrain) * w\n",
    "    hess = hessian(prediction, dtrain) * w\n",
    "    return grad, hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom feval\n",
    "\n",
    "def feval(prediction, dtrain):\n",
    "    prediction = prediction.astype(int)\n",
    "#     predt = np.minimum(predt.astype(int), 1)\n",
    "    target = dtrain.get_label()\n",
    "    simulationPrice = dtrain.get_weight()\n",
    "    return 'feval', np.sum((prediction - np.maximum(prediction - target, 0) * 1.6)  * simulationPrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-feval:84890.44004\tval-feval:9371.34002\n",
      "Multiple eval metrics have been passed: 'val-feval' will be used for early stopping.\n",
      "\n",
      "Will train until val-feval hasn't improved in 10 rounds.\n",
      "[1]\ttrain-feval:155756.33802\tval-feval:16117.52401\n",
      "[2]\ttrain-feval:362273.85631\tval-feval:34828.89000\n",
      "[3]\ttrain-feval:415741.49434\tval-feval:40651.69799\n",
      "[4]\ttrain-feval:479058.11432\tval-feval:46892.81399\n",
      "[5]\ttrain-feval:571556.77219\tval-feval:50726.16200\n",
      "[6]\ttrain-feval:627300.82426\tval-feval:56721.67800\n",
      "[7]\ttrain-feval:964776.66430\tval-feval:80595.54197\n",
      "[8]\ttrain-feval:1005776.90636\tval-feval:85970.26997\n",
      "[9]\ttrain-feval:1082760.80840\tval-feval:93506.47399\n",
      "[10]\ttrain-feval:1112972.94246\tval-feval:95649.81798\n",
      "[11]\ttrain-feval:1159033.48852\tval-feval:101601.98599\n",
      "[12]\ttrain-feval:1591329.98221\tval-feval:125802.30618\n",
      "[13]\ttrain-feval:1651519.07433\tval-feval:132167.72619\n",
      "[14]\ttrain-feval:1679098.45436\tval-feval:134531.08219\n",
      "[15]\ttrain-feval:1726117.44239\tval-feval:140603.93019\n",
      "[16]\ttrain-feval:1771514.13440\tval-feval:144592.64219\n",
      "[17]\ttrain-feval:1901580.78648\tval-feval:157597.16221\n",
      "[18]\ttrain-feval:1942936.34252\tval-feval:162461.04221\n",
      "[19]\ttrain-feval:1975660.24653\tval-feval:167075.23621\n",
      "[20]\ttrain-feval:2130440.96652\tval-feval:171617.92422\n",
      "[21]\ttrain-feval:2153890.10452\tval-feval:174902.10622\n",
      "[22]\ttrain-feval:2233199.86258\tval-feval:181169.58225\n",
      "[23]\ttrain-feval:2372147.57061\tval-feval:199830.87422\n",
      "[24]\ttrain-feval:2428450.96263\tval-feval:204856.08624\n",
      "[25]\ttrain-feval:2470933.65068\tval-feval:210266.64624\n",
      "[26]\ttrain-feval:2490200.61469\tval-feval:212712.38824\n",
      "[27]\ttrain-feval:2568795.80471\tval-feval:218526.69426\n",
      "[28]\ttrain-feval:2860120.76243\tval-feval:232214.95415\n",
      "[29]\ttrain-feval:2911631.06045\tval-feval:236398.40616\n",
      "[30]\ttrain-feval:2956526.63437\tval-feval:240697.61616\n",
      "[31]\ttrain-feval:2997460.85241\tval-feval:245700.05417\n",
      "[32]\ttrain-feval:3024205.73647\tval-feval:248854.49015\n",
      "[33]\ttrain-feval:3116542.43843\tval-feval:254601.20419\n",
      "[34]\ttrain-feval:3177284.18058\tval-feval:264990.32223\n",
      "[35]\ttrain-feval:3304009.00858\tval-feval:268615.39022\n",
      "[36]\ttrain-feval:3328835.85861\tval-feval:272848.52623\n",
      "[37]\ttrain-feval:3391301.90669\tval-feval:279178.19223\n",
      "[38]\ttrain-feval:3421533.24876\tval-feval:283567.89223\n",
      "[39]\ttrain-feval:3489398.83860\tval-feval:285722.87626\n",
      "[40]\ttrain-feval:3612489.34067\tval-feval:304137.13619\n",
      "[41]\ttrain-feval:3919539.24058\tval-feval:317851.37436\n",
      "[42]\ttrain-feval:3955627.58861\tval-feval:323125.25437\n",
      "[43]\ttrain-feval:3979694.56868\tval-feval:327006.95436\n",
      "[44]\ttrain-feval:4015250.99871\tval-feval:331591.77036\n",
      "[45]\ttrain-feval:4081450.23471\tval-feval:335099.36839\n",
      "[46]\ttrain-feval:4145737.98687\tval-feval:345633.87439\n",
      "[47]\ttrain-feval:4173567.99093\tval-feval:348972.36640\n",
      "[48]\ttrain-feval:4211596.81887\tval-feval:352931.60640\n",
      "[49]\ttrain-feval:4253107.18089\tval-feval:357116.58840\n",
      "[50]\ttrain-feval:4292575.11499\tval-feval:361559.05842\n",
      "[51]\ttrain-feval:4353628.70900\tval-feval:365132.00044\n",
      "[52]\ttrain-feval:4381472.36302\tval-feval:368601.26245\n",
      "[53]\ttrain-feval:4534281.66712\tval-feval:378435.08844\n",
      "[54]\ttrain-feval:4560010.88517\tval-feval:381325.02645\n",
      "[55]\ttrain-feval:4587514.10320\tval-feval:385233.87845\n",
      "[56]\ttrain-feval:4639586.85109\tval-feval:390190.11645\n",
      "[57]\ttrain-feval:4668484.38714\tval-feval:394167.75646\n",
      "[58]\ttrain-feval:4800691.73307\tval-feval:405659.86046\n",
      "[59]\ttrain-feval:4824995.76307\tval-feval:408209.84047\n",
      "[60]\ttrain-feval:4883078.56317\tval-feval:418558.16446\n",
      "[61]\ttrain-feval:4924353.98125\tval-feval:422810.31846\n",
      "[62]\ttrain-feval:4954927.46529\tval-feval:426375.93848\n",
      "[63]\ttrain-feval:4973081.83325\tval-feval:429259.02448\n",
      "[64]\ttrain-feval:5029598.11329\tval-feval:432664.75249\n",
      "[65]\ttrain-feval:5059327.74521\tval-feval:435975.14851\n",
      "[66]\ttrain-feval:5084487.50922\tval-feval:439383.42252\n",
      "[67]\ttrain-feval:5141427.28937\tval-feval:448296.25051\n",
      "[68]\ttrain-feval:5179420.56343\tval-feval:452306.04252\n",
      "[69]\ttrain-feval:5209313.89742\tval-feval:455984.14651\n",
      "[70]\ttrain-feval:5235575.60746\tval-feval:459591.60452\n",
      "[71]\ttrain-feval:5261111.69547\tval-feval:461957.93053\n",
      "[72]\ttrain-feval:5396003.17553\tval-feval:469002.07664\n",
      "[73]\ttrain-feval:5427262.27158\tval-feval:472251.93066\n",
      "[74]\ttrain-feval:5471102.75556\tval-feval:477613.66264\n",
      "[75]\ttrain-feval:5717876.94355\tval-feval:491826.53063\n",
      "[76]\ttrain-feval:5747845.63162\tval-feval:495661.70063\n",
      "[77]\ttrain-feval:5779975.20154\tval-feval:498599.22864\n",
      "[78]\ttrain-feval:5827323.58952\tval-feval:503639.98867\n",
      "[79]\ttrain-feval:5902984.31749\tval-feval:512138.76269\n",
      "[80]\ttrain-feval:5955501.09161\tval-feval:515794.06468\n",
      "[81]\ttrain-feval:5989131.16963\tval-feval:517296.34069\n",
      "[82]\ttrain-feval:6023097.87372\tval-feval:523298.21069\n",
      "[83]\ttrain-feval:6057350.42376\tval-feval:526376.59668\n",
      "[84]\ttrain-feval:6093383.86368\tval-feval:529831.26268\n",
      "[85]\ttrain-feval:6133045.98775\tval-feval:535903.06469\n",
      "[86]\ttrain-feval:6168800.57582\tval-feval:539306.71469\n",
      "[87]\ttrain-feval:6198011.35776\tval-feval:543148.37664\n",
      "[88]\ttrain-feval:6233907.94968\tval-feval:546722.99464\n",
      "[89]\ttrain-feval:6272118.33983\tval-feval:552572.07263\n",
      "[90]\ttrain-feval:6307473.59583\tval-feval:553736.72463\n",
      "[91]\ttrain-feval:6331777.70386\tval-feval:557372.41864\n",
      "[92]\ttrain-feval:6356200.48386\tval-feval:559918.36463\n",
      "[93]\ttrain-feval:6398567.05985\tval-feval:563723.09663\n",
      "[94]\ttrain-feval:6436581.34192\tval-feval:569062.93063\n",
      "[95]\ttrain-feval:6647174.18450\tval-feval:575711.08254\n",
      "[96]\ttrain-feval:6716853.23864\tval-feval:578468.07851\n",
      "[97]\ttrain-feval:6756744.81864\tval-feval:582642.28450\n",
      "[98]\ttrain-feval:6792777.26077\tval-feval:586552.44855\n",
      "[99]\ttrain-feval:6825034.24272\tval-feval:587624.51854\n",
      "[100]\ttrain-feval:6859314.93665\tval-feval:590825.26454\n",
      "[101]\ttrain-feval:6901077.31064\tval-feval:599397.26657\n",
      "[102]\ttrain-feval:6941210.68064\tval-feval:602208.62458\n",
      "[103]\ttrain-feval:6955789.71473\tval-feval:604706.91059\n",
      "[104]\ttrain-feval:7023608.18475\tval-feval:615474.84256\n",
      "[105]\ttrain-feval:7039147.17284\tval-feval:617686.76457\n",
      "[106]\ttrain-feval:7075052.78085\tval-feval:620730.90258\n",
      "[107]\ttrain-feval:7099954.35084\tval-feval:624721.80856\n",
      "[108]\ttrain-feval:7129484.94085\tval-feval:627048.89056\n",
      "[109]\ttrain-feval:7157659.38887\tval-feval:630443.63856\n",
      "[110]\ttrain-feval:7188313.37892\tval-feval:630946.26857\n",
      "[111]\ttrain-feval:7210238.71288\tval-feval:634225.73253\n",
      "[112]\ttrain-feval:7249121.52880\tval-feval:636699.89655\n",
      "[113]\ttrain-feval:7270468.32277\tval-feval:639758.26655\n",
      "[114]\ttrain-feval:7302010.85083\tval-feval:644412.88655\n",
      "[115]\ttrain-feval:7327361.52289\tval-feval:646478.46255\n",
      "[116]\ttrain-feval:7345254.28893\tval-feval:648730.57256\n",
      "[117]\ttrain-feval:7374600.09295\tval-feval:653827.39651\n",
      "[118]\ttrain-feval:7408014.15693\tval-feval:656945.80849\n",
      "[119]\ttrain-feval:7489173.85700\tval-feval:665809.99852\n",
      "[120]\ttrain-feval:7563723.68090\tval-feval:668030.64253\n",
      "[121]\ttrain-feval:7594866.98296\tval-feval:670218.97254\n",
      "[122]\ttrain-feval:7618576.32500\tval-feval:672029.88054\n",
      "[123]\ttrain-feval:7648726.88102\tval-feval:674205.37654\n",
      "[124]\ttrain-feval:7676642.83706\tval-feval:676157.48056\n",
      "[125]\ttrain-feval:7747220.35533\tval-feval:678419.26256\n",
      "[126]\ttrain-feval:7789066.11741\tval-feval:686059.72659\n",
      "[127]\ttrain-feval:7811706.40145\tval-feval:688682.60860\n",
      "[128]\ttrain-feval:7831713.31555\tval-feval:691328.96259\n",
      "[129]\ttrain-feval:7863073.43931\tval-feval:693167.44659\n",
      "[130]\ttrain-feval:7888335.09927\tval-feval:696092.33259\n",
      "[131]\ttrain-feval:7914102.59730\tval-feval:698294.91060\n",
      "[132]\ttrain-feval:7930596.95521\tval-feval:700576.20661\n",
      "[133]\ttrain-feval:7955572.23916\tval-feval:702181.37459\n",
      "[134]\ttrain-feval:8001910.67907\tval-feval:708799.62057\n",
      "[135]\ttrain-feval:8025502.57311\tval-feval:712498.03255\n",
      "[136]\ttrain-feval:8050070.22311\tval-feval:715537.37058\n",
      "[137]\ttrain-feval:8073756.47919\tval-feval:717310.95858\n",
      "[138]\ttrain-feval:8101216.40920\tval-feval:722044.88858\n",
      "[139]\ttrain-feval:8125849.15908\tval-feval:723924.92457\n",
      "[140]\ttrain-feval:8151970.87708\tval-feval:727075.45857\n",
      "[141]\ttrain-feval:8174575.34518\tval-feval:729001.08259\n",
      "[142]\ttrain-feval:8188247.21119\tval-feval:730833.25859\n",
      "[143]\ttrain-feval:8211455.66113\tval-feval:733626.80663\n",
      "[144]\ttrain-feval:8230524.78111\tval-feval:735461.40262\n",
      "[145]\ttrain-feval:8246034.35916\tval-feval:737610.93063\n",
      "[146]\ttrain-feval:8273070.40326\tval-feval:742175.21669\n",
      "[147]\ttrain-feval:8296234.88321\tval-feval:742063.07269\n",
      "[148]\ttrain-feval:8321657.95121\tval-feval:744459.41270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[149]\ttrain-feval:8333098.51718\tval-feval:746609.61271\n",
      "[150]\ttrain-feval:8354335.44322\tval-feval:748591.56470\n",
      "[151]\ttrain-feval:8372571.23118\tval-feval:749923.85871\n",
      "[152]\ttrain-feval:8396954.83312\tval-feval:753966.44668\n",
      "[153]\ttrain-feval:8410277.22115\tval-feval:756334.41463\n",
      "[154]\ttrain-feval:8434520.50317\tval-feval:760787.29663\n",
      "[155]\ttrain-feval:8449380.77514\tval-feval:762947.16463\n",
      "[156]\ttrain-feval:8469969.23913\tval-feval:763615.11664\n",
      "[157]\ttrain-feval:8492069.11516\tval-feval:765623.29666\n",
      "[158]\ttrain-feval:8507451.68727\tval-feval:767603.23866\n",
      "[159]\ttrain-feval:8523936.73130\tval-feval:769564.42866\n",
      "[160]\ttrain-feval:8538633.18721\tval-feval:769513.73467\n",
      "[161]\ttrain-feval:8597468.49338\tval-feval:773805.36273\n",
      "[162]\ttrain-feval:8614017.39541\tval-feval:775936.04472\n",
      "[163]\ttrain-feval:8629978.52949\tval-feval:777211.77273\n",
      "[164]\ttrain-feval:8652126.35948\tval-feval:779680.50872\n",
      "[165]\ttrain-feval:8786635.29334\tval-feval:789437.75867\n",
      "[166]\ttrain-feval:8802657.70320\tval-feval:790115.81266\n",
      "[167]\ttrain-feval:8823583.41921\tval-feval:791074.72067\n",
      "[168]\ttrain-feval:8839221.41323\tval-feval:794062.62868\n",
      "[169]\ttrain-feval:8860483.15112\tval-feval:797111.58268\n",
      "[170]\ttrain-feval:8882624.02515\tval-feval:799520.77468\n",
      "[171]\ttrain-feval:8894193.15519\tval-feval:802020.94267\n",
      "[172]\ttrain-feval:8903522.05121\tval-feval:802732.99868\n",
      "[173]\ttrain-feval:8945077.74921\tval-feval:809307.93265\n",
      "[174]\ttrain-feval:8994637.14910\tval-feval:811428.35466\n",
      "[175]\ttrain-feval:9014573.86310\tval-feval:812142.48866\n",
      "[176]\ttrain-feval:9025997.22911\tval-feval:813312.91666\n",
      "[177]\ttrain-feval:9044489.64304\tval-feval:814807.24666\n",
      "[178]\ttrain-feval:9060556.76509\tval-feval:816543.41867\n",
      "[179]\ttrain-feval:9079771.20314\tval-feval:820194.57474\n",
      "[180]\ttrain-feval:9088405.06124\tval-feval:821174.51674\n",
      "[181]\ttrain-feval:9105889.66925\tval-feval:823289.51075\n",
      "[182]\ttrain-feval:9120496.83723\tval-feval:825025.34875\n",
      "[183]\ttrain-feval:9143758.93325\tval-feval:827277.88673\n",
      "[184]\ttrain-feval:9159089.79121\tval-feval:829056.17874\n",
      "[185]\ttrain-feval:9224529.91893\tval-feval:831948.95874\n",
      "[186]\ttrain-feval:9241797.38290\tval-feval:835041.21878\n",
      "[187]\ttrain-feval:9254365.91492\tval-feval:836341.65877\n",
      "[188]\ttrain-feval:9258974.81466\tval-feval:837128.23878\n",
      "[189]\ttrain-feval:9270157.97670\tval-feval:836378.66279\n",
      "[190]\ttrain-feval:9294121.08679\tval-feval:839348.67678\n",
      "[191]\ttrain-feval:9301156.98679\tval-feval:840260.81079\n",
      "[192]\ttrain-feval:9307059.15876\tval-feval:841470.88679\n",
      "[193]\ttrain-feval:9324230.44278\tval-feval:843861.85278\n",
      "[194]\ttrain-feval:9345685.76075\tval-feval:847747.28279\n",
      "[195]\ttrain-feval:9355900.88873\tval-feval:849070.57879\n",
      "[196]\ttrain-feval:9368445.78876\tval-feval:850578.30079\n",
      "[197]\ttrain-feval:9380999.68890\tval-feval:852109.33679\n",
      "[198]\ttrain-feval:9391526.91096\tval-feval:853596.37479\n",
      "[199]\ttrain-feval:9402476.40494\tval-feval:855953.17078\n",
      "[200]\ttrain-feval:9415547.74696\tval-feval:856849.89678\n",
      "[201]\ttrain-feval:9420737.87488\tval-feval:857708.83676\n",
      "[202]\ttrain-feval:9444555.33296\tval-feval:858916.69277\n",
      "[203]\ttrain-feval:9450737.51286\tval-feval:861132.90678\n",
      "[204]\ttrain-feval:9466545.43291\tval-feval:864336.99277\n",
      "[205]\ttrain-feval:9483767.09095\tval-feval:868468.98084\n",
      "[206]\ttrain-feval:9504427.21105\tval-feval:867846.11484\n",
      "[207]\ttrain-feval:9515093.80520\tval-feval:869747.42485\n",
      "[208]\ttrain-feval:9525424.49726\tval-feval:870617.96285\n",
      "[209]\ttrain-feval:9550703.92537\tval-feval:871970.43885\n",
      "[210]\ttrain-feval:9566778.65942\tval-feval:875915.75084\n",
      "[211]\ttrain-feval:9577343.73741\tval-feval:876738.37085\n",
      "[212]\ttrain-feval:9591728.89748\tval-feval:878440.80684\n",
      "[213]\ttrain-feval:9605801.40140\tval-feval:879352.04684\n",
      "[214]\ttrain-feval:9628730.13527\tval-feval:882261.45482\n",
      "[215]\ttrain-feval:9641271.59124\tval-feval:883404.18683\n",
      "[216]\ttrain-feval:9652863.63528\tval-feval:885063.22483\n",
      "[217]\ttrain-feval:9668533.43124\tval-feval:887796.49883\n",
      "[218]\ttrain-feval:9684767.23710\tval-feval:888764.97084\n",
      "[219]\ttrain-feval:9691343.28702\tval-feval:890949.15483\n",
      "[220]\ttrain-feval:9709941.70705\tval-feval:892920.13685\n",
      "[221]\ttrain-feval:9728499.69694\tval-feval:894958.65083\n",
      "[222]\ttrain-feval:9743754.81497\tval-feval:896334.93882\n",
      "[223]\ttrain-feval:9762091.76716\tval-feval:896508.22281\n",
      "[224]\ttrain-feval:9781703.22115\tval-feval:898647.25283\n",
      "[225]\ttrain-feval:9781786.23501\tval-feval:899109.71084\n",
      "[226]\ttrain-feval:9795072.06114\tval-feval:900788.03483\n",
      "[227]\ttrain-feval:9803160.54911\tval-feval:902148.96283\n",
      "[228]\ttrain-feval:9815306.55111\tval-feval:903111.74684\n",
      "[229]\ttrain-feval:9821102.93511\tval-feval:905099.57284\n",
      "[230]\ttrain-feval:9834518.54324\tval-feval:905888.51284\n",
      "[231]\ttrain-feval:9845613.93725\tval-feval:906896.11683\n",
      "[232]\ttrain-feval:9866106.85332\tval-feval:908268.51484\n",
      "[233]\ttrain-feval:9881922.78513\tval-feval:907813.36285\n",
      "[234]\ttrain-feval:9890829.06125\tval-feval:908910.48286\n",
      "[235]\ttrain-feval:9905267.47937\tval-feval:910414.88486\n",
      "[236]\ttrain-feval:9913598.33331\tval-feval:910904.64685\n",
      "[237]\ttrain-feval:9952369.47723\tval-feval:916366.16291\n",
      "[238]\ttrain-feval:9965991.96532\tval-feval:917186.66892\n",
      "[239]\ttrain-feval:9970676.21330\tval-feval:918171.07492\n",
      "[240]\ttrain-feval:9982717.50739\tval-feval:919010.74293\n",
      "[241]\ttrain-feval:9991487.58745\tval-feval:919058.74094\n",
      "[242]\ttrain-feval:10015191.40326\tval-feval:921378.63494\n",
      "[243]\ttrain-feval:10020400.57525\tval-feval:921727.90294\n",
      "[244]\ttrain-feval:10028720.89934\tval-feval:924619.82692\n",
      "[245]\ttrain-feval:10036054.34943\tval-feval:926015.68092\n",
      "[246]\ttrain-feval:10046874.86553\tval-feval:927527.37691\n",
      "[247]\ttrain-feval:10055115.49148\tval-feval:927993.41091\n",
      "[248]\ttrain-feval:10066191.41955\tval-feval:930001.99690\n",
      "[249]\ttrain-feval:10068223.23752\tval-feval:930372.97891\n",
      "[250]\ttrain-feval:10083612.16752\tval-feval:932395.47489\n",
      "[251]\ttrain-feval:10086428.23952\tval-feval:932861.25289\n",
      "[252]\ttrain-feval:10089375.16952\tval-feval:933227.15289\n",
      "[253]\ttrain-feval:10101299.37549\tval-feval:935369.58289\n",
      "[254]\ttrain-feval:10108870.00949\tval-feval:935679.36089\n",
      "[255]\ttrain-feval:10113503.38748\tval-feval:936348.40890\n",
      "[256]\ttrain-feval:10130219.95544\tval-feval:936759.79090\n",
      "[257]\ttrain-feval:10139178.56157\tval-feval:938504.50687\n",
      "[258]\ttrain-feval:10144188.22563\tval-feval:938298.85687\n",
      "[259]\ttrain-feval:10155337.30957\tval-feval:938790.85888\n",
      "[260]\ttrain-feval:10178984.07510\tval-feval:939143.53288\n",
      "[261]\ttrain-feval:10187451.10311\tval-feval:942843.26695\n",
      "[262]\ttrain-feval:10193697.17304\tval-feval:943681.79295\n",
      "[263]\ttrain-feval:10200352.80515\tval-feval:944230.29695\n",
      "[264]\ttrain-feval:10211617.59511\tval-feval:944335.73497\n",
      "[265]\ttrain-feval:10223903.39113\tval-feval:945757.05497\n",
      "[266]\ttrain-feval:10245893.66319\tval-feval:947337.89698\n",
      "[267]\ttrain-feval:10252766.27924\tval-feval:947921.74498\n",
      "[268]\ttrain-feval:10258627.78927\tval-feval:948437.71297\n",
      "[269]\ttrain-feval:10259203.98727\tval-feval:948720.42098\n",
      "[270]\ttrain-feval:10266901.61527\tval-feval:949676.35698\n",
      "[271]\ttrain-feval:10278270.56913\tval-feval:950678.79899\n",
      "[272]\ttrain-feval:10312862.23516\tval-feval:950906.62500\n",
      "[273]\ttrain-feval:10321167.75508\tval-feval:954949.26290\n",
      "[274]\ttrain-feval:10326727.72911\tval-feval:957445.11089\n",
      "[275]\ttrain-feval:10336099.83895\tval-feval:957646.53289\n",
      "[276]\ttrain-feval:10342305.23086\tval-feval:957249.77887\n",
      "[277]\ttrain-feval:10348268.43887\tval-feval:957405.59887\n",
      "[278]\ttrain-feval:10357651.76082\tval-feval:958569.18488\n",
      "[279]\ttrain-feval:10369004.09477\tval-feval:959112.41488\n",
      "[280]\ttrain-feval:10374623.49881\tval-feval:959551.32288\n",
      "[281]\ttrain-feval:10387680.56277\tval-feval:960932.05887\n",
      "[282]\ttrain-feval:10396058.71481\tval-feval:961472.69287\n",
      "[283]\ttrain-feval:10400996.08072\tval-feval:962010.85487\n",
      "[284]\ttrain-feval:10411800.09480\tval-feval:962460.45087\n",
      "[285]\ttrain-feval:10422067.90486\tval-feval:963949.83089\n",
      "[286]\ttrain-feval:10427286.38486\tval-feval:964682.34889\n",
      "[287]\ttrain-feval:10431983.49888\tval-feval:964660.97089\n",
      "[288]\ttrain-feval:10436718.92294\tval-feval:965113.68289\n",
      "[289]\ttrain-feval:10441843.01492\tval-feval:966158.30289\n",
      "[290]\ttrain-feval:10449302.62894\tval-feval:966950.36689\n",
      "[291]\ttrain-feval:10454217.46296\tval-feval:967682.77089\n",
      "[292]\ttrain-feval:10463160.80100\tval-feval:968772.79489\n",
      "[293]\ttrain-feval:10468303.99710\tval-feval:971000.89890\n",
      "[294]\ttrain-feval:10471791.52316\tval-feval:972707.96288\n",
      "[295]\ttrain-feval:10479562.31735\tval-feval:972089.57489\n",
      "[296]\ttrain-feval:10485765.27940\tval-feval:972409.77690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[297]\ttrain-feval:10490291.02139\tval-feval:973435.07889\n",
      "[298]\ttrain-feval:10493876.33328\tval-feval:975046.04489\n",
      "[299]\ttrain-feval:10495478.03530\tval-feval:975273.50289\n",
      "[300]\ttrain-feval:10498032.07333\tval-feval:975554.44689\n",
      "[301]\ttrain-feval:10503626.76536\tval-feval:975947.57289\n",
      "[302]\ttrain-feval:10512687.85934\tval-feval:975440.07688\n",
      "[303]\ttrain-feval:10518069.38335\tval-feval:975664.91286\n",
      "[304]\ttrain-feval:10525486.34729\tval-feval:976178.82686\n",
      "[305]\ttrain-feval:10525330.44526\tval-feval:976393.02286\n",
      "[306]\ttrain-feval:10532941.36528\tval-feval:976527.02286\n",
      "[307]\ttrain-feval:10540166.50726\tval-feval:976845.82086\n",
      "[308]\ttrain-feval:10577786.23322\tval-feval:977575.62486\n",
      "[309]\ttrain-feval:10583260.19127\tval-feval:978199.56486\n",
      "[310]\ttrain-feval:10587018.88526\tval-feval:978389.72086\n",
      "[311]\ttrain-feval:10596868.95325\tval-feval:978674.13287\n",
      "[312]\ttrain-feval:10604765.94140\tval-feval:982392.62694\n",
      "[313]\ttrain-feval:10611235.05736\tval-feval:982453.14095\n",
      "[314]\ttrain-feval:10614890.68941\tval-feval:983082.26495\n",
      "[315]\ttrain-feval:10616799.23937\tval-feval:983214.99095\n",
      "[316]\ttrain-feval:10621377.06531\tval-feval:982859.71495\n",
      "[317]\ttrain-feval:10626660.90330\tval-feval:983001.14496\n",
      "[318]\ttrain-feval:10635823.23539\tval-feval:983217.33896\n",
      "[319]\ttrain-feval:10638103.22336\tval-feval:983602.16695\n",
      "[320]\ttrain-feval:10650680.04714\tval-feval:984443.64294\n",
      "[321]\ttrain-feval:10655469.87918\tval-feval:984976.66496\n",
      "[322]\ttrain-feval:10657595.71927\tval-feval:985184.87695\n",
      "[323]\ttrain-feval:10670906.23345\tval-feval:985481.06097\n",
      "[324]\ttrain-feval:10674166.19945\tval-feval:985998.99495\n",
      "[325]\ttrain-feval:10677948.64747\tval-feval:986295.37696\n",
      "[326]\ttrain-feval:10677530.41949\tval-feval:987055.63096\n",
      "[327]\ttrain-feval:10682202.29567\tval-feval:988337.14695\n",
      "[328]\ttrain-feval:10686832.36164\tval-feval:988788.80895\n",
      "[329]\ttrain-feval:10689797.17761\tval-feval:989023.37294\n",
      "[330]\ttrain-feval:10697098.72963\tval-feval:990281.43694\n",
      "[331]\ttrain-feval:10699786.40353\tval-feval:990159.73094\n",
      "[332]\ttrain-feval:10702309.02954\tval-feval:990698.31694\n",
      "[333]\ttrain-feval:10716726.89138\tval-feval:991708.98092\n",
      "[334]\ttrain-feval:10721523.24138\tval-feval:992195.40693\n",
      "[335]\ttrain-feval:10722961.78339\tval-feval:992560.70894\n",
      "[336]\ttrain-feval:10730219.57338\tval-feval:992768.40292\n",
      "[337]\ttrain-feval:10738566.42341\tval-feval:993177.61091\n",
      "[338]\ttrain-feval:10741814.79737\tval-feval:993561.41491\n",
      "[339]\ttrain-feval:10745358.54938\tval-feval:994271.75893\n",
      "[340]\ttrain-feval:10748509.38532\tval-feval:994908.50693\n",
      "[341]\ttrain-feval:10752220.64936\tval-feval:995085.79893\n",
      "[342]\ttrain-feval:10757285.34536\tval-feval:995783.61493\n",
      "[343]\ttrain-feval:10757546.94938\tval-feval:995914.08894\n",
      "[344]\ttrain-feval:10763314.10736\tval-feval:996595.38494\n",
      "[345]\ttrain-feval:10765476.09535\tval-feval:996719.68694\n",
      "[346]\ttrain-feval:10765688.13333\tval-feval:995858.59094\n",
      "[347]\ttrain-feval:10757911.96934\tval-feval:995889.88095\n",
      "[348]\ttrain-feval:10761860.81933\tval-feval:996232.47694\n",
      "[349]\ttrain-feval:10763994.17737\tval-feval:996754.27895\n",
      "[350]\ttrain-feval:10770507.60939\tval-feval:997305.76695\n",
      "[351]\ttrain-feval:10769509.01549\tval-feval:997487.19695\n",
      "[352]\ttrain-feval:10773812.72346\tval-feval:997679.29095\n",
      "[353]\ttrain-feval:10774699.63136\tval-feval:996701.41893\n",
      "[354]\ttrain-feval:10775185.40937\tval-feval:997229.95093\n",
      "[355]\ttrain-feval:10779161.37139\tval-feval:997453.18893\n",
      "[356]\ttrain-feval:10787795.03753\tval-feval:1000017.88692\n",
      "[357]\ttrain-feval:10792198.33154\tval-feval:1000157.03292\n",
      "[358]\ttrain-feval:10793504.85157\tval-feval:1000320.83692\n",
      "[359]\ttrain-feval:10793203.28757\tval-feval:1000527.86492\n",
      "[360]\ttrain-feval:10791448.65533\tval-feval:1004428.72896\n",
      "[361]\ttrain-feval:10799879.13140\tval-feval:1005134.62296\n",
      "[362]\ttrain-feval:10799548.70546\tval-feval:1006162.86497\n",
      "[363]\ttrain-feval:10801673.38544\tval-feval:1006354.24898\n",
      "[364]\ttrain-feval:10807023.82546\tval-feval:1007125.28496\n",
      "[365]\ttrain-feval:10808461.47342\tval-feval:1007151.17096\n",
      "[366]\ttrain-feval:10813204.21745\tval-feval:1007205.97297\n",
      "[367]\ttrain-feval:10814825.69341\tval-feval:1008496.55696\n",
      "[368]\ttrain-feval:10811821.92928\tval-feval:1008703.43697\n",
      "[369]\ttrain-feval:10822215.31948\tval-feval:1009204.23096\n",
      "[370]\ttrain-feval:10820641.23132\tval-feval:1009351.09096\n",
      "[371]\ttrain-feval:10823385.74124\tval-feval:1009442.12896\n",
      "[372]\ttrain-feval:10830659.32720\tval-feval:1010146.62095\n",
      "[373]\ttrain-feval:10829963.14115\tval-feval:1010317.17494\n",
      "[374]\ttrain-feval:10833246.87520\tval-feval:1010887.51695\n",
      "[375]\ttrain-feval:10830658.50116\tval-feval:1011130.33495\n",
      "[376]\ttrain-feval:10835741.23927\tval-feval:1013525.57101\n",
      "[377]\ttrain-feval:10839426.64541\tval-feval:1013490.20102\n",
      "[378]\ttrain-feval:10842024.07748\tval-feval:1013549.87102\n",
      "[379]\ttrain-feval:10844496.84347\tval-feval:1013123.28100\n",
      "[380]\ttrain-feval:10848066.08148\tval-feval:1013384.08101\n",
      "[381]\ttrain-feval:10850413.59745\tval-feval:1013799.17901\n",
      "[382]\ttrain-feval:10851407.21546\tval-feval:1014206.06101\n",
      "[383]\ttrain-feval:10853601.72548\tval-feval:1014604.95101\n",
      "[384]\ttrain-feval:10858634.12951\tval-feval:1014634.71701\n",
      "[385]\ttrain-feval:10854784.91156\tval-feval:1015148.14500\n",
      "[386]\ttrain-feval:10850530.73135\tval-feval:1015157.34900\n",
      "[387]\ttrain-feval:10853051.95134\tval-feval:1015865.66299\n",
      "[388]\ttrain-feval:10854526.84937\tval-feval:1015799.18699\n",
      "[389]\ttrain-feval:10856505.14538\tval-feval:1016088.47899\n",
      "[390]\ttrain-feval:10859913.43137\tval-feval:1017289.79100\n",
      "[391]\ttrain-feval:10865080.52129\tval-feval:1018316.45300\n",
      "[392]\ttrain-feval:10864290.12345\tval-feval:1018450.06899\n",
      "[393]\ttrain-feval:10873789.81520\tval-feval:1018457.05098\n",
      "[394]\ttrain-feval:10877519.25714\tval-feval:1018587.83298\n",
      "[395]\ttrain-feval:10881214.54722\tval-feval:1017616.61899\n",
      "[396]\ttrain-feval:10885938.93929\tval-feval:1018041.22299\n",
      "[397]\ttrain-feval:10887866.65131\tval-feval:1017827.13499\n",
      "[398]\ttrain-feval:10886819.01327\tval-feval:1017981.69500\n",
      "[399]\ttrain-feval:10892347.06931\tval-feval:1018815.47298\n",
      "[400]\ttrain-feval:10895908.22531\tval-feval:1019028.21899\n",
      "[401]\ttrain-feval:10901931.70946\tval-feval:1019242.58498\n",
      "[402]\ttrain-feval:10906340.25351\tval-feval:1019402.05899\n",
      "[403]\ttrain-feval:10905780.83554\tval-feval:1019170.42299\n",
      "[404]\ttrain-feval:10903357.89553\tval-feval:1019190.09099\n",
      "[405]\ttrain-feval:10925281.91342\tval-feval:1019173.90699\n",
      "[406]\ttrain-feval:10929144.39542\tval-feval:1019022.99099\n",
      "[407]\ttrain-feval:10931883.95141\tval-feval:1019565.68899\n",
      "[408]\ttrain-feval:10933739.07139\tval-feval:1019873.16100\n",
      "[409]\ttrain-feval:10935380.27339\tval-feval:1019829.32300\n",
      "[410]\ttrain-feval:10936891.84137\tval-feval:1020038.27300\n",
      "[411]\ttrain-feval:10937674.79541\tval-feval:1020486.56099\n",
      "[412]\ttrain-feval:10939429.35524\tval-feval:1020551.79300\n",
      "[413]\ttrain-feval:10944850.82533\tval-feval:1020449.86499\n",
      "[414]\ttrain-feval:10948220.07539\tval-feval:1020866.71500\n",
      "[415]\ttrain-feval:10947868.91935\tval-feval:1020884.17700\n",
      "[416]\ttrain-feval:10957801.36345\tval-feval:1020846.19299\n",
      "[417]\ttrain-feval:10959840.54143\tval-feval:1020964.59700\n",
      "[418]\ttrain-feval:10959566.15944\tval-feval:1020946.64300\n",
      "[419]\ttrain-feval:10963644.97957\tval-feval:1022922.18100\n",
      "[420]\ttrain-feval:10968079.91960\tval-feval:1023712.66497\n",
      "[421]\ttrain-feval:10973722.89161\tval-feval:1023983.89096\n",
      "[422]\ttrain-feval:10973799.42962\tval-feval:1023604.56696\n",
      "[423]\ttrain-feval:10972150.81351\tval-feval:1023829.08497\n",
      "[424]\ttrain-feval:10973566.53549\tval-feval:1024217.43297\n",
      "[425]\ttrain-feval:10978043.56753\tval-feval:1024804.47096\n",
      "[426]\ttrain-feval:10968767.53959\tval-feval:1024849.55096\n",
      "[427]\ttrain-feval:10973415.13366\tval-feval:1025485.06697\n",
      "[428]\ttrain-feval:10975970.51568\tval-feval:1025704.46097\n",
      "[429]\ttrain-feval:10978201.92764\tval-feval:1026588.38899\n",
      "[430]\ttrain-feval:10978862.79166\tval-feval:1026615.99299\n",
      "[431]\ttrain-feval:10982513.84557\tval-feval:1027032.43299\n",
      "[432]\ttrain-feval:10984553.97364\tval-feval:1027052.05099\n",
      "[433]\ttrain-feval:10991856.99963\tval-feval:1027139.64699\n",
      "[434]\ttrain-feval:10997094.38167\tval-feval:1027235.44700\n",
      "[435]\ttrain-feval:11000683.36370\tval-feval:1027738.10899\n",
      "[436]\ttrain-feval:11004590.20973\tval-feval:1028270.44497\n",
      "[437]\ttrain-feval:10998723.98371\tval-feval:1028626.54698\n",
      "[438]\ttrain-feval:11003710.25579\tval-feval:1028738.27897\n",
      "[439]\ttrain-feval:11002829.70568\tval-feval:1031954.06688\n",
      "[440]\ttrain-feval:11006018.29567\tval-feval:1032015.93288\n",
      "[441]\ttrain-feval:11008253.32766\tval-feval:1032909.08288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[442]\ttrain-feval:11010986.70361\tval-feval:1033363.83088\n",
      "[443]\ttrain-feval:11012769.89761\tval-feval:1033246.01088\n",
      "[444]\ttrain-feval:11017461.91368\tval-feval:1033777.55086\n",
      "[445]\ttrain-feval:11020436.36769\tval-feval:1034175.87487\n",
      "[446]\ttrain-feval:11021218.08570\tval-feval:1034018.07687\n",
      "[447]\ttrain-feval:11028365.23352\tval-feval:1033683.95087\n",
      "[448]\ttrain-feval:11029145.36142\tval-feval:1034045.63288\n",
      "[449]\ttrain-feval:11030368.52166\tval-feval:1034462.25690\n",
      "[450]\ttrain-feval:11036753.45146\tval-feval:1034438.90291\n",
      "[451]\ttrain-feval:11038359.03745\tval-feval:1034633.02690\n",
      "[452]\ttrain-feval:11042437.94946\tval-feval:1034304.21691\n",
      "[453]\ttrain-feval:11044274.93949\tval-feval:1034454.62491\n",
      "[454]\ttrain-feval:11050107.09152\tval-feval:1034777.86092\n",
      "[455]\ttrain-feval:11049091.88151\tval-feval:1035319.02692\n",
      "[456]\ttrain-feval:11054396.08352\tval-feval:1035312.31092\n",
      "[457]\ttrain-feval:11053091.13955\tval-feval:1035450.72093\n",
      "[458]\ttrain-feval:11053762.82946\tval-feval:1035645.14492\n",
      "[459]\ttrain-feval:11053530.57349\tval-feval:1035934.67091\n",
      "[460]\ttrain-feval:11053528.93746\tval-feval:1035930.79292\n",
      "[461]\ttrain-feval:11052164.65954\tval-feval:1035851.49292\n",
      "[462]\ttrain-feval:11054683.79944\tval-feval:1036055.61692\n",
      "[463]\ttrain-feval:11059909.67349\tval-feval:1036182.45892\n",
      "[464]\ttrain-feval:11057486.42157\tval-feval:1039664.39497\n",
      "[465]\ttrain-feval:11063152.49355\tval-feval:1039664.03697\n",
      "[466]\ttrain-feval:11064303.52955\tval-feval:1040061.05496\n",
      "[467]\ttrain-feval:11061761.23159\tval-feval:1040095.05496\n",
      "[468]\ttrain-feval:11062974.29755\tval-feval:1040415.41495\n",
      "[469]\ttrain-feval:11068407.07761\tval-feval:1040436.78095\n",
      "[470]\ttrain-feval:11072448.49966\tval-feval:1040311.51294\n",
      "[471]\ttrain-feval:11076312.35565\tval-feval:1040227.82494\n",
      "[472]\ttrain-feval:11078230.07368\tval-feval:1040689.50093\n",
      "[473]\ttrain-feval:11079729.23971\tval-feval:1040824.42694\n",
      "[474]\ttrain-feval:11085304.97373\tval-feval:1041237.99694\n",
      "[475]\ttrain-feval:11083688.49367\tval-feval:1041341.27294\n",
      "[476]\ttrain-feval:11090678.26364\tval-feval:1041129.94493\n",
      "[477]\ttrain-feval:11091098.64976\tval-feval:1041551.14094\n",
      "[478]\ttrain-feval:11093617.32178\tval-feval:1041598.31294\n",
      "[479]\ttrain-feval:11095288.72977\tval-feval:1041308.19295\n",
      "[480]\ttrain-feval:11099272.88770\tval-feval:1040416.59296\n",
      "[481]\ttrain-feval:11102824.07568\tval-feval:1041046.37095\n",
      "[482]\ttrain-feval:11105426.46162\tval-feval:1041165.93495\n",
      "[483]\ttrain-feval:11105206.87362\tval-feval:1042565.83094\n",
      "[484]\ttrain-feval:11106325.01765\tval-feval:1042623.79694\n",
      "[485]\ttrain-feval:11104157.47771\tval-feval:1042743.10494\n",
      "[486]\ttrain-feval:11106022.73775\tval-feval:1042864.64095\n",
      "[487]\ttrain-feval:11105609.37376\tval-feval:1042959.42695\n",
      "[488]\ttrain-feval:11108882.89172\tval-feval:1042701.59095\n",
      "[489]\ttrain-feval:11109831.57368\tval-feval:1042827.57695\n",
      "[490]\ttrain-feval:11110058.40170\tval-feval:1043232.22095\n",
      "[491]\ttrain-feval:11109067.19373\tval-feval:1043514.18895\n",
      "[492]\ttrain-feval:11108052.43776\tval-feval:1043377.67696\n",
      "[493]\ttrain-feval:11109722.12978\tval-feval:1043589.89296\n",
      "[494]\ttrain-feval:11104600.57177\tval-feval:1044787.22897\n",
      "[495]\ttrain-feval:11105368.63376\tval-feval:1044850.39296\n",
      "[496]\ttrain-feval:11110445.71774\tval-feval:1044680.67096\n",
      "[497]\ttrain-feval:11111842.36572\tval-feval:1042864.26496\n",
      "[498]\ttrain-feval:11112637.94769\tval-feval:1043099.14297\n",
      "[499]\ttrain-feval:11112778.12165\tval-feval:1043401.93296\n",
      "[500]\ttrain-feval:11117318.48766\tval-feval:1043841.66895\n",
      "[501]\ttrain-feval:11114570.50957\tval-feval:1043928.54095\n",
      "[502]\ttrain-feval:11115515.19762\tval-feval:1044159.56895\n",
      "[503]\ttrain-feval:11116244.99960\tval-feval:1044248.62295\n",
      "[504]\ttrain-feval:11118644.11764\tval-feval:1044128.47295\n",
      "[505]\ttrain-feval:11120683.97559\tval-feval:1044254.61296\n",
      "Stopping. Best iteration:\n",
      "[495]\ttrain-feval:11105368.63376\tval-feval:1044850.39296\n",
      "\n"
     ]
    }
   ],
   "source": [
    "missing = 0\n",
    "dtrain = xgb.DMatrix(X_train, y_train, w_train, missing = missing)\n",
    "dfulltrain = xgb.DMatrix(X_full_train, y_full_train, w_full_train, missing = missing)\n",
    "dval = xgb.DMatrix(X_val, y_val, w_val, missing = missing)\n",
    "dsub = xgb.DMatrix(X_sub, y_sub, w_sub, missing = missing)\n",
    "# specify parameters via map\n",
    "param = {\n",
    "    'max_depth':4,\n",
    "    'eta':0.005,\n",
    "    'objective':'reg:squarederror',\n",
    "    'disable_default_eval_metric': 1,\n",
    "    \"min_child_weight\" : 10000,\n",
    "    \n",
    "#     'tree_method' : 'gpu_hist',\n",
    "}\n",
    "num_round = 800\n",
    "bst = xgb.train(param, dtrain,\n",
    "                num_round,\n",
    "                early_stopping_rounds = 10,\n",
    "                evals = [(dtrain, 'train'), (dval, 'val')],\n",
    "#                 obj = objective,\n",
    "                feval = feval,\n",
    "                maximize = True,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1156373.3959999997"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = bst.predict(dsub, ntree_limit=bst.best_ntree_limit).astype(int)\n",
    "evaluate(prediction, y_sub, w_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "496"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst_sub = xgb.train(param, dfulltrain,\n",
    "    num_boost_round = bst.best_ntree_limit,\n",
    "    #                 obj = objective,\n",
    "    feval = feval, maximize = True,\n",
    "    evals = [(dfulltrain, 'ftrain')],\n",
    "    verbose_eval = False,\n",
    ")\n",
    "bst_sub.best_ntree_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1164394.386"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = bst_sub.predict(dsub, ntree_limit=bst_sub.best_ntree_limit).astype(int)\n",
    "evaluate(prediction, y_sub, w_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some other things below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7683293.24"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max possible score\n",
    "evaluate(y_sub, y_sub, w_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3425880.0980000007"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using previous weekpair\n",
    "evaluate(y_val, y_sub, w_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = items[['itemID']].copy()\n",
    "submission['demandPrediction'] = bst.predict(dsub, ntree_limit=bst.best_ntree_limit).astype(int)\n",
    "submission.to_csv('../../submissions/sub_inclass_03.csv', sep = '|', index=False)\n",
    "# submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feval_lgbm(prediction, dtrain):\n",
    "    prediction = prediction.astype(int)\n",
    "    target = dtrain.get_label()\n",
    "    simulationPrice = dtrain.get_weight()\n",
    "    return 'feval', np.sum((prediction - np.maximum(prediction - target, 0) * 1.6)  * simulationPrice), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['weekpair', 'itemID', 'order', 'brand', 'manufacturer',\n",
       "       'customerRating', 'category1', 'category2', 'category3',\n",
       "       'recommendedRetailPrice', 'item_1', 'item_2', 'item_4',\n",
       "       'dist2firstvalueLeak', 'leak_cat3', 'total_new'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data.columns).index(\"dist2firstvalueLeak\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "[5]\ttrain's l1: 24.8487\ttrain's feval: 4.29048e+06\tval's l1: 48.3218\tval's feval: 271200\n",
      "[10]\ttrain's l1: 24.6151\ttrain's feval: 4.61705e+06\tval's l1: 47.8479\tval's feval: 304486\n",
      "[15]\ttrain's l1: 24.2905\ttrain's feval: 4.96764e+06\tval's l1: 47.0789\tval's feval: 331263\n",
      "[20]\ttrain's l1: 23.9994\ttrain's feval: 5.34257e+06\tval's l1: 46.4069\tval's feval: 373530\n",
      "[25]\ttrain's l1: 23.2281\ttrain's feval: 6.34816e+06\tval's l1: 44.0037\tval's feval: 507889\n",
      "[30]\ttrain's l1: 22.9181\ttrain's feval: 6.77466e+06\tval's l1: 43.133\tval's feval: 560501\n",
      "[35]\ttrain's l1: 22.5438\ttrain's feval: 7.29709e+06\tval's l1: 42.0321\tval's feval: 624908\n",
      "[40]\ttrain's l1: 22.4135\ttrain's feval: 7.4532e+06\tval's l1: 41.6251\tval's feval: 647617\n",
      "[45]\ttrain's l1: 22.3849\ttrain's feval: 7.46894e+06\tval's l1: 41.6281\tval's feval: 646772\n",
      "Early stopping, best iteration is:\n",
      "[40]\ttrain's l1: 22.4135\ttrain's feval: 7.4532e+06\tval's l1: 41.6251\tval's feval: 647617\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "params = {\n",
    "          \"objective\" : 'regression_l1',\n",
    "#           \"metric\" :\"rmse\",\n",
    "          \"learning_rate\" : 0.05,\n",
    "          'verbosity': 2,\n",
    "#           'max_depth': 6,\n",
    "#           'num_leaves': 4,\n",
    "          \"min_data_in_leaf\":1500\n",
    "         }\n",
    "# https://lightgbm.readthedocs.io/en/latest/Parameters.html\n",
    "\n",
    "\n",
    "ds_params = {\n",
    "#     'categorical_feature' : [3, 4, 5, 7, list(data.columns).index(\"dist2firstvalueLeak\"),],\n",
    "}\n",
    "lgbtrain = lgb.Dataset(X_train, label = y_train, weight=w_train, **ds_params)\n",
    "lgbfulltrain = lgb.Dataset(X_full_train, label = y_full_train, weight=w_full_train, **ds_params)\n",
    "lgbvalid = lgb.Dataset(X_val, label = y_val, weight=w_val, **ds_params)\n",
    "lgbsubmis = lgb.Dataset(X_sub, label = y_sub, weight=w_sub, **ds_params)\n",
    "\n",
    "num_round = 1000\n",
    "lgb_model = lgb.train(params,\n",
    "                  lgbtrain,\n",
    "                  num_round,\n",
    "                  valid_sets = [lgbtrain, lgbvalid],\n",
    "                  valid_names = ['train', 'val'],\n",
    "                  verbose_eval=5,\n",
    "                  early_stopping_rounds=5,\n",
    "                  feval = feval_lgbm,\n",
    "#                   fobj = objective,\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "694935.078"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = lgb_model.predict(X_sub, num_iteration=lgb_model.best_iteration).astype(int)\n",
    "evaluate(prediction, y_sub, w_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\ttrain's l1: 25.8364\ttrain's feval: 4.56168e+06\n",
      "[10]\ttrain's l1: 25.5888\ttrain's feval: 4.93825e+06\n",
      "[15]\ttrain's l1: 25.1633\ttrain's feval: 5.49753e+06\n",
      "[20]\ttrain's l1: 24.6177\ttrain's feval: 6.20721e+06\n",
      "[25]\ttrain's l1: 23.9284\ttrain's feval: 7.13715e+06\n",
      "[30]\ttrain's l1: 23.5276\ttrain's feval: 7.65153e+06\n",
      "[35]\ttrain's l1: 23.1251\ttrain's feval: 8.29038e+06\n",
      "[40]\ttrain's l1: 22.9386\ttrain's feval: 8.50625e+06\n"
     ]
    }
   ],
   "source": [
    "lgb_model_sub = lgb.train(params,\n",
    "                  lgbfulltrain,\n",
    "                  lgb_model.best_iteration,\n",
    "                  valid_sets = [lgbfulltrain],\n",
    "                  valid_names = ['train'],\n",
    "                  verbose_eval=5,\n",
    "                  early_stopping_rounds=None,\n",
    "                 feval = feval_lgbm,\n",
    "#                   fobj = objective,\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "739717.054"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = lgb_model_sub.predict(X_sub, num_iteration=80).astype(int)\n",
    "evaluate(prediction, y_sub, w_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoost, CatBoostRegressor, Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class feval_cat(object):\n",
    "    def get_final_error(self, error, weight):\n",
    "        # return error / (weight + 1e-38)\n",
    "        return error\n",
    "\n",
    "    def is_max_optimal(self):\n",
    "        return True\n",
    "\n",
    "    def evaluate(self, approxes, target, simulationPrice):\n",
    "#         global smthing\n",
    "#         smthing = [approxes, target, simulationPrice]\n",
    "        prediction = np.array(approxes[0]).astype(int)\n",
    "        target = np.array(target).astype(int)\n",
    "        simulationPrice = np.array(simulationPrice)\n",
    "        score = np.sum((prediction - np.maximum(prediction - target, 0) * 1.6)  * simulationPrice)\n",
    "#         print('score', score)\n",
    "#         print(approxes, type(target), type(simulationPrice))\n",
    "        return score, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 4553062.6628147\ttest: 4553062.6628147\ttest1: 254199.4882493\tbest: 254199.4882493 (0)\ttotal: 66.8ms\tremaining: 1m 6s\n",
      "1:\tlearn: 5080532.9513628\ttest: 5080532.9513628\ttest1: 342110.4841304\tbest: 342110.4841304 (1)\ttotal: 81.7ms\tremaining: 40.7s\n",
      "2:\tlearn: 5324451.3578394\ttest: 5324451.3578394\ttest1: 444157.7189374\tbest: 444157.7189374 (2)\ttotal: 92.7ms\tremaining: 30.8s\n",
      "3:\tlearn: 5651841.3145368\ttest: 5651841.3145368\ttest1: 493705.1290571\tbest: 493705.1290571 (3)\ttotal: 104ms\tremaining: 25.9s\n",
      "4:\tlearn: 5646189.5222374\ttest: 5646189.5222374\ttest1: 554045.4149854\tbest: 554045.4149854 (4)\ttotal: 118ms\tremaining: 23.4s\n",
      "5:\tlearn: 5905600.7724218\ttest: 5905600.7724218\ttest1: 611343.0728264\tbest: 611343.0728264 (5)\ttotal: 128ms\tremaining: 21.3s\n",
      "6:\tlearn: 6219821.4223866\ttest: 6219821.4223866\ttest1: 654614.1268941\tbest: 654614.1268941 (6)\ttotal: 140ms\tremaining: 19.8s\n",
      "7:\tlearn: 6485456.9865360\ttest: 6485456.9865360\ttest1: 678919.5469258\tbest: 678919.5469258 (7)\ttotal: 151ms\tremaining: 18.7s\n",
      "8:\tlearn: 6445070.2099257\ttest: 6445070.2099257\ttest1: 705336.6127045\tbest: 705336.6127045 (8)\ttotal: 166ms\tremaining: 18.3s\n",
      "9:\tlearn: 6781719.5143077\ttest: 6781719.5143077\ttest1: 713860.4626192\tbest: 713860.4626192 (9)\ttotal: 179ms\tremaining: 17.7s\n",
      "10:\tlearn: 6896714.2412247\ttest: 6896714.2412247\ttest1: 725784.5567901\tbest: 725784.5567901 (10)\ttotal: 190ms\tremaining: 17.1s\n",
      "11:\tlearn: 7244486.1442662\ttest: 7244486.1442662\ttest1: 756800.0627589\tbest: 756800.0627589 (11)\ttotal: 202ms\tremaining: 16.6s\n",
      "12:\tlearn: 7382822.8692420\ttest: 7382822.8692420\ttest1: 780387.0745336\tbest: 780387.0745336 (12)\ttotal: 213ms\tremaining: 16.2s\n",
      "13:\tlearn: 7592370.1555382\ttest: 7592370.1555382\ttest1: 786546.0785674\tbest: 786546.0785674 (13)\ttotal: 225ms\tremaining: 15.8s\n",
      "14:\tlearn: 7499871.2192375\ttest: 7499871.2192375\ttest1: 799522.7826946\tbest: 799522.7826946 (14)\ttotal: 236ms\tremaining: 15.5s\n",
      "15:\tlearn: 7597674.1673662\ttest: 7597674.1673662\ttest1: 817086.6827186\tbest: 817086.6827186 (15)\ttotal: 247ms\tremaining: 15.2s\n",
      "16:\tlearn: 7552698.4564851\ttest: 7552698.4564851\ttest1: 828982.9085916\tbest: 828982.9085916 (16)\ttotal: 259ms\tremaining: 15s\n",
      "17:\tlearn: 7697558.7923092\ttest: 7697558.7923092\ttest1: 830637.0227101\tbest: 830637.0227101 (17)\ttotal: 270ms\tremaining: 14.7s\n",
      "18:\tlearn: 7662165.4328519\ttest: 7662165.4328519\ttest1: 851672.4507282\tbest: 851672.4507282 (18)\ttotal: 281ms\tremaining: 14.5s\n",
      "19:\tlearn: 7756013.2850027\ttest: 7756013.2850027\ttest1: 848806.6385813\tbest: 851672.4507282 (18)\ttotal: 300ms\tremaining: 14.7s\n",
      "20:\tlearn: 7776840.2573695\ttest: 7776840.2573695\ttest1: 856505.4266439\tbest: 856505.4266439 (20)\ttotal: 311ms\tremaining: 14.5s\n",
      "21:\tlearn: 7897953.6019169\ttest: 7897953.6019169\ttest1: 861889.4527036\tbest: 861889.4527036 (21)\ttotal: 325ms\tremaining: 14.5s\n",
      "22:\tlearn: 8064775.7358651\ttest: 8064775.7358651\ttest1: 858164.3906199\tbest: 861889.4527036 (21)\ttotal: 336ms\tremaining: 14.3s\n",
      "23:\tlearn: 8079172.3395568\ttest: 8079172.3395568\ttest1: 860812.5505911\tbest: 861889.4527036 (21)\ttotal: 348ms\tremaining: 14.1s\n",
      "24:\tlearn: 8018266.6736744\ttest: 8018266.6736744\ttest1: 863612.9464277\tbest: 863612.9464277 (24)\ttotal: 360ms\tremaining: 14s\n",
      "25:\tlearn: 8081682.2291684\ttest: 8081682.2291684\ttest1: 873617.6863599\tbest: 873617.6863599 (25)\ttotal: 371ms\tremaining: 13.9s\n",
      "26:\tlearn: 8069914.6474191\ttest: 8069914.6474191\ttest1: 881650.5303924\tbest: 881650.5303924 (26)\ttotal: 382ms\tremaining: 13.8s\n",
      "27:\tlearn: 8192367.9893197\ttest: 8192367.9893197\ttest1: 886949.7423818\tbest: 886949.7423818 (27)\ttotal: 393ms\tremaining: 13.7s\n",
      "28:\tlearn: 8264824.9747319\ttest: 8264824.9747319\ttest1: 873108.3660784\tbest: 886949.7423818 (27)\ttotal: 404ms\tremaining: 13.5s\n",
      "29:\tlearn: 8290468.5088688\ttest: 8290468.5088688\ttest1: 877462.8021353\tbest: 886949.7423818 (27)\ttotal: 416ms\tremaining: 13.4s\n",
      "30:\tlearn: 8258488.8351029\ttest: 8258488.8351029\ttest1: 879645.2141341\tbest: 886949.7423818 (27)\ttotal: 426ms\tremaining: 13.3s\n",
      "31:\tlearn: 8321653.6847999\ttest: 8321653.6847999\ttest1: 880039.6620343\tbest: 886949.7423818 (27)\ttotal: 438ms\tremaining: 13.2s\n",
      "32:\tlearn: 8380584.0151445\ttest: 8380584.0151445\ttest1: 879592.7160082\tbest: 886949.7423818 (27)\ttotal: 449ms\tremaining: 13.2s\n",
      "Stopped by overfitting detector  (5 iterations wait)\n",
      "\n",
      "bestTest = 886949.7424\n",
      "bestIteration = 27\n",
      "\n",
      "Shrink model to first 28 iterations.\n"
     ]
    }
   ],
   "source": [
    "ds_params = {\n",
    "#     'cat_features' : [8, 9, 10],\n",
    "}\n",
    "train_pool = Pool(X_train, label = y_train, weight = w_train, **ds_params)\n",
    "trainfull_pool = Pool(X_full_train, label = y_full_train, weight = w_full_train, **ds_params)\n",
    "val_pool = Pool(X_val, label = y_val, weight = w_val, **ds_params)\n",
    "sub_pool = Pool(X_sub, label = y_sub, weight = w_sub, **ds_params)\n",
    "\n",
    "\n",
    "model = CatBoostRegressor(\n",
    "#     iterations = 2,\n",
    "    depth=7, \n",
    "    learning_rate=0.1, \n",
    "    loss_function='MAE',\n",
    "    early_stopping_rounds=5,\n",
    "    eval_metric = feval_cat(),\n",
    "    thread_count=-1,\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_pool,\n",
    "    eval_set=[train_pool, val_pool],\n",
    "#     logging_level='Verbose',  # you can uncomment this for text output\n",
    "\n",
    ");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "932333.0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict(X_sub, ntree_end = model.best_iteration_).astype(int)\n",
    "evaluate(prediction, y_sub, w_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_iteration_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 4877921.8366379\ttest: 4877921.8366379\tbest: 4877921.8366379 (0)\ttotal: 15.1ms\tremaining: 392ms\n",
      "1:\tlearn: 5467868.6152376\ttest: 5467868.6152376\tbest: 5467868.6152376 (1)\ttotal: 31.2ms\tremaining: 390ms\n",
      "2:\tlearn: 5820571.7668651\ttest: 5820571.7668651\tbest: 5820571.7668651 (2)\ttotal: 46.7ms\tremaining: 373ms\n",
      "3:\tlearn: 6179459.8011581\ttest: 6179459.8011581\tbest: 6179459.8011581 (3)\ttotal: 66.2ms\tremaining: 381ms\n",
      "4:\tlearn: 6227764.6548927\ttest: 6227764.6548927\tbest: 6227764.6548927 (4)\ttotal: 82.1ms\tremaining: 361ms\n",
      "5:\tlearn: 6541577.2749894\ttest: 6541577.2749894\tbest: 6541577.2749894 (5)\ttotal: 93.4ms\tremaining: 327ms\n",
      "6:\tlearn: 6889170.2589114\ttest: 6889170.2589114\tbest: 6889170.2589114 (6)\ttotal: 105ms\tremaining: 300ms\n",
      "7:\tlearn: 7232641.9293438\ttest: 7232641.9293438\tbest: 7232641.9293438 (7)\ttotal: 122ms\tremaining: 289ms\n",
      "8:\tlearn: 7167455.4202043\ttest: 7167455.4202043\tbest: 7232641.9293438 (7)\ttotal: 135ms\tremaining: 269ms\n",
      "9:\tlearn: 7528826.7488443\ttest: 7528826.7488443\tbest: 7528826.7488443 (9)\ttotal: 145ms\tremaining: 247ms\n",
      "10:\tlearn: 7673321.1577955\ttest: 7673321.1577955\tbest: 7673321.1577955 (10)\ttotal: 162ms\tremaining: 235ms\n",
      "11:\tlearn: 8117443.6748375\ttest: 8117443.6748375\tbest: 8117443.6748375 (11)\ttotal: 173ms\tremaining: 216ms\n",
      "12:\tlearn: 8257658.1934644\ttest: 8257658.1934644\tbest: 8257658.1934644 (12)\ttotal: 184ms\tremaining: 198ms\n",
      "13:\tlearn: 8403516.8713467\ttest: 8403516.8713467\tbest: 8403516.8713467 (13)\ttotal: 197ms\tremaining: 183ms\n",
      "14:\tlearn: 8408849.3599370\ttest: 8408849.3599370\tbest: 8408849.3599370 (14)\ttotal: 208ms\tremaining: 166ms\n",
      "15:\tlearn: 8545392.6744892\ttest: 8545392.6744892\tbest: 8545392.6744892 (15)\ttotal: 222ms\tremaining: 153ms\n",
      "16:\tlearn: 8513201.6467392\ttest: 8513201.6467392\tbest: 8545392.6744892 (15)\ttotal: 243ms\tremaining: 143ms\n",
      "17:\tlearn: 8766564.6635914\ttest: 8766564.6635914\tbest: 8766564.6635914 (17)\ttotal: 267ms\tremaining: 133ms\n",
      "18:\tlearn: 8766698.0578040\ttest: 8766698.0578040\tbest: 8766698.0578040 (18)\ttotal: 282ms\tremaining: 119ms\n",
      "19:\tlearn: 8832510.2100311\ttest: 8832510.2100311\tbest: 8832510.2100311 (19)\ttotal: 296ms\tremaining: 104ms\n",
      "20:\tlearn: 8895871.3161299\ttest: 8895871.3161299\tbest: 8895871.3161299 (20)\ttotal: 309ms\tremaining: 88.2ms\n",
      "21:\tlearn: 9017885.4968666\ttest: 9017885.4968666\tbest: 9017885.4968666 (21)\ttotal: 320ms\tremaining: 72.8ms\n",
      "22:\tlearn: 9161831.8067192\ttest: 9161831.8067192\tbest: 9161831.8067192 (22)\ttotal: 332ms\tremaining: 57.7ms\n",
      "23:\tlearn: 9171479.0628551\ttest: 9171479.0628551\tbest: 9171479.0628551 (23)\ttotal: 342ms\tremaining: 42.8ms\n",
      "24:\tlearn: 9115696.7648451\ttest: 9115696.7648451\tbest: 9171479.0628551 (23)\ttotal: 353ms\tremaining: 28.3ms\n",
      "25:\tlearn: 9254987.6007574\ttest: 9254987.6007574\tbest: 9254987.6007574 (25)\ttotal: 365ms\tremaining: 14ms\n",
      "26:\tlearn: 9176336.5101561\ttest: 9176336.5101561\tbest: 9254987.6007574 (25)\ttotal: 376ms\tremaining: 0us\n",
      "\n",
      "bestTest = 9254987.601\n",
      "bestIteration = 25\n",
      "\n",
      "Shrink model to first 26 iterations.\n"
     ]
    }
   ],
   "source": [
    "cat_sub = CatBoostRegressor(**{**model.get_params(), \"iterations\" : model.best_iteration_})\n",
    "cat_sub.fit(\n",
    "    trainfull_pool,\n",
    "    eval_set=[trainfull_pool],\n",
    "#     logging_level='Verbose',  # you can uncomment this for text output\n",
    "\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "802618.406"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = cat_sub.predict(X_sub, ntree_end = cat_sub.best_iteration_).astype(int)\n",
    "evaluate(prediction, y_sub, w_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1066921.946"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_w = .2\n",
    "lgb_w = .2\n",
    "xgb_w = 1\n",
    "ensemble = model.predict(X_sub, ntree_end = model.best_iteration_) * cat_w\n",
    "ensemble += lgb_model.predict(X_sub, num_iteration=lgb_model.best_iteration) * lgb_w\n",
    "ensemble += bst.predict(dsub, ntree_limit=bst.best_ntree_limit) * xgb_w\n",
    "ensemble = ensemble / (cat_w + lgb_w + xgb_w)\n",
    "evaluate(ensemble.astype(int), y_sub, w_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.metrics import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 778,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train, y_train, w_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -25798195.590995364\n",
      "test -2082818.3608716822\n",
      "sub -2279245.550001612\n"
     ]
    }
   ],
   "source": [
    "print('train', evaluate(lr.predict(X_train), y_train, w_train))\n",
    "print('test', evaluate(lr.predict(X_val), y_val, w_val))\n",
    "print('sub', evaluate(lr.predict(X_sub), y_sub, w_sub))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fazer feature que pega o percentil de quando o item deu de dinheiro dentro de uma categoria\n",
    "# fazer features que pega dist de atual at o pico mais alto\n",
    "# dist do maior pico pro segundo\n",
    "# min(dist(terceiro, primeiro), dist(terceiro, segundo))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
