{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "infos = pd.read_csv('../../data/infos.csv', sep = '|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = pd.read_csv('../../data/items.csv', sep = '|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = pd.read_csv('../../data/orders.csv', sep = '|', parse_dates=['time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Creating the structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = orders.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weekpair'] = (df.time.dt.dayofyear + 1) // 14 - 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "npairs = df.weekpair.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of items: 10463\n",
      "expected number of instances: 136019\n"
     ]
    }
   ],
   "source": [
    "n_items = items['itemID'].nunique()\n",
    "print('total number of items:', n_items)\n",
    "print('expected number of instances:', n_items * npairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi = pd.MultiIndex.from_product([range(-npairs, 0 + 1), items['itemID']], names=['weekpair', 'itemID'])\n",
    "data_temp = pd.DataFrame(index = mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_temp = data_temp.join(df.groupby(['weekpair', 'itemID'])[['order']].sum(), how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_temp.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order    14\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_temp.groupby('itemID').count().min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Creating features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gbagg(data, group_cols, targeted_cols, out_names, function, as_index = False):\n",
    "  \n",
    "    X = data.values\n",
    "    col = {c : i for i, c in enumerate(data.columns)}\n",
    "\n",
    "    # values that are going to calculated\n",
    "    new_feat = []\n",
    "    \n",
    "    # numbers of the columns\n",
    "    gcols = [col[c] for c in group_cols]\n",
    "    tcols = [col[c] for c in targeted_cols]\n",
    "    \n",
    "    interval = None\n",
    "    a = None\n",
    "    i = 0\n",
    "    while i < len(X):\n",
    "        a = X[i, gcols]\n",
    "\n",
    "        # find the whole interval of this group\n",
    "        j = i\n",
    "        while j < len(X):\n",
    "            if (X[j, gcols] != a).any():\n",
    "                break\n",
    "            j += 1\n",
    "        interval = X[i:j, tcols]\n",
    "\n",
    "        # apply function on interval, save in new feature\n",
    "        output = function(interval)\n",
    "        new_feat.append(output)\n",
    "\n",
    "        # go to next group\n",
    "        i = j\n",
    "    \n",
    "    idx = data.groupby(group_cols).size().index # this is actually fast...\n",
    "    out_df = pd.DataFrame(new_feat, columns = out_names, index = idx)\n",
    "        \n",
    "    if not as_index:\n",
    "        out_df.reset_index(inplace = True)\n",
    "        \n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gbtransf(data, group_cols, targeted_cols, out_names, function, params = dict()):\n",
    "  \n",
    "    X = data.values\n",
    "    col = {c : i for i, c in enumerate(data.columns)}\n",
    "\n",
    "    # values that are going to calculated\n",
    "    new_feat = np.zeros((len(data), len(out_names)))\n",
    "    \n",
    "    # numbers of the columns\n",
    "    gcols = [col[c] for c in group_cols]\n",
    "    tcols = [col[c] for c in targeted_cols]\n",
    "    \n",
    "    interval = None\n",
    "    a = None\n",
    "    i = 0\n",
    "    while i < len(X):\n",
    "        a = X[i, gcols]\n",
    "\n",
    "        # find the whole interval of this group\n",
    "        j = i\n",
    "        while j < len(X):\n",
    "            if (X[j, gcols] != a).any():\n",
    "                break\n",
    "            j += 1\n",
    "        interval = X[i:j, tcols]\n",
    "\n",
    "        # apply function on interval, save in new feature\n",
    "        output = function(interval, **params)\n",
    "        new_feat[i:j] = output\n",
    "\n",
    "        # go to next group\n",
    "        i = j\n",
    "    \n",
    "    out_df = pd.DataFrame(new_feat, columns = out_names, index = data.index)\n",
    "        \n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_and_2n_window(x, ws):\n",
    "#     out = pd.DataFrame(x)\n",
    "#     out = out.shift()\n",
    "#     out = out.rolling(2 ** n).mean()\n",
    "\n",
    "    shifted = np.zeros_like(x) # output\n",
    "    shifted[1:] = x[:-1] # shift\n",
    "    out = np.zeros_like(x, dtype = float)\n",
    "    \n",
    "    # rolling mean\n",
    "    total = shifted[:ws].sum()\n",
    "    out[ws - 1] = total / ws\n",
    "    for i in range(ws, len(out)):\n",
    "        total = total - shifted[i - ws] + shifted[i]\n",
    "        out[i] = total / ws\n",
    "    out[:ws] = np.NaN # maybe ws -1 should be NaN as well for receiving one NaN value when ws > 1\n",
    "    # out[0] = np.NaN # this is always NaN for a shift of 1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_temp.reset_index()\n",
    "data = pd.merge(data, items, on = 'itemID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data[\"weekpair\"] == 0, \"order\"] = 1 # facilita para fazer feature que detecta item novo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values(['itemID', 'weekpair'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gbtransf(data, ['itemID', 'weekpair'], ['order'], ['out'], lambda x : np.ones_like(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, nan, 1.5, 2.5, 3.5, 4.5])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shift_and_2n_window(np.array([1 , 2, 3, 4, 5, 6]), 2 ** 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [('itemID', 'item')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "itemID\n"
     ]
    }
   ],
   "source": [
    "for f, name in features:\n",
    "    print(f)\n",
    "    new_feature_block = pd.DataFrame()\n",
    "    for n in range(3):\n",
    "        new_f = gbtransf(data, ['itemID'], ['order'], ['out'], shift_and_2n_window, {'ws' : 2 ** n})\n",
    "        new_feature_block['%s_%d' % (name, 2 ** n)] = new_f['out']\n",
    "#     data = pd.merge(data, new_feature_block.reset_index(), on = [f, 'weekpair'])\n",
    "    data = pd.concat([data, new_feature_block], axis =  1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"diff\"] = data.groupby(\"order\")[\"order\"].shift()\n",
    "data[\"diff\"] = data.groupby(\"order\")[\"diff\"].diff()\n",
    "data[\"diff2\"] = data.groupby(\"order\")[\"diff\"].diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "weekpair                  146482\n",
       "itemID                    146482\n",
       "order                     146482\n",
       "brand                     146482\n",
       "manufacturer              146482\n",
       "customerRating            146482\n",
       "category1                 146482\n",
       "category2                 146482\n",
       "category3                 146482\n",
       "recommendedRetailPrice    146482\n",
       "item_1                    136019\n",
       "item_2                    125556\n",
       "item_4                    104630\n",
       "diff                      144694\n",
       "diff2                     144113\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count() # the larger the window, more NaN are expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist2firstvalueLeak(x):\n",
    "    out = np.zeros_like(x, dtype = float)\n",
    "    for i in range(len(x)):\n",
    "        if x[i] != 0:\n",
    "            out[i] = 1\n",
    "            break\n",
    "#         else:\n",
    "#             out[i] = -9999\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist2firstvalueLeak(np.array([0 , 0, 3, 0, 5, 6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values(['itemID', 'weekpair'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['dist2firstvalueLeak'] = gbtransf(data, ['itemID'], ['order'], ['out'], dist2firstvalueLeak)['out']\n",
    "# data['dist2lastpeak'] = gbtransf(data, ['itemID'], ['order'], ['out'], dist2lastpeak)['out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_cat = \"manufacturer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sla = data.groupby([\"weekpair\", the_cat])[\"dist2firstvalueLeak\"].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sla = sla.rename(columns={\"dist2firstvalueLeak\" : \"leak_cat3\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acho que mudou nada... opa, mudou sim\n",
    "data = pd.merge(data, sla, on = [\"weekpair\", the_cat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"total_new\"] = data[\"weekpair\"].map(data.groupby(\"weekpair\")[\"dist2firstvalueLeak\"].sum().to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_trans = df.groupby([\"weekpair\", \"itemID\"]).size().reset_index().rename(columns = {0 : \"total_trans\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_week = infos[[\"itemID\"]].copy()\n",
    "new_week[\"weekpair\"] = 0\n",
    "new_week[\"total_trans\"] = 0\n",
    "total_trans = pd.concat([total_trans, new_week], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_trans.sort_values(\"weekpair\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_trans[\"total_trans\"] = total_trans.groupby(\"itemID\")[\"total_trans\"].shift()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(data, total_trans, on = [\"weekpair\", \"itemID\"], how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Min Expected Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(prediction, target, simulationPrice):\n",
    "    return np.sum((prediction - np.maximum(prediction - target, 0) * 1.6)  * simulationPrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_prop(prediction, target, simulationPrice):\n",
    "    max_profit = np.sum((target)  * simulationPrice)\n",
    "    return np.sum((prediction - np.maximum(prediction - target, 0) * 1.6)  * simulationPrice) / max_profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max expected rmse\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "# pred = data.loc[1:12].groupby('itemID')['order'].mean().sort_index()\n",
    "# target_week = data.loc[13:, 'order'].reset_index(level = 0, drop = True).sort_index()\n",
    "# mse(target_week, pred) ** .5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  - Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = infos.set_index('itemID')['simulationPrice'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['weekpair', 'itemID', 'order', 'brand', 'manufacturer',\n",
       "       'customerRating', 'category1', 'category2', 'category3',\n",
       "       'recommendedRetailPrice', 'item_1', 'item_2', 'item_4', 'diff', 'diff2',\n",
       "       'dist2firstvalueLeak', 'leak_cat3', 'total_new', 'total_trans'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'brand', 'category3'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove = set([\n",
    "#     \"weekpair\",\n",
    "    \"brand\",\n",
    "#     \"manufacturer\",\n",
    "#     \"customerRating\",\n",
    "#     \"category1\",\n",
    "#     \"category2\",\n",
    "    \"category3\",\n",
    "#     \"recommendedRetailPrice\", # very important!\n",
    "#     \"total_new\",\n",
    "#     \"total_trans\", # the master!\n",
    "])\n",
    "remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_cols = set(list(data.columns)) - remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_data = data\n",
    "filtered_data = data.query(\"dist2firstvalueLeak != 1\")[sel_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146482, 136019)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data), len(filtered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_week = 0\n",
    "train = filtered_data.query('-13 <= weekpair <= (@sub_week - 2)').reset_index(drop = True)\n",
    "full_train = filtered_data.query('-13 <= weekpair <= (@sub_week - 1)').reset_index(drop = True)\n",
    "val = filtered_data.query('weekpair == (@sub_week - 1)').reset_index(drop = True)\n",
    "sub = filtered_data.query('weekpair == (@sub_week)').reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub[\"weekpair\"] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116444, 9735, 9840)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(val), len(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train.pop('order').values\n",
    "y_full_train = full_train.pop('order').values\n",
    "y_val = val.pop('order').values\n",
    "y_sub = sub.pop('order').values\n",
    "\n",
    "w_train = train['itemID'].map(weights)\n",
    "w_full_train = full_train['itemID'].map(weights)\n",
    "w_val = val['itemID'].map(weights)\n",
    "w_sub = sub['itemID'].map(weights)\n",
    "\n",
    "i_train = train.pop(\"itemID\")\n",
    "i_full_train = full_train.pop(\"itemID\")\n",
    "i_val = val.pop(\"itemID\")\n",
    "i_sub = sub.pop(\"itemID\")\n",
    "\n",
    "X_train = train.values\n",
    "X_full_train = full_train.values\n",
    "X_val = val.values\n",
    "X_sub = sub.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom objective\n",
    "\n",
    "def gradient(prediction, dtrain):\n",
    "    y = dtrain.get_label()\n",
    "#     prediction.astype(int)\n",
    "#     prediction = np.minimum(prediction.astype(int), 1)\n",
    "    return -2 * (prediction - np.maximum(prediction - y, 0) * 1.6) * (1 - (prediction > y) * 1.6)\n",
    "\n",
    "def hessian(prediction, dtrain):\n",
    "    y = dtrain.get_label()\n",
    "#     prediction.prediction(int)\n",
    "#     prediction = np.minimum(prediction.astype(int), 1)\n",
    "    return -2 * (1 - (prediction > y) * 1.6) ** 2\n",
    "\n",
    "def objective(prediction, dtrain):\n",
    "    w = dtrain.get_weight()\n",
    "    grad = gradient(prediction, dtrain) * w\n",
    "    hess = hessian(prediction, dtrain) * w\n",
    "    return grad, hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom feval\n",
    "\n",
    "def feval(prediction, dtrain):\n",
    "    prediction = prediction.astype(int)\n",
    "#     predt = np.minimum(predt.astype(int), 1)\n",
    "    target = dtrain.get_label()\n",
    "    simulationPrice = dtrain.get_weight()\n",
    "    max_profit = np.sum((target) * simulationPrice)\n",
    "    return 'feval', np.sum((prediction - np.maximum(prediction - target, 0) * 1.6)  * simulationPrice) / max_profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-feval:0.00125\tval-feval:0.00136\n",
      "Multiple eval metrics have been passed: 'val-feval' will be used for early stopping.\n",
      "\n",
      "Will train until val-feval hasn't improved in 10 rounds.\n",
      "[1]\ttrain-feval:0.00489\tval-feval:0.00476\n",
      "[2]\ttrain-feval:0.00864\tval-feval:0.01058\n",
      "[3]\ttrain-feval:0.01211\tval-feval:0.01453\n",
      "[4]\ttrain-feval:0.01556\tval-feval:0.01806\n",
      "[5]\ttrain-feval:0.01931\tval-feval:0.02136\n",
      "[6]\ttrain-feval:0.02356\tval-feval:0.02624\n",
      "[7]\ttrain-feval:0.02572\tval-feval:0.02932\n",
      "[8]\ttrain-feval:0.02938\tval-feval:0.03350\n",
      "[9]\ttrain-feval:0.03112\tval-feval:0.03563\n",
      "[10]\ttrain-feval:0.03274\tval-feval:0.03755\n",
      "[11]\ttrain-feval:0.03674\tval-feval:0.03984\n",
      "[12]\ttrain-feval:0.04087\tval-feval:0.04574\n",
      "[13]\ttrain-feval:0.04403\tval-feval:0.04901\n",
      "[14]\ttrain-feval:0.04696\tval-feval:0.05170\n",
      "[15]\ttrain-feval:0.04809\tval-feval:0.05366\n",
      "[16]\ttrain-feval:0.05045\tval-feval:0.05498\n",
      "[17]\ttrain-feval:0.05139\tval-feval:0.05583\n",
      "[18]\ttrain-feval:0.05929\tval-feval:0.06457\n",
      "[19]\ttrain-feval:0.06057\tval-feval:0.06549\n",
      "[20]\ttrain-feval:0.06175\tval-feval:0.06657\n",
      "[21]\ttrain-feval:0.06237\tval-feval:0.06737\n",
      "[22]\ttrain-feval:0.06398\tval-feval:0.06911\n",
      "[23]\ttrain-feval:0.06538\tval-feval:0.06957\n",
      "[24]\ttrain-feval:0.06629\tval-feval:0.07032\n",
      "[25]\ttrain-feval:0.06703\tval-feval:0.07113\n",
      "[26]\ttrain-feval:0.06782\tval-feval:0.07215\n",
      "[27]\ttrain-feval:0.07134\tval-feval:0.07746\n",
      "[28]\ttrain-feval:0.07237\tval-feval:0.07923\n",
      "[29]\ttrain-feval:0.07357\tval-feval:0.07984\n",
      "[30]\ttrain-feval:0.07431\tval-feval:0.07980\n",
      "[31]\ttrain-feval:0.07476\tval-feval:0.08017\n",
      "[32]\ttrain-feval:0.07518\tval-feval:0.08034\n",
      "[33]\ttrain-feval:0.07631\tval-feval:0.08123\n",
      "[34]\ttrain-feval:0.07921\tval-feval:0.08377\n",
      "[35]\ttrain-feval:0.08028\tval-feval:0.08435\n",
      "[36]\ttrain-feval:0.08209\tval-feval:0.08619\n",
      "[37]\ttrain-feval:0.08270\tval-feval:0.08624\n",
      "[38]\ttrain-feval:0.08424\tval-feval:0.08749\n",
      "[39]\ttrain-feval:0.08504\tval-feval:0.08856\n",
      "[40]\ttrain-feval:0.08533\tval-feval:0.08856\n",
      "[41]\ttrain-feval:0.08570\tval-feval:0.08931\n",
      "[42]\ttrain-feval:0.08611\tval-feval:0.08947\n",
      "[43]\ttrain-feval:0.08651\tval-feval:0.08958\n",
      "[44]\ttrain-feval:0.08858\tval-feval:0.09070\n",
      "[45]\ttrain-feval:0.08913\tval-feval:0.09149\n",
      "[46]\ttrain-feval:0.08942\tval-feval:0.09162\n",
      "[47]\ttrain-feval:0.09050\tval-feval:0.09169\n",
      "[48]\ttrain-feval:0.09093\tval-feval:0.09207\n",
      "[49]\ttrain-feval:0.09162\tval-feval:0.09267\n",
      "[50]\ttrain-feval:0.09228\tval-feval:0.09306\n",
      "[51]\ttrain-feval:0.09298\tval-feval:0.09345\n",
      "[52]\ttrain-feval:0.09373\tval-feval:0.09393\n",
      "[53]\ttrain-feval:0.09472\tval-feval:0.09445\n",
      "[54]\ttrain-feval:0.09506\tval-feval:0.09484\n",
      "[55]\ttrain-feval:0.09577\tval-feval:0.09587\n",
      "[56]\ttrain-feval:0.09653\tval-feval:0.09739\n",
      "[57]\ttrain-feval:0.09847\tval-feval:0.09976\n",
      "[58]\ttrain-feval:0.10158\tval-feval:0.10288\n",
      "[59]\ttrain-feval:0.10216\tval-feval:0.10372\n",
      "[60]\ttrain-feval:0.10231\tval-feval:0.10367\n",
      "[61]\ttrain-feval:0.10282\tval-feval:0.10402\n",
      "[62]\ttrain-feval:0.10320\tval-feval:0.10422\n",
      "[63]\ttrain-feval:0.10342\tval-feval:0.10453\n",
      "[64]\ttrain-feval:0.10381\tval-feval:0.10468\n",
      "[65]\ttrain-feval:0.10454\tval-feval:0.10503\n",
      "[66]\ttrain-feval:0.10502\tval-feval:0.10521\n",
      "[67]\ttrain-feval:0.10548\tval-feval:0.10513\n",
      "[68]\ttrain-feval:0.10577\tval-feval:0.10546\n",
      "[69]\ttrain-feval:0.10592\tval-feval:0.10578\n",
      "[70]\ttrain-feval:0.10616\tval-feval:0.10629\n",
      "[71]\ttrain-feval:0.10670\tval-feval:0.10646\n",
      "[72]\ttrain-feval:0.10683\tval-feval:0.10610\n",
      "[73]\ttrain-feval:0.10714\tval-feval:0.10737\n",
      "[74]\ttrain-feval:0.10744\tval-feval:0.10690\n",
      "[75]\ttrain-feval:0.10815\tval-feval:0.10726\n",
      "[76]\ttrain-feval:0.10826\tval-feval:0.10825\n",
      "[77]\ttrain-feval:0.10886\tval-feval:0.10851\n",
      "[78]\ttrain-feval:0.10923\tval-feval:0.10854\n",
      "[79]\ttrain-feval:0.10926\tval-feval:0.10882\n",
      "[80]\ttrain-feval:0.10963\tval-feval:0.10840\n",
      "[81]\ttrain-feval:0.11065\tval-feval:0.10955\n",
      "[82]\ttrain-feval:0.11073\tval-feval:0.11000\n",
      "[83]\ttrain-feval:0.11081\tval-feval:0.10989\n",
      "[84]\ttrain-feval:0.11129\tval-feval:0.11015\n",
      "[85]\ttrain-feval:0.11143\tval-feval:0.11014\n",
      "[86]\ttrain-feval:0.11160\tval-feval:0.11001\n",
      "[87]\ttrain-feval:0.11172\tval-feval:0.11045\n",
      "[88]\ttrain-feval:0.11202\tval-feval:0.10957\n",
      "[89]\ttrain-feval:0.11221\tval-feval:0.11004\n",
      "[90]\ttrain-feval:0.11241\tval-feval:0.11113\n",
      "[91]\ttrain-feval:0.11240\tval-feval:0.11068\n",
      "[92]\ttrain-feval:0.11267\tval-feval:0.11188\n",
      "[93]\ttrain-feval:0.11300\tval-feval:0.11233\n",
      "[94]\ttrain-feval:0.11314\tval-feval:0.11228\n",
      "[95]\ttrain-feval:0.11382\tval-feval:0.11275\n",
      "[96]\ttrain-feval:0.11454\tval-feval:0.11256\n",
      "[97]\ttrain-feval:0.11463\tval-feval:0.11269\n",
      "[98]\ttrain-feval:0.11477\tval-feval:0.11281\n",
      "[99]\ttrain-feval:0.11483\tval-feval:0.11247\n",
      "[100]\ttrain-feval:0.11481\tval-feval:0.11237\n",
      "[101]\ttrain-feval:0.11488\tval-feval:0.11236\n",
      "[102]\ttrain-feval:0.11589\tval-feval:0.11355\n",
      "[103]\ttrain-feval:0.11605\tval-feval:0.11375\n",
      "[104]\ttrain-feval:0.11621\tval-feval:0.11368\n",
      "[105]\ttrain-feval:0.11634\tval-feval:0.11366\n",
      "[106]\ttrain-feval:0.11665\tval-feval:0.11373\n",
      "[107]\ttrain-feval:0.11725\tval-feval:0.11381\n",
      "[108]\ttrain-feval:0.11799\tval-feval:0.11500\n",
      "[109]\ttrain-feval:0.11859\tval-feval:0.11515\n",
      "[110]\ttrain-feval:0.11956\tval-feval:0.11575\n",
      "[111]\ttrain-feval:0.12018\tval-feval:0.11593\n",
      "[112]\ttrain-feval:0.12024\tval-feval:0.11561\n",
      "[113]\ttrain-feval:0.12068\tval-feval:0.11531\n",
      "[114]\ttrain-feval:0.12066\tval-feval:0.11563\n",
      "[115]\ttrain-feval:0.12077\tval-feval:0.11543\n",
      "[116]\ttrain-feval:0.12096\tval-feval:0.11544\n",
      "[117]\ttrain-feval:0.12151\tval-feval:0.11586\n",
      "[118]\ttrain-feval:0.12166\tval-feval:0.11580\n",
      "[119]\ttrain-feval:0.12237\tval-feval:0.11585\n",
      "[120]\ttrain-feval:0.12286\tval-feval:0.11627\n",
      "[121]\ttrain-feval:0.12409\tval-feval:0.11602\n",
      "[122]\ttrain-feval:0.12402\tval-feval:0.11608\n",
      "[123]\ttrain-feval:0.12415\tval-feval:0.11533\n",
      "[124]\ttrain-feval:0.12453\tval-feval:0.11349\n",
      "[125]\ttrain-feval:0.12482\tval-feval:0.11273\n",
      "[126]\ttrain-feval:0.12496\tval-feval:0.11262\n",
      "[127]\ttrain-feval:0.12602\tval-feval:0.11267\n",
      "[128]\ttrain-feval:0.12608\tval-feval:0.11256\n",
      "[129]\ttrain-feval:0.12650\tval-feval:0.11222\n",
      "[130]\ttrain-feval:0.12654\tval-feval:0.11239\n",
      "Stopping. Best iteration:\n",
      "[120]\ttrain-feval:0.12286\tval-feval:0.11627\n",
      "\n"
     ]
    }
   ],
   "source": [
    "missing = 0\n",
    "dtrain = xgb.DMatrix(X_train, y_train, w_train, missing = missing)\n",
    "dfulltrain = xgb.DMatrix(X_full_train, y_full_train, w_full_train, missing = missing)\n",
    "dval = xgb.DMatrix(X_val, y_val, w_val, missing = missing)\n",
    "dsub = xgb.DMatrix(X_sub, y_sub, w_sub, missing = missing)\n",
    "# specify parameters via map\n",
    "param = {\n",
    "    'max_depth':7,\n",
    "    'eta':0.005,\n",
    "    'objective':'reg:squarederror',\n",
    "    'disable_default_eval_metric': 1,\n",
    "    \"min_child_weight\" : 10000,\n",
    "    \n",
    "#     'tree_method' : 'gpu_hist',\n",
    "}\n",
    "num_round = 800\n",
    "bst = xgb.train(param, dtrain,\n",
    "                num_round,\n",
    "                early_stopping_rounds = 10,\n",
    "                evals = [(dtrain, 'train'), (dval, 'val')],\n",
    "#                 obj = objective,\n",
    "                feval = feval,\n",
    "                maximize = True,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2458791.9580000006, -2.0231528483317303)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = bst.predict(dsub, ntree_limit=bst.best_ntree_limit).astype(int)\n",
    "evaluate(prediction, y_sub, w_sub), evaluate_prop(prediction, y_sub, w_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211119, 104)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.sum(), len(np.unique(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst_sub = xgb.train(param, dfulltrain,\n",
    "    num_boost_round = bst.best_ntree_limit,\n",
    "    #                 obj = objective,\n",
    "    feval = feval, maximize = True,\n",
    "    evals = [(dfulltrain, 'ftrain')],\n",
    "    verbose_eval = False,\n",
    ")\n",
    "bst_sub.best_ntree_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2463317.2420000006, -2.026876360271942)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_old = bst_sub.predict(dsub, ntree_limit=bst_sub.best_ntree_limit).astype(int)\n",
    "evaluate(prediction_old, y_sub, w_sub), evaluate_prop(prediction_old, y_sub, w_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_preds = {item : pred for item, pred in zip(i_sub, prediction_old)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some other things below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1215326.8399999999"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max possible score\n",
    "evaluate(y_sub, y_sub, w_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using previous weekpair\n",
    "# evaluate(y_val, y_sub, w_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_data = data\n",
    "filtered_data = data.query(\"dist2firstvalueLeak == 1\")[sel_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146482, 10463)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data), len(filtered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sub_week = 0\n",
    "train = filtered_data.query('-13 <= weekpair <= (@sub_week - 2)').reset_index(drop = True)\n",
    "full_train = filtered_data.query('-13 <= weekpair <= (@sub_week - 1)').reset_index(drop = True)\n",
    "val = filtered_data.query('weekpair == (@sub_week - 1)').reset_index(drop = True)\n",
    "sub = filtered_data.query('weekpair == (@sub_week)').reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9112, 728, 623)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(val), len(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train.pop('order').values\n",
    "y_full_train = full_train.pop('order').values\n",
    "y_val = val.pop('order').values\n",
    "y_sub = sub.pop('order').values\n",
    "\n",
    "w_train = train['itemID'].map(weights)\n",
    "w_full_train = full_train['itemID'].map(weights)\n",
    "w_val = val['itemID'].map(weights)\n",
    "w_sub = sub['itemID'].map(weights)\n",
    "\n",
    "i_train = train.pop(\"itemID\")\n",
    "i_full_train = full_train.pop(\"itemID\")\n",
    "i_val = val.pop(\"itemID\")\n",
    "i_sub = sub.pop(\"itemID\")\n",
    "\n",
    "X_train = train.values\n",
    "X_full_train = full_train.values\n",
    "X_val = val.values\n",
    "X_sub = sub.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-feval:0.00256\tval-feval:0.00347\n",
      "Multiple eval metrics have been passed: 'val-feval' will be used for early stopping.\n",
      "\n",
      "Will train until val-feval hasn't improved in 10 rounds.\n",
      "[1]\ttrain-feval:0.00597\tval-feval:0.00796\n",
      "[2]\ttrain-feval:0.01174\tval-feval:0.01334\n",
      "[3]\ttrain-feval:0.01270\tval-feval:0.01436\n",
      "[4]\ttrain-feval:0.01500\tval-feval:0.01737\n",
      "[5]\ttrain-feval:0.01903\tval-feval:0.02036\n",
      "[6]\ttrain-feval:0.02683\tval-feval:0.02829\n",
      "[7]\ttrain-feval:0.03147\tval-feval:0.03318\n",
      "[8]\ttrain-feval:0.03278\tval-feval:0.03478\n",
      "[9]\ttrain-feval:0.03459\tval-feval:0.03751\n",
      "[10]\ttrain-feval:0.03633\tval-feval:0.03973\n",
      "[11]\ttrain-feval:0.03746\tval-feval:0.04067\n",
      "[12]\ttrain-feval:0.04938\tval-feval:0.04918\n",
      "[13]\ttrain-feval:0.05291\tval-feval:0.05427\n",
      "[14]\ttrain-feval:0.05441\tval-feval:0.05640\n",
      "[15]\ttrain-feval:0.05579\tval-feval:0.05813\n",
      "[16]\ttrain-feval:0.05671\tval-feval:0.05894\n",
      "[17]\ttrain-feval:0.05956\tval-feval:0.06277\n",
      "[18]\ttrain-feval:0.06218\tval-feval:0.06520\n",
      "[19]\ttrain-feval:0.06407\tval-feval:0.06796\n",
      "[20]\ttrain-feval:0.06534\tval-feval:0.06977\n",
      "[21]\ttrain-feval:0.07196\tval-feval:0.07754\n",
      "[22]\ttrain-feval:0.07412\tval-feval:0.08012\n",
      "[23]\ttrain-feval:0.07516\tval-feval:0.08150\n",
      "[24]\ttrain-feval:0.07838\tval-feval:0.08572\n",
      "[25]\ttrain-feval:0.07923\tval-feval:0.08688\n",
      "[26]\ttrain-feval:0.08087\tval-feval:0.08895\n",
      "[27]\ttrain-feval:0.08284\tval-feval:0.09163\n",
      "[28]\ttrain-feval:0.09102\tval-feval:0.09586\n",
      "[29]\ttrain-feval:0.09295\tval-feval:0.09865\n",
      "[30]\ttrain-feval:0.09475\tval-feval:0.10115\n",
      "[31]\ttrain-feval:0.09599\tval-feval:0.10281\n",
      "[32]\ttrain-feval:0.09748\tval-feval:0.10477\n",
      "[33]\ttrain-feval:0.09922\tval-feval:0.10709\n",
      "[34]\ttrain-feval:0.10060\tval-feval:0.10808\n",
      "[35]\ttrain-feval:0.10254\tval-feval:0.11093\n",
      "[36]\ttrain-feval:0.10884\tval-feval:0.11796\n",
      "[37]\ttrain-feval:0.11086\tval-feval:0.12120\n",
      "[38]\ttrain-feval:0.11214\tval-feval:0.12273\n",
      "[39]\ttrain-feval:0.12174\tval-feval:0.13052\n",
      "[40]\ttrain-feval:0.12317\tval-feval:0.13263\n",
      "[41]\ttrain-feval:0.12462\tval-feval:0.13438\n",
      "[42]\ttrain-feval:0.12622\tval-feval:0.13611\n",
      "[43]\ttrain-feval:0.12802\tval-feval:0.13936\n",
      "[44]\ttrain-feval:0.12947\tval-feval:0.14149\n",
      "[45]\ttrain-feval:0.13065\tval-feval:0.14272\n",
      "[46]\ttrain-feval:0.13194\tval-feval:0.14415\n",
      "[47]\ttrain-feval:0.13283\tval-feval:0.14556\n",
      "[48]\ttrain-feval:0.13474\tval-feval:0.14864\n",
      "[49]\ttrain-feval:0.13595\tval-feval:0.15011\n",
      "[50]\ttrain-feval:0.13819\tval-feval:0.15294\n",
      "[51]\ttrain-feval:0.13909\tval-feval:0.15419\n",
      "[52]\ttrain-feval:0.14076\tval-feval:0.15562\n",
      "[53]\ttrain-feval:0.14613\tval-feval:0.16261\n",
      "[54]\ttrain-feval:0.14796\tval-feval:0.16478\n",
      "[55]\ttrain-feval:0.14890\tval-feval:0.16630\n",
      "[56]\ttrain-feval:0.15036\tval-feval:0.16775\n",
      "[57]\ttrain-feval:0.15193\tval-feval:0.17002\n",
      "[58]\ttrain-feval:0.15283\tval-feval:0.17141\n",
      "[59]\ttrain-feval:0.15386\tval-feval:0.17298\n",
      "[60]\ttrain-feval:0.15566\tval-feval:0.17526\n",
      "[61]\ttrain-feval:0.15668\tval-feval:0.17654\n",
      "[62]\ttrain-feval:0.15805\tval-feval:0.17831\n",
      "[63]\ttrain-feval:0.15914\tval-feval:0.17896\n",
      "[64]\ttrain-feval:0.16086\tval-feval:0.18123\n",
      "[65]\ttrain-feval:0.16223\tval-feval:0.18346\n",
      "[66]\ttrain-feval:0.16325\tval-feval:0.18440\n",
      "[67]\ttrain-feval:0.16461\tval-feval:0.18623\n",
      "[68]\ttrain-feval:0.16565\tval-feval:0.18718\n",
      "[69]\ttrain-feval:0.16713\tval-feval:0.18883\n",
      "[70]\ttrain-feval:0.16859\tval-feval:0.19021\n",
      "[71]\ttrain-feval:0.16998\tval-feval:0.19226\n",
      "[72]\ttrain-feval:0.17555\tval-feval:0.19983\n",
      "[73]\ttrain-feval:0.18167\tval-feval:0.20462\n",
      "[74]\ttrain-feval:0.18276\tval-feval:0.20566\n",
      "[75]\ttrain-feval:0.18494\tval-feval:0.20972\n",
      "[76]\ttrain-feval:0.18603\tval-feval:0.21083\n",
      "[77]\ttrain-feval:0.18709\tval-feval:0.21239\n",
      "[78]\ttrain-feval:0.18804\tval-feval:0.21336\n",
      "[79]\ttrain-feval:0.18942\tval-feval:0.21559\n",
      "[80]\ttrain-feval:0.19059\tval-feval:0.21727\n",
      "[81]\ttrain-feval:0.19151\tval-feval:0.21856\n",
      "[82]\ttrain-feval:0.19255\tval-feval:0.21960\n",
      "[83]\ttrain-feval:0.19397\tval-feval:0.22145\n",
      "[84]\ttrain-feval:0.19501\tval-feval:0.22257\n",
      "[85]\ttrain-feval:0.19569\tval-feval:0.22324\n",
      "[86]\ttrain-feval:0.19670\tval-feval:0.22469\n",
      "[87]\ttrain-feval:0.19807\tval-feval:0.22647\n",
      "[88]\ttrain-feval:0.19940\tval-feval:0.22800\n",
      "[89]\ttrain-feval:0.20029\tval-feval:0.22895\n",
      "[90]\ttrain-feval:0.20727\tval-feval:0.23390\n",
      "[91]\ttrain-feval:0.20822\tval-feval:0.23503\n",
      "[92]\ttrain-feval:0.20894\tval-feval:0.23581\n",
      "[93]\ttrain-feval:0.21337\tval-feval:0.24194\n",
      "[94]\ttrain-feval:0.21430\tval-feval:0.24336\n",
      "[95]\ttrain-feval:0.21542\tval-feval:0.24504\n",
      "[96]\ttrain-feval:0.21663\tval-feval:0.24657\n",
      "[97]\ttrain-feval:0.21781\tval-feval:0.24786\n",
      "[98]\ttrain-feval:0.21870\tval-feval:0.24866\n",
      "[99]\ttrain-feval:0.21970\tval-feval:0.24985\n",
      "[100]\ttrain-feval:0.22095\tval-feval:0.25197\n",
      "[101]\ttrain-feval:0.22152\tval-feval:0.25293\n",
      "[102]\ttrain-feval:0.22282\tval-feval:0.25476\n",
      "[103]\ttrain-feval:0.22354\tval-feval:0.25534\n",
      "[104]\ttrain-feval:0.22431\tval-feval:0.25620\n",
      "[105]\ttrain-feval:0.22522\tval-feval:0.25747\n",
      "[106]\ttrain-feval:0.22615\tval-feval:0.25864\n",
      "[107]\ttrain-feval:0.22694\tval-feval:0.25956\n",
      "[108]\ttrain-feval:0.22852\tval-feval:0.26159\n",
      "[109]\ttrain-feval:0.22952\tval-feval:0.26302\n",
      "[110]\ttrain-feval:0.23076\tval-feval:0.26460\n",
      "[111]\ttrain-feval:0.23145\tval-feval:0.26531\n",
      "[112]\ttrain-feval:0.23232\tval-feval:0.26690\n",
      "[113]\ttrain-feval:0.23300\tval-feval:0.26746\n",
      "[114]\ttrain-feval:0.23383\tval-feval:0.26845\n",
      "[115]\ttrain-feval:0.23446\tval-feval:0.26916\n",
      "[116]\ttrain-feval:0.23932\tval-feval:0.27220\n",
      "[117]\ttrain-feval:0.24012\tval-feval:0.27339\n",
      "[118]\ttrain-feval:0.24112\tval-feval:0.27442\n",
      "[119]\ttrain-feval:0.24413\tval-feval:0.27891\n",
      "[120]\ttrain-feval:0.24516\tval-feval:0.28047\n",
      "[121]\ttrain-feval:0.24558\tval-feval:0.28106\n",
      "[122]\ttrain-feval:0.24629\tval-feval:0.28194\n",
      "[123]\ttrain-feval:0.24740\tval-feval:0.28334\n",
      "[124]\ttrain-feval:0.24793\tval-feval:0.28392\n",
      "[125]\ttrain-feval:0.24891\tval-feval:0.28559\n",
      "[126]\ttrain-feval:0.25000\tval-feval:0.28716\n",
      "[127]\ttrain-feval:0.25081\tval-feval:0.28749\n",
      "[128]\ttrain-feval:0.25178\tval-feval:0.28870\n",
      "[129]\ttrain-feval:0.25254\tval-feval:0.28976\n",
      "[130]\ttrain-feval:0.25327\tval-feval:0.29084\n",
      "[131]\ttrain-feval:0.25384\tval-feval:0.29162\n",
      "[132]\ttrain-feval:0.25473\tval-feval:0.29266\n",
      "[133]\ttrain-feval:0.25537\tval-feval:0.29307\n",
      "[134]\ttrain-feval:0.25586\tval-feval:0.29368\n",
      "[135]\ttrain-feval:0.25694\tval-feval:0.29505\n",
      "[136]\ttrain-feval:0.25743\tval-feval:0.29551\n",
      "[137]\ttrain-feval:0.25818\tval-feval:0.29606\n",
      "[138]\ttrain-feval:0.25965\tval-feval:0.29939\n",
      "[139]\ttrain-feval:0.26052\tval-feval:0.30088\n",
      "[140]\ttrain-feval:0.26121\tval-feval:0.30162\n",
      "[141]\ttrain-feval:0.26183\tval-feval:0.30245\n",
      "[142]\ttrain-feval:0.26254\tval-feval:0.30332\n",
      "[143]\ttrain-feval:0.26306\tval-feval:0.30371\n",
      "[144]\ttrain-feval:0.26366\tval-feval:0.30418\n",
      "[145]\ttrain-feval:0.26484\tval-feval:0.30598\n",
      "[146]\ttrain-feval:0.26564\tval-feval:0.30692\n",
      "[147]\ttrain-feval:0.26637\tval-feval:0.30810\n",
      "[148]\ttrain-feval:0.26675\tval-feval:0.30863\n",
      "[149]\ttrain-feval:0.26749\tval-feval:0.30941\n",
      "[150]\ttrain-feval:0.27020\tval-feval:0.31302\n",
      "[151]\ttrain-feval:0.27045\tval-feval:0.31332\n",
      "[152]\ttrain-feval:0.27149\tval-feval:0.31410\n",
      "[153]\ttrain-feval:0.27208\tval-feval:0.31491\n",
      "[154]\ttrain-feval:0.27268\tval-feval:0.31587\n",
      "[155]\ttrain-feval:0.27391\tval-feval:0.31711\n",
      "[156]\ttrain-feval:0.27441\tval-feval:0.31800\n",
      "[157]\ttrain-feval:0.27509\tval-feval:0.31832\n",
      "[158]\ttrain-feval:0.27581\tval-feval:0.31912\n",
      "[159]\ttrain-feval:0.27608\tval-feval:0.31947\n",
      "[160]\ttrain-feval:0.27678\tval-feval:0.32010\n",
      "[161]\ttrain-feval:0.27725\tval-feval:0.32074\n",
      "[162]\ttrain-feval:0.27793\tval-feval:0.32187\n",
      "[163]\ttrain-feval:0.27851\tval-feval:0.32321\n",
      "[164]\ttrain-feval:0.27919\tval-feval:0.32534\n",
      "[165]\ttrain-feval:0.28219\tval-feval:0.32584\n",
      "[166]\ttrain-feval:0.28272\tval-feval:0.32615\n",
      "[167]\ttrain-feval:0.28393\tval-feval:0.32728\n",
      "[168]\ttrain-feval:0.28807\tval-feval:0.32802\n",
      "[169]\ttrain-feval:0.28846\tval-feval:0.32850\n",
      "[170]\ttrain-feval:0.28916\tval-feval:0.32929\n",
      "[171]\ttrain-feval:0.28972\tval-feval:0.32981\n",
      "[172]\ttrain-feval:0.29050\tval-feval:0.33074\n",
      "[173]\ttrain-feval:0.29112\tval-feval:0.33151\n",
      "[174]\ttrain-feval:0.29150\tval-feval:0.33202\n",
      "[175]\ttrain-feval:0.29205\tval-feval:0.33241\n",
      "[176]\ttrain-feval:0.29269\tval-feval:0.33623\n",
      "[177]\ttrain-feval:0.29317\tval-feval:0.33690\n",
      "[178]\ttrain-feval:0.29367\tval-feval:0.33731\n",
      "[179]\ttrain-feval:0.29406\tval-feval:0.33752\n",
      "[180]\ttrain-feval:0.29446\tval-feval:0.33795\n",
      "[181]\ttrain-feval:0.29505\tval-feval:0.33897\n",
      "[182]\ttrain-feval:0.29590\tval-feval:0.33922\n",
      "[183]\ttrain-feval:0.29647\tval-feval:0.34036\n",
      "[184]\ttrain-feval:0.29687\tval-feval:0.34084\n",
      "[185]\ttrain-feval:0.29712\tval-feval:0.34097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[186]\ttrain-feval:0.29757\tval-feval:0.34125\n",
      "[187]\ttrain-feval:0.29820\tval-feval:0.34223\n",
      "[188]\ttrain-feval:0.29865\tval-feval:0.34281\n",
      "[189]\ttrain-feval:0.29903\tval-feval:0.34569\n",
      "[190]\ttrain-feval:0.30006\tval-feval:0.34794\n",
      "[191]\ttrain-feval:0.30035\tval-feval:0.34828\n",
      "[192]\ttrain-feval:0.30072\tval-feval:0.34877\n",
      "[193]\ttrain-feval:0.30236\tval-feval:0.34909\n",
      "[194]\ttrain-feval:0.30303\tval-feval:0.34944\n",
      "[195]\ttrain-feval:0.30369\tval-feval:0.35029\n",
      "[196]\ttrain-feval:0.30388\tval-feval:0.35051\n",
      "[197]\ttrain-feval:0.30454\tval-feval:0.35091\n",
      "[198]\ttrain-feval:0.30505\tval-feval:0.35158\n",
      "[199]\ttrain-feval:0.30531\tval-feval:0.35195\n",
      "[200]\ttrain-feval:0.30572\tval-feval:0.35251\n",
      "[201]\ttrain-feval:0.30610\tval-feval:0.35280\n",
      "[202]\ttrain-feval:0.30679\tval-feval:0.35430\n",
      "[203]\ttrain-feval:0.30712\tval-feval:0.35474\n",
      "[204]\ttrain-feval:0.30723\tval-feval:0.35495\n",
      "[205]\ttrain-feval:0.30777\tval-feval:0.35546\n",
      "[206]\ttrain-feval:0.30854\tval-feval:0.35692\n",
      "[207]\ttrain-feval:0.30925\tval-feval:0.35759\n",
      "[208]\ttrain-feval:0.30946\tval-feval:0.35768\n",
      "[209]\ttrain-feval:0.30975\tval-feval:0.36052\n",
      "[210]\ttrain-feval:0.31019\tval-feval:0.36091\n",
      "[211]\ttrain-feval:0.31071\tval-feval:0.36124\n",
      "[212]\ttrain-feval:0.31093\tval-feval:0.36180\n",
      "[213]\ttrain-feval:0.31139\tval-feval:0.36196\n",
      "[214]\ttrain-feval:0.31153\tval-feval:0.36208\n",
      "[215]\ttrain-feval:0.31225\tval-feval:0.36263\n",
      "[216]\ttrain-feval:0.31264\tval-feval:0.36321\n",
      "[217]\ttrain-feval:0.31290\tval-feval:0.36342\n",
      "[218]\ttrain-feval:0.31336\tval-feval:0.36371\n",
      "[219]\ttrain-feval:0.31365\tval-feval:0.36390\n",
      "[220]\ttrain-feval:0.31404\tval-feval:0.36480\n",
      "[221]\ttrain-feval:0.31438\tval-feval:0.36508\n",
      "[222]\ttrain-feval:0.31517\tval-feval:0.36598\n",
      "[223]\ttrain-feval:0.31539\tval-feval:0.36635\n",
      "[224]\ttrain-feval:0.31572\tval-feval:0.36677\n",
      "[225]\ttrain-feval:0.31620\tval-feval:0.36711\n",
      "[226]\ttrain-feval:0.31680\tval-feval:0.36720\n",
      "[227]\ttrain-feval:0.31722\tval-feval:0.36773\n",
      "[228]\ttrain-feval:0.31754\tval-feval:0.36790\n",
      "[229]\ttrain-feval:0.31786\tval-feval:0.36818\n",
      "[230]\ttrain-feval:0.31808\tval-feval:0.36834\n",
      "[231]\ttrain-feval:0.31996\tval-feval:0.36854\n",
      "[232]\ttrain-feval:0.32061\tval-feval:0.36907\n",
      "[233]\ttrain-feval:0.32096\tval-feval:0.36959\n",
      "[234]\ttrain-feval:0.32128\tval-feval:0.36985\n",
      "[235]\ttrain-feval:0.32151\tval-feval:0.37027\n",
      "[236]\ttrain-feval:0.32207\tval-feval:0.37039\n",
      "[237]\ttrain-feval:0.32244\tval-feval:0.37094\n",
      "[238]\ttrain-feval:0.32304\tval-feval:0.37138\n",
      "[239]\ttrain-feval:0.32326\tval-feval:0.37139\n",
      "[240]\ttrain-feval:0.32372\tval-feval:0.37180\n",
      "[241]\ttrain-feval:0.32389\tval-feval:0.37225\n",
      "[242]\ttrain-feval:0.32429\tval-feval:0.37242\n",
      "[243]\ttrain-feval:0.32460\tval-feval:0.37298\n",
      "[244]\ttrain-feval:0.32492\tval-feval:0.37339\n",
      "[245]\ttrain-feval:0.32515\tval-feval:0.37350\n",
      "[246]\ttrain-feval:0.32561\tval-feval:0.37541\n",
      "[247]\ttrain-feval:0.32609\tval-feval:0.37578\n",
      "[248]\ttrain-feval:0.32633\tval-feval:0.37601\n",
      "[249]\ttrain-feval:0.32650\tval-feval:0.37624\n",
      "[250]\ttrain-feval:0.32688\tval-feval:0.37646\n",
      "[251]\ttrain-feval:0.32699\tval-feval:0.37751\n",
      "[252]\ttrain-feval:0.32732\tval-feval:0.37768\n",
      "[253]\ttrain-feval:0.32756\tval-feval:0.37830\n",
      "[254]\ttrain-feval:0.32796\tval-feval:0.37895\n",
      "[255]\ttrain-feval:0.32828\tval-feval:0.37911\n",
      "[256]\ttrain-feval:0.32911\tval-feval:0.38225\n",
      "[257]\ttrain-feval:0.32939\tval-feval:0.38248\n",
      "[258]\ttrain-feval:0.32960\tval-feval:0.38259\n",
      "[259]\ttrain-feval:0.33217\tval-feval:0.38281\n",
      "[260]\ttrain-feval:0.33257\tval-feval:0.38315\n",
      "[261]\ttrain-feval:0.33274\tval-feval:0.38301\n",
      "[262]\ttrain-feval:0.33408\tval-feval:0.38398\n",
      "[263]\ttrain-feval:0.33415\tval-feval:0.38433\n",
      "[264]\ttrain-feval:0.33456\tval-feval:0.38484\n",
      "[265]\ttrain-feval:0.33481\tval-feval:0.38515\n",
      "[266]\ttrain-feval:0.33489\tval-feval:0.38516\n",
      "[267]\ttrain-feval:0.33521\tval-feval:0.38561\n",
      "[268]\ttrain-feval:0.33555\tval-feval:0.38586\n",
      "[269]\ttrain-feval:0.33589\tval-feval:0.38619\n",
      "[270]\ttrain-feval:0.33609\tval-feval:0.38644\n",
      "[271]\ttrain-feval:0.33625\tval-feval:0.38671\n",
      "[272]\ttrain-feval:0.33660\tval-feval:0.38723\n",
      "[273]\ttrain-feval:0.33690\tval-feval:0.38777\n",
      "[274]\ttrain-feval:0.33711\tval-feval:0.38785\n",
      "[275]\ttrain-feval:0.33727\tval-feval:0.38805\n",
      "[276]\ttrain-feval:0.33753\tval-feval:0.38811\n",
      "[277]\ttrain-feval:0.33773\tval-feval:0.38832\n",
      "[278]\ttrain-feval:0.33786\tval-feval:0.38876\n",
      "[279]\ttrain-feval:0.33817\tval-feval:0.38900\n",
      "[280]\ttrain-feval:0.33850\tval-feval:0.38924\n",
      "[281]\ttrain-feval:0.33858\tval-feval:0.38928\n",
      "[282]\ttrain-feval:0.33890\tval-feval:0.38796\n",
      "[283]\ttrain-feval:0.33920\tval-feval:0.38826\n",
      "[284]\ttrain-feval:0.33938\tval-feval:0.38817\n",
      "[285]\ttrain-feval:0.33952\tval-feval:0.38854\n",
      "[286]\ttrain-feval:0.33977\tval-feval:0.38876\n",
      "[287]\ttrain-feval:0.33989\tval-feval:0.38878\n",
      "[288]\ttrain-feval:0.34006\tval-feval:0.39080\n",
      "[289]\ttrain-feval:0.34022\tval-feval:0.39103\n",
      "[290]\ttrain-feval:0.34038\tval-feval:0.39104\n",
      "[291]\ttrain-feval:0.34066\tval-feval:0.39133\n",
      "[292]\ttrain-feval:0.34091\tval-feval:0.39173\n",
      "[293]\ttrain-feval:0.34099\tval-feval:0.39219\n",
      "[294]\ttrain-feval:0.34123\tval-feval:0.39237\n",
      "[295]\ttrain-feval:0.34140\tval-feval:0.39246\n",
      "[296]\ttrain-feval:0.34171\tval-feval:0.39285\n",
      "[297]\ttrain-feval:0.34211\tval-feval:0.39316\n",
      "[298]\ttrain-feval:0.34236\tval-feval:0.39372\n",
      "[299]\ttrain-feval:0.34244\tval-feval:0.39380\n",
      "[300]\ttrain-feval:0.34259\tval-feval:0.39398\n",
      "[301]\ttrain-feval:0.34274\tval-feval:0.39418\n",
      "[302]\ttrain-feval:0.34290\tval-feval:0.39430\n",
      "[303]\ttrain-feval:0.34310\tval-feval:0.39442\n",
      "[304]\ttrain-feval:0.34316\tval-feval:0.39453\n",
      "[305]\ttrain-feval:0.34340\tval-feval:0.39475\n",
      "[306]\ttrain-feval:0.34358\tval-feval:0.39504\n",
      "[307]\ttrain-feval:0.34382\tval-feval:0.39527\n",
      "[308]\ttrain-feval:0.34400\tval-feval:0.39544\n",
      "[309]\ttrain-feval:0.34419\tval-feval:0.39571\n",
      "[310]\ttrain-feval:0.34424\tval-feval:0.39586\n",
      "[311]\ttrain-feval:0.34451\tval-feval:0.39627\n",
      "[312]\ttrain-feval:0.34470\tval-feval:0.39645\n",
      "[313]\ttrain-feval:0.34494\tval-feval:0.39658\n",
      "[314]\ttrain-feval:0.34517\tval-feval:0.39677\n",
      "[315]\ttrain-feval:0.34534\tval-feval:0.39692\n",
      "[316]\ttrain-feval:0.34550\tval-feval:0.39714\n",
      "[317]\ttrain-feval:0.34561\tval-feval:0.39717\n",
      "[318]\ttrain-feval:0.34602\tval-feval:0.39731\n",
      "[319]\ttrain-feval:0.34639\tval-feval:0.39758\n",
      "[320]\ttrain-feval:0.34648\tval-feval:0.39827\n",
      "[321]\ttrain-feval:0.34656\tval-feval:0.39856\n",
      "[322]\ttrain-feval:0.34669\tval-feval:0.39850\n",
      "[323]\ttrain-feval:0.34681\tval-feval:0.39873\n",
      "[324]\ttrain-feval:0.34691\tval-feval:0.39924\n",
      "[325]\ttrain-feval:0.34709\tval-feval:0.39927\n",
      "[326]\ttrain-feval:0.34715\tval-feval:0.39998\n",
      "[327]\ttrain-feval:0.34722\tval-feval:0.40014\n",
      "[328]\ttrain-feval:0.34741\tval-feval:0.40035\n",
      "[329]\ttrain-feval:0.34767\tval-feval:0.40066\n",
      "[330]\ttrain-feval:0.34785\tval-feval:0.40082\n",
      "[331]\ttrain-feval:0.34802\tval-feval:0.40105\n",
      "[332]\ttrain-feval:0.34807\tval-feval:0.40101\n",
      "[333]\ttrain-feval:0.34818\tval-feval:0.40136\n",
      "[334]\ttrain-feval:0.34832\tval-feval:0.40160\n",
      "[335]\ttrain-feval:0.34841\tval-feval:0.40174\n",
      "[336]\ttrain-feval:0.34875\tval-feval:0.40179\n",
      "[337]\ttrain-feval:0.34889\tval-feval:0.40182\n",
      "[338]\ttrain-feval:0.34901\tval-feval:0.40206\n",
      "[339]\ttrain-feval:0.34929\tval-feval:0.40232\n",
      "[340]\ttrain-feval:0.34940\tval-feval:0.40224\n",
      "[341]\ttrain-feval:0.34959\tval-feval:0.40230\n",
      "[342]\ttrain-feval:0.34982\tval-feval:0.40246\n",
      "[343]\ttrain-feval:0.34983\tval-feval:0.40262\n",
      "[344]\ttrain-feval:0.35004\tval-feval:0.40268\n",
      "[345]\ttrain-feval:0.35011\tval-feval:0.40276\n",
      "[346]\ttrain-feval:0.35022\tval-feval:0.40399\n",
      "[347]\ttrain-feval:0.35028\tval-feval:0.40425\n",
      "[348]\ttrain-feval:0.35045\tval-feval:0.40398\n",
      "[349]\ttrain-feval:0.35060\tval-feval:0.40408\n",
      "[350]\ttrain-feval:0.35062\tval-feval:0.40382\n",
      "[351]\ttrain-feval:0.35074\tval-feval:0.40396\n",
      "[352]\ttrain-feval:0.35079\tval-feval:0.40424\n",
      "[353]\ttrain-feval:0.35095\tval-feval:0.40426\n",
      "[354]\ttrain-feval:0.35100\tval-feval:0.40427\n",
      "[355]\ttrain-feval:0.35109\tval-feval:0.40425\n",
      "[356]\ttrain-feval:0.35129\tval-feval:0.40433\n",
      "[357]\ttrain-feval:0.35131\tval-feval:0.40437\n",
      "[358]\ttrain-feval:0.35141\tval-feval:0.40454\n",
      "[359]\ttrain-feval:0.35150\tval-feval:0.40461\n",
      "[360]\ttrain-feval:0.35148\tval-feval:0.40616\n",
      "[361]\ttrain-feval:0.35140\tval-feval:0.40576\n",
      "[362]\ttrain-feval:0.35148\tval-feval:0.40618\n",
      "[363]\ttrain-feval:0.35158\tval-feval:0.40636\n",
      "[364]\ttrain-feval:0.35182\tval-feval:0.40645\n",
      "[365]\ttrain-feval:0.35198\tval-feval:0.40625\n",
      "[366]\ttrain-feval:0.35217\tval-feval:0.40669\n",
      "[367]\ttrain-feval:0.35240\tval-feval:0.40671\n",
      "[368]\ttrain-feval:0.35247\tval-feval:0.40682\n",
      "[369]\ttrain-feval:0.35245\tval-feval:0.40687\n",
      "[370]\ttrain-feval:0.35231\tval-feval:0.40704\n",
      "[371]\ttrain-feval:0.35237\tval-feval:0.40713\n",
      "[372]\ttrain-feval:0.35241\tval-feval:0.40720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[373]\ttrain-feval:0.35262\tval-feval:0.40720\n",
      "[374]\ttrain-feval:0.35274\tval-feval:0.40722\n",
      "[375]\ttrain-feval:0.35306\tval-feval:0.40779\n",
      "[376]\ttrain-feval:0.35326\tval-feval:0.40785\n",
      "[377]\ttrain-feval:0.35337\tval-feval:0.40801\n",
      "[378]\ttrain-feval:0.35344\tval-feval:0.40804\n",
      "[379]\ttrain-feval:0.35355\tval-feval:0.40829\n",
      "[380]\ttrain-feval:0.35354\tval-feval:0.40840\n",
      "[381]\ttrain-feval:0.35374\tval-feval:0.40848\n",
      "[382]\ttrain-feval:0.35398\tval-feval:0.40853\n",
      "[383]\ttrain-feval:0.35404\tval-feval:0.40853\n",
      "[384]\ttrain-feval:0.35407\tval-feval:0.40854\n",
      "[385]\ttrain-feval:0.35417\tval-feval:0.40857\n",
      "[386]\ttrain-feval:0.35435\tval-feval:0.40880\n",
      "[387]\ttrain-feval:0.35440\tval-feval:0.40884\n",
      "[388]\ttrain-feval:0.35457\tval-feval:0.40897\n",
      "[389]\ttrain-feval:0.35465\tval-feval:0.40852\n",
      "[390]\ttrain-feval:0.35478\tval-feval:0.40856\n",
      "[391]\ttrain-feval:0.35481\tval-feval:0.40849\n",
      "[392]\ttrain-feval:0.35491\tval-feval:0.40851\n",
      "[393]\ttrain-feval:0.35494\tval-feval:0.40866\n",
      "[394]\ttrain-feval:0.35496\tval-feval:0.40872\n",
      "[395]\ttrain-feval:0.35509\tval-feval:0.40938\n",
      "[396]\ttrain-feval:0.35524\tval-feval:0.40959\n",
      "[397]\ttrain-feval:0.35531\tval-feval:0.40962\n",
      "[398]\ttrain-feval:0.35541\tval-feval:0.40985\n",
      "[399]\ttrain-feval:0.35544\tval-feval:0.40983\n",
      "[400]\ttrain-feval:0.35548\tval-feval:0.41154\n",
      "[401]\ttrain-feval:0.35603\tval-feval:0.41179\n",
      "[402]\ttrain-feval:0.35602\tval-feval:0.41183\n",
      "[403]\ttrain-feval:0.35623\tval-feval:0.41190\n",
      "[404]\ttrain-feval:0.35629\tval-feval:0.41196\n",
      "[405]\ttrain-feval:0.35635\tval-feval:0.41203\n",
      "[406]\ttrain-feval:0.35648\tval-feval:0.41220\n",
      "[407]\ttrain-feval:0.35652\tval-feval:0.41220\n",
      "[408]\ttrain-feval:0.35655\tval-feval:0.41211\n",
      "[409]\ttrain-feval:0.35659\tval-feval:0.41215\n",
      "[410]\ttrain-feval:0.35664\tval-feval:0.41224\n",
      "[411]\ttrain-feval:0.35675\tval-feval:0.41230\n",
      "[412]\ttrain-feval:0.35676\tval-feval:0.41242\n",
      "[413]\ttrain-feval:0.35686\tval-feval:0.41268\n",
      "[414]\ttrain-feval:0.35677\tval-feval:0.41266\n",
      "[415]\ttrain-feval:0.35694\tval-feval:0.41264\n",
      "[416]\ttrain-feval:0.35686\tval-feval:0.41271\n",
      "[417]\ttrain-feval:0.35683\tval-feval:0.41255\n",
      "[418]\ttrain-feval:0.35696\tval-feval:0.41360\n",
      "[419]\ttrain-feval:0.35696\tval-feval:0.41346\n",
      "[420]\ttrain-feval:0.35681\tval-feval:0.41367\n",
      "[421]\ttrain-feval:0.35692\tval-feval:0.41364\n",
      "[422]\ttrain-feval:0.35701\tval-feval:0.41367\n",
      "[423]\ttrain-feval:0.35727\tval-feval:0.41371\n",
      "[424]\ttrain-feval:0.35745\tval-feval:0.41381\n",
      "[425]\ttrain-feval:0.35752\tval-feval:0.41371\n",
      "[426]\ttrain-feval:0.35759\tval-feval:0.41387\n",
      "[427]\ttrain-feval:0.35775\tval-feval:0.41394\n",
      "[428]\ttrain-feval:0.35773\tval-feval:0.41361\n",
      "[429]\ttrain-feval:0.35786\tval-feval:0.41339\n",
      "[430]\ttrain-feval:0.35811\tval-feval:0.41356\n",
      "[431]\ttrain-feval:0.35818\tval-feval:0.41348\n",
      "[432]\ttrain-feval:0.35838\tval-feval:0.41353\n",
      "[433]\ttrain-feval:0.35842\tval-feval:0.41338\n",
      "[434]\ttrain-feval:0.35847\tval-feval:0.41358\n",
      "[435]\ttrain-feval:0.35857\tval-feval:0.41355\n",
      "[436]\ttrain-feval:0.35855\tval-feval:0.41350\n",
      "[437]\ttrain-feval:0.35855\tval-feval:0.41365\n",
      "Stopping. Best iteration:\n",
      "[427]\ttrain-feval:0.35775\tval-feval:0.41394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "missing = 0\n",
    "dtrain = xgb.DMatrix(X_train, y_train, w_train, missing = missing)\n",
    "dfulltrain = xgb.DMatrix(X_full_train, y_full_train, w_full_train, missing = missing)\n",
    "dval = xgb.DMatrix(X_val, y_val, w_val, missing = missing)\n",
    "dsub = xgb.DMatrix(X_sub, y_sub, w_sub, missing = missing)\n",
    "# specify parameters via map\n",
    "param = {\n",
    "    'max_depth':4,\n",
    "    'eta':0.005,\n",
    "    'objective':'reg:squarederror',\n",
    "    'disable_default_eval_metric': 1,\n",
    "    \"min_child_weight\" : 10000,\n",
    "    \n",
    "#     'tree_method' : 'gpu_hist',\n",
    "}\n",
    "num_round = 800\n",
    "bst = xgb.train(param, dtrain,\n",
    "                num_round,\n",
    "                early_stopping_rounds = 10,\n",
    "                evals = [(dtrain, 'train'), (dval, 'val')],\n",
    "#                 obj = objective,\n",
    "                feval = feval,\n",
    "                maximize = True,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-735639.9660000001, -12.00608898907564)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = bst.predict(dsub, ntree_limit=bst.best_ntree_limit).astype(int)\n",
    "evaluate(prediction, y_sub, w_sub), evaluate_prop(prediction, y_sub, w_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43902"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "428"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst_sub = xgb.train(param, dfulltrain,\n",
    "    num_boost_round = bst.best_ntree_limit,\n",
    "    #                 obj = objective,\n",
    "    feval = feval, maximize = True,\n",
    "    evals = [(dfulltrain, 'ftrain')],\n",
    "    verbose_eval = False,\n",
    ")\n",
    "bst_sub.best_ntree_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-749497.0980000002, -12.23224576088617)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_new = bst_sub.predict(dsub, ntree_limit=bst_sub.best_ntree_limit).astype(int)\n",
    "evaluate(prediction_new, y_sub, w_sub), evaluate_prop(prediction_new, y_sub, w_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_preds = {item : pred for item, pred in zip(i_sub, prediction_new)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some other things below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61272.24000000001"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max possible score\n",
    "evaluate(y_sub, y_sub, w_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using previous weekpair\n",
    "# evaluate(y_val, y_sub, w_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = {**old_preds, **new_preds}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10463, 10463, 9840, 623)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds), len(infos), len(old_preds), len(new_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 17,\n",
       " 31: 10,\n",
       " 32: 34,\n",
       " 37: 10,\n",
       " 108: 29,\n",
       " 109: 15,\n",
       " 112: 7,\n",
       " 281: 29,\n",
       " 282: 29,\n",
       " 283: 23,\n",
       " 387: 16,\n",
       " 388: 15,\n",
       " 430: 6,\n",
       " 431: 7,\n",
       " 688: 5,\n",
       " 720: 9,\n",
       " 721: 29,\n",
       " 907: 10,\n",
       " 908: 5,\n",
       " 1039: 22,\n",
       " 1097: 9,\n",
       " 1300: 16,\n",
       " 1301: 23,\n",
       " 1302: 29,\n",
       " 1303: 7,\n",
       " 1304: 8,\n",
       " 1305: 9,\n",
       " 1306: 7,\n",
       " 1307: 11,\n",
       " 1308: 8,\n",
       " 1309: 12,\n",
       " 1310: 9,\n",
       " 1451: 10,\n",
       " 1452: 9,\n",
       " 1453: 11,\n",
       " 1454: 9,\n",
       " 1604: 5,\n",
       " 1641: 6,\n",
       " 1642: 17,\n",
       " 1643: 7,\n",
       " 2: 31,\n",
       " 4: 15,\n",
       " 5: 20,\n",
       " 6: 16,\n",
       " 11: 20,\n",
       " 12: 19,\n",
       " 14: 32,\n",
       " 28: 17,\n",
       " 48: 27,\n",
       " 64: 36,\n",
       " 65: 25,\n",
       " 68: 30,\n",
       " 69: 41,\n",
       " 72: 25,\n",
       " 73: 38,\n",
       " 74: 14,\n",
       " 90: 10,\n",
       " 148: 13,\n",
       " 151: 21,\n",
       " 163: 25,\n",
       " 164: 13,\n",
       " 236: 41,\n",
       " 237: 24,\n",
       " 238: 38,\n",
       " 239: 31,\n",
       " 253: 9,\n",
       " 259: 10,\n",
       " 260: 9,\n",
       " 261: 9,\n",
       " 262: 36,\n",
       " 263: 10,\n",
       " 269: 38,\n",
       " 270: 9,\n",
       " 271: 12,\n",
       " 272: 15,\n",
       " 284: 15,\n",
       " 285: 7,\n",
       " 286: 26,\n",
       " 288: 25,\n",
       " 289: 38,\n",
       " 290: 35,\n",
       " 291: 15,\n",
       " 292: 9,\n",
       " 293: 7,\n",
       " 342: 23,\n",
       " 343: 13,\n",
       " 344: 10,\n",
       " 345: 10,\n",
       " 347: 13,\n",
       " 348: 17,\n",
       " 349: 9,\n",
       " 350: 23,\n",
       " 351: 8,\n",
       " 366: 27,\n",
       " 371: 14,\n",
       " 372: 15,\n",
       " 373: 32,\n",
       " 374: 9,\n",
       " 382: 41,\n",
       " 408: 13,\n",
       " 409: 13,\n",
       " 410: 10,\n",
       " 432: 26,\n",
       " 433: 14,\n",
       " 434: 10,\n",
       " 435: 31,\n",
       " 436: 36,\n",
       " 438: 18,\n",
       " 439: 24,\n",
       " 440: 17,\n",
       " 441: 23,\n",
       " 442: 12,\n",
       " 443: 8,\n",
       " 444: 14,\n",
       " 445: 9,\n",
       " 446: 10,\n",
       " 447: 12,\n",
       " 448: 17,\n",
       " 473: 17,\n",
       " 486: 30,\n",
       " 487: 32,\n",
       " 488: 36,\n",
       " 513: 14,\n",
       " 514: 14,\n",
       " 515: 9,\n",
       " 516: 11,\n",
       " 517: 16,\n",
       " 518: 32,\n",
       " 519: 9,\n",
       " 520: 21,\n",
       " 521: 15,\n",
       " 522: 18,\n",
       " 523: 18,\n",
       " 524: 7,\n",
       " 525: 19,\n",
       " 526: 15,\n",
       " 539: 9,\n",
       " 540: 17,\n",
       " 541: 15,\n",
       " 542: 11,\n",
       " 554: 10,\n",
       " 555: 36,\n",
       " 559: 10,\n",
       " 560: 9,\n",
       " 567: 14,\n",
       " 592: 20,\n",
       " 593: 31,\n",
       " 594: 9,\n",
       " 595: 38,\n",
       " 596: 11,\n",
       " 597: 28,\n",
       " 598: 22,\n",
       " 609: 22,\n",
       " 610: 11,\n",
       " 611: 16,\n",
       " 621: 8,\n",
       " 667: 36,\n",
       " 694: 14,\n",
       " 695: 10,\n",
       " 696: 25,\n",
       " 697: 9,\n",
       " 698: 19,\n",
       " 699: 7,\n",
       " 700: 32,\n",
       " 702: 17,\n",
       " 703: 13,\n",
       " 704: 12,\n",
       " 705: 19,\n",
       " 759: 10,\n",
       " 760: 38,\n",
       " 761: 9,\n",
       " 762: 31,\n",
       " 763: 25,\n",
       " 764: 38,\n",
       " 765: 38,\n",
       " 766: 34,\n",
       " 797: 12,\n",
       " 798: 13,\n",
       " 799: 10,\n",
       " 800: 6,\n",
       " 801: 24,\n",
       " 802: 21,\n",
       " 803: 36,\n",
       " 804: 21,\n",
       " 805: 15,\n",
       " 1103: 10,\n",
       " 1104: 21,\n",
       " 1105: 24,\n",
       " 1106: 8,\n",
       " 1107: 41,\n",
       " 1108: 11,\n",
       " 1218: 9,\n",
       " 1219: 22,\n",
       " 1220: 13,\n",
       " 1221: 5,\n",
       " 1222: 11,\n",
       " 1223: 16,\n",
       " 1224: 31,\n",
       " 1225: 24,\n",
       " 1226: 19,\n",
       " 1227: 24,\n",
       " 1228: 20,\n",
       " 1229: 26,\n",
       " 1230: 24,\n",
       " 1231: 21,\n",
       " 1232: 9,\n",
       " 1233: 15,\n",
       " 1234: 5,\n",
       " 1235: 31,\n",
       " 1236: 15,\n",
       " 1237: 14,\n",
       " 1238: 12,\n",
       " 1239: 10,\n",
       " 1240: 11,\n",
       " 1241: 14,\n",
       " 1242: 7,\n",
       " 1243: 10,\n",
       " 1244: 19,\n",
       " 1245: 14,\n",
       " 1246: 12,\n",
       " 1247: 16,\n",
       " 1248: 22,\n",
       " 1249: 11,\n",
       " 1250: 15,\n",
       " 1251: 20,\n",
       " 1252: 17,\n",
       " 1253: 16,\n",
       " 1254: 11,\n",
       " 1255: 19,\n",
       " 1311: 36,\n",
       " 1312: 38,\n",
       " 1313: 16,\n",
       " 1314: 13,\n",
       " 1315: 26,\n",
       " 1316: 13,\n",
       " 1317: 14,\n",
       " 1318: 29,\n",
       " 1354: 7,\n",
       " 1355: 17,\n",
       " 1356: 11,\n",
       " 1357: 9,\n",
       " 1358: 11,\n",
       " 1359: 9,\n",
       " 1360: 10,\n",
       " 1361: 11,\n",
       " 1362: 10,\n",
       " 1363: 25,\n",
       " 1364: 11,\n",
       " 1365: 9,\n",
       " 1366: 13,\n",
       " 1367: 14,\n",
       " 1369: 11,\n",
       " 1547: 11,\n",
       " 1548: 10,\n",
       " 1593: 7,\n",
       " 1596: 7,\n",
       " 1597: 7,\n",
       " 1864: 14,\n",
       " 1865: 10,\n",
       " 1883: 3,\n",
       " 1948: 6,\n",
       " 1949: 10,\n",
       " 1950: 9,\n",
       " 1951: 6,\n",
       " 1952: 5,\n",
       " 1973: 5,\n",
       " 1987: 8,\n",
       " 1988: 13,\n",
       " 1994: 9,\n",
       " 1995: 6,\n",
       " 2183: 3,\n",
       " 2184: 9,\n",
       " 2185: 6,\n",
       " 2186: 9,\n",
       " 2187: 10,\n",
       " 2188: 14,\n",
       " 2189: 5,\n",
       " 2190: 10,\n",
       " 2191: 5,\n",
       " 2219: 21,\n",
       " 2220: 26,\n",
       " 2221: 16,\n",
       " 2222: 11,\n",
       " 2223: 22,\n",
       " 2224: 14,\n",
       " 2225: 21,\n",
       " 2226: 12,\n",
       " 2227: 21,\n",
       " 2228: 26,\n",
       " 2229: 22,\n",
       " 2230: 13,\n",
       " 2299: 31,\n",
       " 2300: 33,\n",
       " 2301: 10,\n",
       " 2302: 32,\n",
       " 2303: 33,\n",
       " 2315: 4,\n",
       " 2316: 10,\n",
       " 2317: 9,\n",
       " 2318: 5,\n",
       " 2319: 6,\n",
       " 2320: 6,\n",
       " 2321: 6,\n",
       " 2322: 9,\n",
       " 2323: 25,\n",
       " 2324: 17,\n",
       " 2325: 38,\n",
       " 2326: 16,\n",
       " 2327: 38,\n",
       " 2328: 21,\n",
       " 2329: 26,\n",
       " 2330: 38,\n",
       " 2331: 18,\n",
       " 2332: 31,\n",
       " 2333: 32,\n",
       " 2334: 31,\n",
       " 2335: 32,\n",
       " 2336: 31,\n",
       " 2337: 38,\n",
       " 2338: 38,\n",
       " 2339: 17,\n",
       " 2340: 32,\n",
       " 2341: 16,\n",
       " 2497: 22,\n",
       " 2498: 22,\n",
       " 2521: 16,\n",
       " 2522: 22,\n",
       " 2544: 6,\n",
       " 2545: 5,\n",
       " 2546: 5,\n",
       " 2547: 3,\n",
       " 2548: 6,\n",
       " 2549: 6,\n",
       " 2550: 9,\n",
       " 2551: 9,\n",
       " 2573: 7,\n",
       " 2574: 10,\n",
       " 2575: 5,\n",
       " 2576: 10,\n",
       " 2577: 14,\n",
       " 2578: 9,\n",
       " 2579: 9,\n",
       " 2592: 22,\n",
       " 2593: 9,\n",
       " 2594: 9,\n",
       " 2595: 5,\n",
       " 2596: 9,\n",
       " 2597: 4,\n",
       " 2598: 4,\n",
       " 2599: 5,\n",
       " 2600: 9,\n",
       " 2601: 9,\n",
       " 2602: 14,\n",
       " 2608: 11,\n",
       " 2609: 5,\n",
       " 2610: 10,\n",
       " 2611: 10,\n",
       " 2612: 9,\n",
       " 2909: 6,\n",
       " 2910: 6,\n",
       " 2911: 4,\n",
       " 2912: 4,\n",
       " 2913: 4,\n",
       " 2914: 5,\n",
       " 2915: 5,\n",
       " 2916: 9,\n",
       " 3: 7,\n",
       " 7: 34,\n",
       " 38: 8,\n",
       " 101: 7,\n",
       " 102: 8,\n",
       " 103: 7,\n",
       " 360: 7,\n",
       " 361: 10,\n",
       " 362: 11,\n",
       " 363: 17,\n",
       " 367: 11,\n",
       " 368: 9,\n",
       " 565: 14,\n",
       " 692: 8,\n",
       " 693: 7,\n",
       " 769: 18,\n",
       " 1291: 7,\n",
       " 1292: 8,\n",
       " 1293: 13,\n",
       " 1294: 13,\n",
       " 1295: 13,\n",
       " 1296: 9,\n",
       " 1297: 9,\n",
       " 1298: 15,\n",
       " 1299: 10,\n",
       " 1381: 16,\n",
       " 1382: 5,\n",
       " 1383: 8,\n",
       " 1384: 8,\n",
       " 1541: 7,\n",
       " 1542: 6,\n",
       " 1543: 6,\n",
       " 1544: 21,\n",
       " 1545: 6,\n",
       " 1546: 10,\n",
       " 6733: 26,\n",
       " 6734: 16,\n",
       " 6735: 29,\n",
       " 6736: 7,\n",
       " 6737: 11,\n",
       " 6738: 9,\n",
       " 6739: 16,\n",
       " 6740: 24,\n",
       " 6741: 32,\n",
       " 6788: 22,\n",
       " 6842: 26,\n",
       " 6873: 14,\n",
       " 6874: 16,\n",
       " 6875: 32,\n",
       " 6876: 26,\n",
       " 6877: 20,\n",
       " 6878: 16,\n",
       " 6879: 17,\n",
       " 6918: 26,\n",
       " 6919: 12,\n",
       " 6920: 16,\n",
       " 6921: 17,\n",
       " 6922: 14,\n",
       " 6923: 14,\n",
       " 6924: 26,\n",
       " 6944: 10,\n",
       " 6987: 13,\n",
       " 6988: 9,\n",
       " 7004: 14,\n",
       " 7005: 24,\n",
       " 7006: 32,\n",
       " 7007: 24,\n",
       " 7008: 34,\n",
       " 7009: 17,\n",
       " 7010: 32,\n",
       " 7030: 11,\n",
       " 7039: 17,\n",
       " 7040: 26,\n",
       " 7041: 13,\n",
       " 7042: 24,\n",
       " 7043: 20,\n",
       " 7044: 26,\n",
       " 7045: 33,\n",
       " 7046: 12,\n",
       " 7047: 6,\n",
       " 7048: 13,\n",
       " 7101: 33,\n",
       " 7107: 34,\n",
       " 7108: 24,\n",
       " 7109: 26,\n",
       " 7110: 26,\n",
       " 7180: 13,\n",
       " 7181: 16,\n",
       " 7182: 27,\n",
       " 7183: 16,\n",
       " 7184: 24,\n",
       " 7185: 18,\n",
       " 7186: 25,\n",
       " 7187: 9,\n",
       " 7188: 17,\n",
       " 7189: 8,\n",
       " 7190: 16,\n",
       " 7191: 12,\n",
       " 7192: 15,\n",
       " 7216: 25,\n",
       " 7217: 9,\n",
       " 7218: 4,\n",
       " 7219: 19,\n",
       " 7220: 12,\n",
       " 7221: 12,\n",
       " 7249: 7,\n",
       " 7250: 26,\n",
       " 7277: 18,\n",
       " 7278: 7,\n",
       " 7302: 22,\n",
       " 7303: 23,\n",
       " 7328: 18,\n",
       " 7329: 17,\n",
       " 7330: 7,\n",
       " 7364: 4,\n",
       " 7373: 19,\n",
       " 7374: 32,\n",
       " 7375: 18,\n",
       " 7376: 18,\n",
       " 7377: 18,\n",
       " 7378: 18,\n",
       " 7379: 17,\n",
       " 7380: 23,\n",
       " 8: 11,\n",
       " 10: 15,\n",
       " 13: 11,\n",
       " 33: 31,\n",
       " 34: 10,\n",
       " 44: 16,\n",
       " 45: 31,\n",
       " 46: 29,\n",
       " 51: 8,\n",
       " 54: 29,\n",
       " 55: 24,\n",
       " 56: 29,\n",
       " 61: 32,\n",
       " 62: 15,\n",
       " 83: 11,\n",
       " 95: 27,\n",
       " 96: 29,\n",
       " 97: 29,\n",
       " 100: 12,\n",
       " 121: 29,\n",
       " 122: 31,\n",
       " 215: 12,\n",
       " 278: 24,\n",
       " 279: 17,\n",
       " 280: 32,\n",
       " 327: 30,\n",
       " 328: 30,\n",
       " 421: 29,\n",
       " 437: 29,\n",
       " 495: 29,\n",
       " 496: 24,\n",
       " 599: 6,\n",
       " 600: 22,\n",
       " 601: 29,\n",
       " 602: 18,\n",
       " 603: 20,\n",
       " 614: 8,\n",
       " 615: 9,\n",
       " 616: 23,\n",
       " 617: 32,\n",
       " 618: 24,\n",
       " 714: 16,\n",
       " 1477: 17,\n",
       " 1478: 20,\n",
       " 1479: 24,\n",
       " 1480: 19,\n",
       " 1481: 10,\n",
       " 1482: 8,\n",
       " 1483: 22,\n",
       " 1549: 7,\n",
       " 1550: 7,\n",
       " 1551: 22,\n",
       " 1552: 8,\n",
       " 9: 11,\n",
       " 23: 15,\n",
       " 30: 22,\n",
       " 35: 15,\n",
       " 42: 29,\n",
       " 43: 10,\n",
       " 49: 29,\n",
       " 50: 18,\n",
       " 70: 3,\n",
       " 71: 6,\n",
       " 76: 5,\n",
       " 77: 21,\n",
       " 93: 10,\n",
       " 94: 10,\n",
       " 110: 18,\n",
       " 135: 11,\n",
       " 140: 1,\n",
       " 144: 10,\n",
       " 149: 14,\n",
       " 155: 3,\n",
       " 156: 9,\n",
       " 167: 10,\n",
       " 217: 26,\n",
       " 226: 14,\n",
       " 243: 3,\n",
       " 244: 11,\n",
       " 245: 4,\n",
       " 246: 6,\n",
       " 305: 11,\n",
       " 322: 6,\n",
       " 365: 6,\n",
       " 369: 15,\n",
       " 370: 10,\n",
       " 407: 4,\n",
       " 484: 33,\n",
       " 485: 9,\n",
       " 561: 10,\n",
       " 566: 3,\n",
       " 623: 8,\n",
       " 624: 8,\n",
       " 625: 25,\n",
       " 689: 9,\n",
       " 690: 5,\n",
       " 691: 7,\n",
       " 767: 10,\n",
       " 794: 10,\n",
       " 795: 7,\n",
       " 880: 31,\n",
       " 881: 9,\n",
       " 882: 7,\n",
       " 883: 10,\n",
       " 884: 7,\n",
       " 885: 8,\n",
       " 931: 26,\n",
       " 932: 12,\n",
       " 933: 24,\n",
       " 934: 21,\n",
       " 935: 32,\n",
       " 936: 12,\n",
       " 937: 33,\n",
       " 938: 13,\n",
       " 939: 11,\n",
       " 940: 36,\n",
       " 941: 21,\n",
       " 1040: 22,\n",
       " 1041: 10,\n",
       " 1042: 10,\n",
       " 1043: 9,\n",
       " 1044: 6,\n",
       " 1045: 5,\n",
       " 1046: 22,\n",
       " 1047: 10,\n",
       " 1048: 3,\n",
       " 1049: 9,\n",
       " 1050: 12,\n",
       " 1051: 14,\n",
       " 1052: 10,\n",
       " 1053: 9,\n",
       " 1054: 6,\n",
       " 1055: 5,\n",
       " 1056: 10,\n",
       " 1057: 9,\n",
       " 1058: 14,\n",
       " 1059: 5,\n",
       " 1126: 7,\n",
       " 1127: 4,\n",
       " 1128: 9,\n",
       " 1129: 7,\n",
       " 1130: 5,\n",
       " 1131: 10,\n",
       " 1132: 9,\n",
       " 1133: 31,\n",
       " 1134: 9,\n",
       " 1135: 9,\n",
       " 1443: 9,\n",
       " 1444: 7,\n",
       " 1445: 7,\n",
       " 1446: 7,\n",
       " 1447: 36,\n",
       " 1448: 26,\n",
       " 1449: 9,\n",
       " 1450: 7,\n",
       " 1456: 5,\n",
       " 1457: 4,\n",
       " 1525: 17,\n",
       " 1526: 23,\n",
       " 1527: 16,\n",
       " 1528: 5,\n",
       " 1529: 12,\n",
       " 1530: 3,\n",
       " 1531: 6,\n",
       " 1533: 11,\n",
       " 1534: 6,\n",
       " 1535: 7,\n",
       " 1536: 8,\n",
       " 1537: 5,\n",
       " 1538: 7,\n",
       " 1539: 7,\n",
       " 1540: 11,\n",
       " 1631: 5,\n",
       " 15: 3,\n",
       " 16: 10,\n",
       " 20: 4,\n",
       " 40: 3,\n",
       " 57: 9,\n",
       " 86: 12,\n",
       " 88: 2,\n",
       " 89: 4,\n",
       " 165: 11,\n",
       " 199: 7,\n",
       " 211: 3,\n",
       " 212: 11,\n",
       " 254: 8,\n",
       " 277: 3,\n",
       " 311: 2,\n",
       " 312: 3,\n",
       " 377: 9,\n",
       " 465: 10,\n",
       " 466: 12,\n",
       " 497: 6,\n",
       " 498: 7,\n",
       " 499: 13,\n",
       " 500: 5,\n",
       " 501: 12,\n",
       " 502: 7,\n",
       " 503: 12,\n",
       " 504: 21,\n",
       " 604: 3,\n",
       " 605: 13,\n",
       " 626: 3,\n",
       " 712: 3,\n",
       " 713: 10,\n",
       " 770: 3,\n",
       " 771: 3,\n",
       " 772: 3,\n",
       " 773: 3,\n",
       " 774: 3,\n",
       " 775: 5,\n",
       " 776: 6,\n",
       " 777: 11,\n",
       " 778: 6,\n",
       " 888: 3,\n",
       " 889: 9,\n",
       " 890: 6,\n",
       " 891: 6,\n",
       " 892: 3,\n",
       " 893: 5,\n",
       " 894: 10,\n",
       " 895: 9,\n",
       " 896: 6,\n",
       " 897: 4,\n",
       " 898: 3,\n",
       " 899: 13,\n",
       " 900: 5,\n",
       " 901: 13,\n",
       " 902: 9,\n",
       " 903: 6,\n",
       " 904: 10,\n",
       " 1114: 5,\n",
       " 1115: 9,\n",
       " 1116: 6,\n",
       " 1117: 12,\n",
       " 1118: 9,\n",
       " 1119: 3,\n",
       " 1120: 2,\n",
       " 1121: 3,\n",
       " 1122: 3,\n",
       " 1150: 4,\n",
       " 1151: 5,\n",
       " 1152: 20,\n",
       " 1153: 13,\n",
       " 1164: 7,\n",
       " 1165: 5,\n",
       " 1166: 3,\n",
       " 1167: 6,\n",
       " 1168: 12,\n",
       " 1169: 11,\n",
       " 1170: 4,\n",
       " 1171: 4,\n",
       " 1172: 8,\n",
       " 1173: 13,\n",
       " 1174: 3,\n",
       " 1175: 4,\n",
       " 1176: 2,\n",
       " 1177: 10,\n",
       " 1262: 10,\n",
       " 1263: 10,\n",
       " 1401: 9,\n",
       " 1402: 5,\n",
       " 1403: 5,\n",
       " 1404: 11,\n",
       " 1405: 17,\n",
       " 1406: 4,\n",
       " 1407: 5,\n",
       " 1408: 9,\n",
       " 1409: 4,\n",
       " 1410: 9,\n",
       " 1411: 4,\n",
       " 1431: 4,\n",
       " 1432: 5,\n",
       " 1433: 6,\n",
       " 1434: 6,\n",
       " 1435: 8,\n",
       " 1436: 3,\n",
       " 1437: 3,\n",
       " 1438: 2,\n",
       " 1439: 3,\n",
       " 1440: 9,\n",
       " 1441: 3,\n",
       " 1442: 3,\n",
       " 1492: 13,\n",
       " 1493: 4,\n",
       " 1494: 7,\n",
       " 1495: 9,\n",
       " 1497: 5,\n",
       " 1498: 3,\n",
       " 1499: 6,\n",
       " 1635: 5,\n",
       " 17: 16,\n",
       " 53: 15,\n",
       " 67: 26,\n",
       " 78: 34,\n",
       " 79: 8,\n",
       " 91: 10,\n",
       " 92: 22,\n",
       " 104: 11,\n",
       " 111: 10,\n",
       " 129: 11,\n",
       " 136: 24,\n",
       " 159: 20,\n",
       " 160: 9,\n",
       " 161: 26,\n",
       " 162: 18,\n",
       " 219: 10,\n",
       " 220: 10,\n",
       " 221: 15,\n",
       " 222: 14,\n",
       " 228: 13,\n",
       " 230: 29,\n",
       " 232: 24,\n",
       " 233: 10,\n",
       " 240: 9,\n",
       " 241: 26,\n",
       " 242: 9,\n",
       " 252: 9,\n",
       " 300: 8,\n",
       " 301: 6,\n",
       " 302: 11,\n",
       " 303: 14,\n",
       " 304: 16,\n",
       " 330: 5,\n",
       " 335: 8,\n",
       " 336: 13,\n",
       " 364: 8,\n",
       " 376: 12,\n",
       " 422: 10,\n",
       " 423: 10,\n",
       " 424: 11,\n",
       " 425: 9,\n",
       " 426: 9,\n",
       " 427: 10,\n",
       " 428: 12,\n",
       " 429: 12,\n",
       " 449: 9,\n",
       " 450: 12,\n",
       " 453: 12,\n",
       " 469: 17,\n",
       " 471: 32,\n",
       " 472: 8,\n",
       " 619: 10,\n",
       " 620: 12,\n",
       " 636: 29,\n",
       " 637: 18,\n",
       " 638: 6,\n",
       " 639: 10,\n",
       " 640: 24,\n",
       " 641: 7,\n",
       " 642: 11,\n",
       " 706: 22,\n",
       " 707: 16,\n",
       " 708: 16,\n",
       " 709: 29,\n",
       " 710: 23,\n",
       " 715: 11,\n",
       " 716: 9,\n",
       " 717: 8,\n",
       " 846: 20,\n",
       " 847: 23,\n",
       " 848: 12,\n",
       " 849: 15,\n",
       " 850: 7,\n",
       " 854: 10,\n",
       " 855: 21,\n",
       " 856: 13,\n",
       " 857: 12,\n",
       " 858: 32,\n",
       " 859: 13,\n",
       " 860: 16,\n",
       " 861: 23,\n",
       " 862: 14,\n",
       " 863: 9,\n",
       " 1098: 15,\n",
       " 1099: 33,\n",
       " 1100: 8,\n",
       " 1101: 23,\n",
       " 1102: 29,\n",
       " 1516: 15,\n",
       " 1626: 11,\n",
       " 1627: 8,\n",
       " 1628: 30,\n",
       " 1629: 11,\n",
       " 18: 15,\n",
       " 24: 32,\n",
       " 26: 9,\n",
       " 27: 32,\n",
       " 81: 7,\n",
       " 105: 13,\n",
       " 106: 10,\n",
       " 113: 17,\n",
       " 114: 20,\n",
       " 127: 5,\n",
       " 198: 10,\n",
       " 200: 16,\n",
       " 201: 17,\n",
       " 202: 27,\n",
       " 203: 8,\n",
       " 204: 13,\n",
       " 205: 30,\n",
       " 206: 12,\n",
       " 207: 24,\n",
       " 208: 16,\n",
       " 209: 16,\n",
       " 210: 20,\n",
       " 383: 8,\n",
       " 384: 6,\n",
       " 385: 15,\n",
       " 386: 20,\n",
       " 475: 19,\n",
       " 476: 12,\n",
       " 477: 34,\n",
       " 645: 13,\n",
       " 646: 22,\n",
       " 647: 10,\n",
       " 648: 10,\n",
       " 649: 16,\n",
       " 650: 15,\n",
       " 651: 16,\n",
       " 652: 5,\n",
       " 653: 9,\n",
       " 654: 6,\n",
       " 655: 2,\n",
       " 673: 10,\n",
       " 674: 16,\n",
       " 675: 23,\n",
       " 676: 13,\n",
       " 677: 18,\n",
       " 678: 12,\n",
       " 679: 29,\n",
       " 680: 24,\n",
       " 681: 3,\n",
       " 682: 6,\n",
       " 683: 16,\n",
       " 684: 24,\n",
       " 685: 29,\n",
       " 686: 29,\n",
       " 687: 17,\n",
       " 806: 10,\n",
       " 807: 17,\n",
       " 808: 10,\n",
       " 809: 6,\n",
       " 810: 10,\n",
       " 811: 11,\n",
       " 812: 10,\n",
       " 813: 10,\n",
       " 814: 20,\n",
       " 815: 9,\n",
       " 816: 5,\n",
       " 817: 8,\n",
       " 818: 2,\n",
       " 819: 18,\n",
       " 994: 30,\n",
       " 995: 33,\n",
       " 996: 17,\n",
       " 1009: 11,\n",
       " 1027: 11,\n",
       " 1028: 9,\n",
       " 1029: 16,\n",
       " 1030: 10,\n",
       " 1031: 17,\n",
       " 1032: 10,\n",
       " 1033: 13,\n",
       " 1034: 11,\n",
       " 1035: 13,\n",
       " 1036: 5,\n",
       " 1207: 2,\n",
       " 1208: 3,\n",
       " 1209: 3,\n",
       " 1210: 6,\n",
       " 1211: 2,\n",
       " 1212: 2,\n",
       " 1213: 23,\n",
       " 1469: 13,\n",
       " 1470: 4,\n",
       " 1471: 3,\n",
       " 1472: 4,\n",
       " 1473: 5,\n",
       " 19: 13,\n",
       " 63: 11,\n",
       " 225: 4,\n",
       " 21: 9,\n",
       " 22: 16,\n",
       " 39: 11,\n",
       " 66: 13,\n",
       " 84: 11,\n",
       " 85: 26,\n",
       " 117: 14,\n",
       " 118: 30,\n",
       " 157: 6,\n",
       " 158: 7,\n",
       " 247: 24,\n",
       " 248: 10,\n",
       " 249: 25,\n",
       " 250: 6,\n",
       " 298: 5,\n",
       " 299: 10,\n",
       " 316: 9,\n",
       " 317: 6,\n",
       " 318: 13,\n",
       " 401: 9,\n",
       " 402: 6,\n",
       " 403: 12,\n",
       " 404: 6,\n",
       " 405: 9,\n",
       " 406: 16,\n",
       " 531: 11,\n",
       " 532: 10,\n",
       " 533: 5,\n",
       " 534: 10,\n",
       " ...}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemID</th>\n",
       "      <th>demandPrediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   itemID  demandPrediction\n",
       "0       1                17\n",
       "1       2                31\n",
       "2       3                 7\n",
       "3       4                15\n",
       "4       5                20"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = items[['itemID']].copy()\n",
    "submission['demandPrediction'] = items[\"itemID\"].map(preds)\n",
    "submission.to_csv('../../submissions/final_submission.csv', sep = '|', index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(submission[\"demandPrediction\"] == 0).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
