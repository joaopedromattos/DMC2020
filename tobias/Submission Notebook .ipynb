{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0v.zip\r\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from utils_submission import *\n",
    "import sys\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from datetime import datetime\n",
    "\n",
    "NUMBER_OF_LAGS = 4\n",
    "\n",
    "sys.path.append(\"../../main/datasets/\")\n",
    "!ls  ../../main/datasets/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline_score function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_score(prediction, target, simulatedPrice):\n",
    "    prediction = prediction.astype(int)\n",
    "\n",
    "    return np.sum((prediction - np.maximum(prediction - target, 0) * 1.6)  * simulatedPrice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feval(prediction, dtrain):\n",
    "    \n",
    "    prediction = prediction.astype(int)\n",
    "    target = dtrain.get_label()\n",
    "\n",
    "    simulatedPrice = dtrain.get_weight()\n",
    "    \n",
    "    return 'feval', np.sum((prediction - np.maximum(prediction - target, 0) * 1.6)  * simulatedPrice), True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building our dataset\n",
    "This notebook makes this step cleaner than the previous versions. So It'll be tidier and shorter than before!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity checks... (10463, 3) (10463, 8) (2181955, 5)\n"
     ]
    }
   ],
   "source": [
    "infos, items, orders = read_data(\"../../main/datasets/\")\n",
    "print(\"Sanity checks...\", infos.shape, items.shape, orders.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing our time signatures\n",
    "process_time(orders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset_builder(orders, items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tobias's transaction features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiIndex = pd.MultiIndex.from_product([items['itemID'], range(13, -1, -1)], names=['itemID', 'group_backwards'])\n",
    "aux = pd.DataFrame(index=multiIndex)\n",
    "\n",
    "orders['transactions'] = 1\n",
    "item_transactions = orders.groupby(['itemID', 'group_backwards']).agg(item_transactions=('transactions','sum'))\n",
    "\n",
    "# Adding this multiindex\n",
    "item_transactions = pd.merge(aux, item_transactions, left_on=['itemID', 'group_backwards'], right_on=['itemID', 'group_backwards'], how='left')\n",
    "\n",
    "item_transactions = item_transactions.groupby(['itemID'])[['item_transactions']].shift(1)\n",
    "df = pd.merge(df, item_transactions, left_on=['group_backwards', 'itemID'], right_on=['group_backwards', 'itemID'], how='left')\n",
    "\n",
    "# I could have done this so much easier than this way...\n",
    "# ... but I won't spend time refatoring it.\n",
    "singleIndex = pd.MultiIndex.from_product([range(13, -1, -1)], names=['group_backwards'])\n",
    "last_week_index = pd.DataFrame(index=singleIndex)\n",
    "\n",
    "last_week_transactions = orders.groupby(['group_backwards']).agg(last_week_transactions=('transactions','sum'))\n",
    "last_week_transactions = pd.merge(last_week_index, last_week_transactions, left_on=['group_backwards'], right_on=['group_backwards'], how='left')\n",
    "\n",
    "last_week_transactions = last_week_transactions.shift(1).fillna(0)\n",
    "\n",
    "df = pd.merge(df, last_week_transactions, left_on=['group_backwards'], right_on=['group_backwards'], how='left', validate='m:1')\n",
    "\n",
    "df = df.fillna(0)\n",
    "df['transactions_feature'] = df['item_transactions'] + df['last_week_transactions']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adding 'is_new'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-0bd0425dea58>:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  notSoldItems['first_appearance'] = 0\n"
     ]
    }
   ],
   "source": [
    "# This cell adds a feature responsible for indicating if in the current week\n",
    "# a given item has its first appearance.\n",
    "orders_sorted_by_week = orders.sort_values('group_backwards', ascending=False)\n",
    "weeks_grouped_by_items = orders_sorted_by_week.groupby('itemID', as_index=False)\n",
    "items_first_appearance = weeks_grouped_by_items.first()[['itemID', 'group_backwards']]\n",
    "\n",
    "items_first_appearance.rename(columns={'group_backwards':'first_appearance'}, inplace=True)\n",
    "\n",
    "# We'll need to change this code a little bit to use this feature to submission.\n",
    "# These lines take for granted that if an item didn't sell any units in the entire\n",
    "# dataset, It MUST be sold on week 0...\n",
    "allSales = df.groupby('itemID', as_index=False).agg({'orderSum':'sum'})\n",
    "notSoldItems = allSales.loc[allSales['orderSum'] == 0]\n",
    "notSoldItems['first_appearance'] = 0\n",
    "items_first_appearance = pd.concat([items_first_appearance, notSoldItems.drop(columns=['orderSum'])])\n",
    "\n",
    "df['is_new'] = 0\n",
    "\n",
    "df = pd.merge(df, items_first_appearance, left_on=['itemID'], right_on=['itemID'], how='left', validate='m:1')\n",
    "\n",
    "df.loc[df['first_appearance'] == df['group_backwards'], 'is_new'] = 1\n",
    "\n",
    "df.drop(columns=['first_appearance'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1431\n",
      "729\n",
      "371\n",
      "533\n",
      "785\n",
      "909\n",
      "716\n",
      "661\n",
      "785\n",
      "671\n",
      "794\n",
      "727\n",
      "728\n",
      "623\n"
     ]
    }
   ],
   "source": [
    "for i in range(13, -1, -1):\n",
    "    print(df.query('group_backwards == @i')['is_new'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.0\n",
       "1        0.0\n",
       "2        0.0\n",
       "3        0.0\n",
       "4        0.0\n",
       "        ... \n",
       "10458    0.0\n",
       "10459    0.0\n",
       "10460    0.0\n",
       "10461    0.0\n",
       "10462    0.0\n",
       "Name: transactions_feature, Length: 10463, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shifting.query('group_backwards == 13')['transactions_feature']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How many new items by category and manufacturer (Tobias's contribuition)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_manufacturers = df.groupby(['group_backwards', 'manufacturer']).is_new.sum().reset_index().rename(columns={'is_new':'new_manufacturers'})\n",
    "df = pd.merge(df, new_manufacturers, left_on=['group_backwards', 'manufacturer'], right_on=['group_backwards', 'manufacturer'], how='left', validate='m:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cat3 = df.groupby(['group_backwards', 'category3']).is_new.sum().reset_index().rename(columns={'is_new':'new_cat3'})\n",
    "df = pd.merge(df, new_cat3, left_on=['group_backwards', 'category3'], right_on=['group_backwards', 'category3'], how='left', validate='m:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cat2 = df.groupby(['group_backwards', 'category2']).is_new.sum().reset_index().rename(columns={'is_new':'new_cat2'})\n",
    "df = pd.merge(df, new_cat2, left_on=['group_backwards', 'category2'], right_on=['group_backwards', 'category2'], how='left', validate='m:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cat1 = df.groupby(['group_backwards', 'category1']).is_new.sum().reset_index().rename(columns={'is_new':'new_cat1'})\n",
    "df = pd.merge(df, new_cat1, left_on=['group_backwards', 'category1'], right_on=['group_backwards', 'category1'], how='left', validate='m:1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cumulative sale by category**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage_accum_cat_3 feature...\n",
    "df = cumulative_sale_by_category(df, category='category3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Time Encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding our weeks as a series of sines and cosines...\n",
    "# This function will consider our period as a semester in a year,\n",
    "# so we can try other types of time encoding later!\n",
    "df = time_encoder(df, 'group_backwards', 26)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lags and diffs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell lags and diffs our feature 'orderSum'\n",
    "shifting = df.copy()\n",
    "\n",
    "for i in range(1, NUMBER_OF_LAGS + 1):\n",
    "    # Carrying the data of weeks t-1\n",
    "    shifting[f'orderSum_{i}'] = shifting.groupby('itemID')['orderSum'].shift(i)\n",
    "\n",
    "    # Getting the difference of the orders and promotions between weeks t-1 and t-2...\n",
    "    shifting[f'orderSum_diff_{i}'] = shifting.groupby('itemID')[f'orderSum_{i}'].diff()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rolling window \"orderSum\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.6 s, sys: 317 ms, total: 36.9 s\n",
      "Wall time: 37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# This cell creates rolling-window features based on 'orderSum' in our dataset!\n",
    "item_group = shifting.groupby([\"itemID\", \"group_backwards\"]).agg({'orderSum':'sum'})\n",
    "\n",
    "# We'll .shift(-1) because it sorts our \"group_backwards\", \n",
    "# so doing .shift(1) would cause a HUGE dataleak.\n",
    "aux_shifting = item_group.groupby('itemID')[['orderSum']].shift(-1)\n",
    "\n",
    "aux_shifting.sort_values(['itemID', 'group_backwards'], ascending=[True, False], inplace=True)\n",
    "\n",
    "for i in range(3):\n",
    "    rolled_window = aux_shifting.groupby(['itemID'], as_index=False)[['orderSum']].rolling(2 ** i).mean()\n",
    "    rolled_window.rename(columns={'orderSum':f\"orderSum_mean_rolled_{i}\"}, inplace=True)\n",
    "    shifting = pd.merge(shifting, rolled_window, left_on=['itemID', 'group_backwards'], right_on=['itemID', 'group_backwards'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGBM Says on docs that it automatically handles zero values as NaN,\n",
    "# so we'll keep this standard...\n",
    "shifting.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's take a moment to apreciate this beautiful dataset, shall we?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_backwards</th>\n",
       "      <th>itemID</th>\n",
       "      <th>orderSum</th>\n",
       "      <th>brand</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>customerRating</th>\n",
       "      <th>category1</th>\n",
       "      <th>category2</th>\n",
       "      <th>category3</th>\n",
       "      <th>recommendedRetailPrice</th>\n",
       "      <th>...</th>\n",
       "      <th>orderSum_diff_1</th>\n",
       "      <th>orderSum_2</th>\n",
       "      <th>orderSum_diff_2</th>\n",
       "      <th>orderSum_3</th>\n",
       "      <th>orderSum_diff_3</th>\n",
       "      <th>orderSum_4</th>\n",
       "      <th>orderSum_diff_4</th>\n",
       "      <th>orderSum_mean_rolled_0</th>\n",
       "      <th>orderSum_mean_rolled_1</th>\n",
       "      <th>orderSum_mean_rolled_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.84</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>16.92</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>15.89</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.44</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>40.17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17.04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146477</th>\n",
       "      <td>0</td>\n",
       "      <td>10459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180</td>\n",
       "      <td>253</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>56.57</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146478</th>\n",
       "      <td>0</td>\n",
       "      <td>10460</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>253</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>163.81</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146479</th>\n",
       "      <td>0</td>\n",
       "      <td>10461</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>253</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>128.01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146480</th>\n",
       "      <td>0</td>\n",
       "      <td>10462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180</td>\n",
       "      <td>253</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>166.97</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146481</th>\n",
       "      <td>0</td>\n",
       "      <td>10463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>253</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>154.82</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146482 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        group_backwards  itemID  orderSum  brand  manufacturer  \\\n",
       "0                    13       1       0.0      0             1   \n",
       "1                    13       2       0.0      0             2   \n",
       "2                    13       3       1.0      0             3   \n",
       "3                    13       4       0.0      0             2   \n",
       "4                    13       5       2.0      0             2   \n",
       "...                 ...     ...       ...    ...           ...   \n",
       "146477                0   10459       0.0    180           253   \n",
       "146478                0   10460       0.0      0           253   \n",
       "146479                0   10461       0.0      0           253   \n",
       "146480                0   10462       0.0    180           253   \n",
       "146481                0   10463       0.0      0           253   \n",
       "\n",
       "        customerRating  category1  category2  category3  \\\n",
       "0                 4.38          1          1          1   \n",
       "1                 3.00          1          2          1   \n",
       "2                 5.00          1          3          1   \n",
       "3                 4.44          1          2          1   \n",
       "4                 2.33          1          1          1   \n",
       "...                ...        ...        ...        ...   \n",
       "146477            0.00          8         44          8   \n",
       "146478            0.00          8         44          8   \n",
       "146479            0.00          8         44          8   \n",
       "146480            0.00          8         44          8   \n",
       "146481            0.00          8         44          8   \n",
       "\n",
       "        recommendedRetailPrice  ...  orderSum_diff_1  orderSum_2  \\\n",
       "0                         8.84  ...              0.0         0.0   \n",
       "1                        16.92  ...              0.0         0.0   \n",
       "2                        15.89  ...              0.0         0.0   \n",
       "3                        40.17  ...              0.0         0.0   \n",
       "4                        17.04  ...              0.0         0.0   \n",
       "...                        ...  ...              ...         ...   \n",
       "146477                   56.57  ...              0.0         0.0   \n",
       "146478                  163.81  ...              0.0         0.0   \n",
       "146479                  128.01  ...              0.0         0.0   \n",
       "146480                  166.97  ...              0.0         0.0   \n",
       "146481                  154.82  ...              0.0         0.0   \n",
       "\n",
       "        orderSum_diff_2  orderSum_3  orderSum_diff_3  orderSum_4  \\\n",
       "0                   0.0         0.0              0.0         0.0   \n",
       "1                   0.0         0.0              0.0         0.0   \n",
       "2                   0.0         0.0              0.0         0.0   \n",
       "3                   0.0         0.0              0.0         0.0   \n",
       "4                   0.0         0.0              0.0         0.0   \n",
       "...                 ...         ...              ...         ...   \n",
       "146477              0.0         0.0             -1.0         1.0   \n",
       "146478              0.0         0.0              0.0         0.0   \n",
       "146479              0.0         0.0              0.0         0.0   \n",
       "146480              0.0         0.0              0.0         0.0   \n",
       "146481             -1.0         1.0              1.0         0.0   \n",
       "\n",
       "        orderSum_diff_4  orderSum_mean_rolled_0  orderSum_mean_rolled_1  \\\n",
       "0                   0.0                     0.0                     0.0   \n",
       "1                   0.0                     0.0                     0.0   \n",
       "2                   0.0                     0.0                     0.0   \n",
       "3                   0.0                     0.0                     0.0   \n",
       "4                   0.0                     0.0                     0.0   \n",
       "...                 ...                     ...                     ...   \n",
       "146477              1.0                     0.0                     0.0   \n",
       "146478              0.0                     0.0                     0.0   \n",
       "146479              0.0                     0.0                     0.0   \n",
       "146480             -1.0                     0.0                     0.0   \n",
       "146481              0.0                     0.0                     0.0   \n",
       "\n",
       "        orderSum_mean_rolled_2  \n",
       "0                         0.00  \n",
       "1                         0.00  \n",
       "2                         0.00  \n",
       "3                         0.00  \n",
       "4                         0.00  \n",
       "...                        ...  \n",
       "146477                    0.25  \n",
       "146478                    0.00  \n",
       "146479                    0.00  \n",
       "146480                    0.00  \n",
       "146481                    0.25  \n",
       "\n",
       "[146482 rows x 32 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "shifting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Splitting (Train until week 3 / Val. week 2/ Test week 1)\n",
    "All my experiments will use weeks 13 to 3 as a train set, week 2 as our validation set and week 1 as a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = shifting.loc[shifting.group_backwards >= 3]\n",
    "val = shifting.loc[shifting.group_backwards == 2]\n",
    "test = shifting.loc[shifting.group_backwards == 1]\n",
    "\n",
    "weights = infos.set_index('itemID')['simulationPrice'].to_dict()\n",
    "\n",
    "w_train = train['itemID'].map(weights)\n",
    "w_val = val['itemID'].map(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I recommend to the other members of the team keeping the\n",
    "# datatypes of our datasets as Pandas DataFrames instead of Numpy,\n",
    "# since It will easier to use Boosting Analysis frameworks\n",
    "y_train = train['orderSum']\n",
    "y_val = val['orderSum']\n",
    "X_train = train.drop(columns=[\"orderSum\"])\n",
    "X_val = val.drop(columns=[\"orderSum\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['group_backwards', 'itemID', 'brand', 'manufacturer', 'customerRating',\n",
       "       'category1', 'category2', 'category3', 'recommendedRetailPrice',\n",
       "       'item_transactions', 'last_week_transactions', 'transactions_feature',\n",
       "       'is_new', 'new_manufacturers', 'new_cat3', 'new_cat2', 'new_cat1',\n",
       "       'percentage_accum_category3', 'group_backwards_sin',\n",
       "       'group_backwards_cos', 'orderSum_1', 'orderSum_diff_1', 'orderSum_2',\n",
       "       'orderSum_diff_2', 'orderSum_3', 'orderSum_diff_3', 'orderSum_4',\n",
       "       'orderSum_diff_4', 'orderSum_mean_rolled_0', 'orderSum_mean_rolled_1',\n",
       "       'orderSum_mean_rolled_2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joaopedromattos/.local/lib/python3.8/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "[5]\ttraining's rmse: 39.2624\ttraining's feval: 6.15797e+06\tvalid_1's rmse: 44.2417\tvalid_1's feval: 489828\n",
      "[10]\ttraining's rmse: 38.9401\ttraining's feval: 7.10896e+06\tvalid_1's rmse: 43.9315\tvalid_1's feval: 564675\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's rmse: 38.9401\ttraining's feval: 7.11256e+06\tvalid_1's rmse: 43.9311\tvalid_1's feval: 565159\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "#           \"objective\" : \"poisson\",\n",
    "          \"objective\" : \"l1\",\n",
    "          \"metric\" :\"rmse\",\n",
    "          \"learning_rate\" : 0.6,\n",
    "          'verbosity': 1,\n",
    "          'max_depth': 6,\n",
    "          \"min_data_in_leaf\":2000,\n",
    "         }\n",
    "\n",
    "lgbtrain = lgb.Dataset(X_train, label = y_train, weight=w_train, categorical_feature=[2, 4, 5, 6, 7, 12])\n",
    "lgbvalid = lgb.Dataset(X_val, label = y_val, weight=w_val, categorical_feature=[2, 4, 5, 6, 7, 12])\n",
    "\n",
    "num_round = 1000\n",
    "model = lgb.train(params,\n",
    "                  lgbtrain,\n",
    "                  num_round,\n",
    "                  valid_sets = [lgbtrain, lgbvalid], \n",
    "                  verbose_eval=5,\n",
    "                  early_stopping_rounds=5,\n",
    "#                   fobj=objective,\n",
    "                  feval=feval,\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['category2', 'brand', 'new_manufacturers', 'percentage_accum_category3',\n",
       "       'is_new', 'group_backwards', 'orderSum_2', 'item_transactions',\n",
       "       'new_cat2', 'orderSum_diff_2', 'orderSum_diff_1', 'new_cat1',\n",
       "       'orderSum_mean_rolled_1', 'customerRating', 'orderSum_1',\n",
       "       'manufacturer', 'itemID', 'orderSum_diff_4', 'category3',\n",
       "       'recommendedRetailPrice', 'orderSum_mean_rolled_2',\n",
       "       'transactions_feature', 'orderSum_diff_3', 'orderSum_3', 'new_cat3',\n",
       "       'orderSum_4', 'category1', 'group_backwards_sin',\n",
       "       'orderSum_mean_rolled_0', 'group_backwards_cos',\n",
       "       'last_week_transactions'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns[list(reversed(model.feature_importance().argsort()))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**New items model with validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Taking the first appearance of each item...\n",
    "first_fortnight_item = orders.sort_values(\"group_backwards\",\n",
    "                                     ascending=False)\\\n",
    "                          .groupby([\"itemID\"])[\"group_backwards\"].first()\n",
    "first_fortnight_item = first_fortnight_item.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8385, 727, 728)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = shifting.loc[shifting.group_backwards >= 3]\n",
    "val = shifting.loc[shifting.group_backwards == 2]\n",
    "test = shifting.loc[shifting.group_backwards == 1]\n",
    "\n",
    "\n",
    "new_items_train = pd.merge(first_fortnight_item, train, on=[\"itemID\", \"group_backwards\"],\n",
    "                  how=\"inner\", validate=\"1:1\")\n",
    "new_items_val = pd.merge(first_fortnight_item, val, on=[\"itemID\", \"group_backwards\"],\n",
    "                  how=\"inner\", validate=\"1:1\")\n",
    "new_items_test = pd.merge(first_fortnight_item, test, on=[\"itemID\", \"group_backwards\"],\n",
    "                  how=\"inner\", validate=\"1:1\")\n",
    "\n",
    "# Check we didn't make mistakes...\n",
    "assert len(new_items_train) + len(new_items_val) + len(new_items_test) == len(first_fortnight_item)\n",
    "assert len(first_fortnight_item.query(\"group_backwards >= 3\")) == len(new_items_train)\n",
    "assert len(first_fortnight_item.query(\"group_backwards == 2\")) == len(new_items_val)\n",
    "assert len(first_fortnight_item.query(\"group_backwards == 1\")) == len(new_items_test)\n",
    "\n",
    "len(new_items_train), len(new_items_val), len(new_items_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_new_items_train = new_items_train['itemID'].map(weights)\n",
    "w_new_items_val = new_items_val['itemID'].map(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_new_items_train = new_items_train['orderSum']\n",
    "y_new_items_val = new_items_val['orderSum']\n",
    "y_new_items_test = new_items_test['orderSum']\n",
    "# Maybe other features don't make sense\n",
    "X_new_items_train = new_items_train.drop(columns=[\"orderSum\", \"itemID\", \"is_new\"])\n",
    "X_new_items_val = new_items_val.drop(columns=[\"orderSum\", \"itemID\", \"is_new\"])\n",
    "X_new_items_test = new_items_test.drop(columns=[\"orderSum\", \"itemID\", \"is_new\"])\n",
    "# Make sure to change the categorical features if you drop more cols\n",
    "cat_feats = [1, 2, 4, 5, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "[5]\ttraining's rmse: 75.7426\ttraining's feval: 6.83009e+06\tvalid_1's rmse: 95.9824\tvalid_1's feval: 815903\n",
      "[10]\ttraining's rmse: 69.3136\ttraining's feval: 1.03007e+07\tvalid_1's rmse: 89.9562\tvalid_1's feval: 1.00066e+06\n",
      "[15]\ttraining's rmse: 65.1485\ttraining's feval: 1.2268e+07\tvalid_1's rmse: 87.6193\tvalid_1's feval: 1.07888e+06\n",
      "[20]\ttraining's rmse: 63.1203\ttraining's feval: 1.32957e+07\tvalid_1's rmse: 86.3373\tvalid_1's feval: 1.12503e+06\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's rmse: 63.9206\ttraining's feval: 1.28882e+07\tvalid_1's rmse: 86.0919\tvalid_1's feval: 1.11692e+06\n"
     ]
    }
   ],
   "source": [
    "params2 = {\n",
    "#           \"objective\" : \"poisson\",\n",
    "          #\"objective\" : \"l1\",\n",
    "          \"objective\" : \"l2\", # L2 works MUCH BETTER than L1\n",
    "          \"metric\" :\"rmse\",\n",
    "          #\"learning_rate\" : 0.5,\n",
    "          'verbosity': 1,\n",
    "          'max_depth': 5,\n",
    "          #'num_leaves': 32,\n",
    "#           \"min_data_in_leaf\":2500,\n",
    "         }\n",
    "lgbtrain2 = lgb.Dataset(X_new_items_train, label=y_new_items_train, weight=w_new_items_train, \n",
    "                        categorical_feature=cat_feats)\n",
    "lgbvalid2 = lgb.Dataset(X_new_items_val, label=y_new_items_val, weight=w_new_items_val, \n",
    "                        categorical_feature=cat_feats)\n",
    "\n",
    "num_round = 1000\n",
    "model_new_items = lgb.train(params2,\n",
    "                  lgbtrain2,\n",
    "                  num_round,\n",
    "                  valid_sets = [lgbtrain2, lgbvalid2], \n",
    "                  verbose_eval=5,\n",
    "                  early_stopping_rounds=5,\n",
    "#                   fobj=objective,\n",
    "                  feval=feval,\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:red'>Submission training</span>\n",
    "Here'll (finally) train with our entire dataset to submit our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = shifting.loc[shifting.group_backwards >= 1]\n",
    "test = shifting.loc[shifting.group_backwards == 0]\n",
    "\n",
    "weights = infos.set_index('itemID')['simulationPrice'].to_dict()\n",
    "\n",
    "w_train = train['itemID'].map(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I recommend to the other members of the team keeping the\n",
    "# datatypes of our datasets as Pandas DataFrames instead of Numpy,\n",
    "# since It will easier to use Boosting Analysis frameworks\n",
    "y_train = train['orderSum']\n",
    "X_train = train.drop(columns=[\"orderSum\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "#           \"objective\" : \"poisson\",\n",
    "          \"objective\" : \"l1\",\n",
    "          \"metric\" :\"rmse\",\n",
    "          \"learning_rate\" : 0.6,\n",
    "          'verbosity': 1,\n",
    "          'max_depth': 6,\n",
    "          'num_leaves': 32,\n",
    "          \"min_data_in_leaf\":2000,\n",
    "         }\n",
    "\n",
    "lgbtrain = lgb.Dataset(X_train, label = y_train, weight=w_train, categorical_feature=[2, 3, 5, 6, 7, 9])\n",
    "\n",
    "model = lgb.train(params,\n",
    "                  lgbtrain,\n",
    "                  model.best_iteration,\n",
    "                  valid_sets = [lgbtrain], \n",
    "                  valid_names = ['train'],\n",
    "                  verbose_eval=5,\n",
    "                  early_stopping_rounds=5,\n",
    "#                   fobj=objective,\n",
    "                  feval=feval,\n",
    "                  \n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**New items model without validation for week 0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Taking the first appearance of each item...\n",
    "first_fortnight_item = orders.sort_values(\"group_backwards\",\n",
    "                                     ascending=False)\\\n",
    "                          .groupby([\"itemID\"])[\"group_backwards\"].first()\n",
    "first_fortnight_item = first_fortnight_item.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_items_train = pd.merge(first_fortnight_item, train, on=[\"itemID\", \"group_backwards\"],\n",
    "                  how=\"inner\", validate=\"1:1\")\n",
    "\n",
    "\"\"\"\n",
    "THIS IS WHERE WE INSERT OUR TEST LEAK.\n",
    "Note that this change in the pipeline is necessary due to the fact that\n",
    "now we're submitting our results!!!\n",
    "\"\"\"\n",
    "all_items_orders = shifting.groupby('itemID').agg({'orderSum':'sum'})\n",
    "items_not_sold = all_items_orders.loc[all_items_orders['orderSum'] == 0].copy()\n",
    "items_not_sold['group_backwards'] = 0\n",
    "items_not_sold = items_not_sold.reset_index().drop(columns=['orderSum'])\n",
    "new_items_test = pd.merge(items_not_sold, test, on=[\"itemID\", \"group_backwards\"],\n",
    "                  how=\"inner\", validate=\"1:1\")\n",
    "\n",
    "# Check we didn't make mistakes...\n",
    "assert len(new_items_train) == len(first_fortnight_item) # Changed this sanity check...\n",
    "assert len(first_fortnight_item.query(\"group_backwards >= 1\")) == len(new_items_train)\n",
    "assert len(items_not_sold) == len(new_items_test) # Changed this sanity check...\n",
    "\n",
    "len(new_items_train), len(new_items_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_new_items_train = new_items_train['itemID'].map(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_new_items_train = new_items_train['orderSum']\n",
    "y_new_items_test = new_items_test['orderSum']\n",
    "# Maybe other features don't make sense\n",
    "X_new_items_train = new_items_train.drop(columns=[\"orderSum\", \"itemID\", \"is_new\"])\n",
    "X_new_items_test = new_items_test.drop(columns=[\"orderSum\", \"itemID\", \"is_new\"])\n",
    "\n",
    "# Make sure to change the categorical features if you drop more cols\n",
    "cat_feats = [1, 2, 4, 5, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_items_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params2 = {\n",
    "#           \"objective\" : \"poisson\",\n",
    "          #\"objective\" : \"l1\",\n",
    "          \"objective\" : \"l2\", # L2 works MUCH BETTER than L1\n",
    "          \"metric\" :\"rmse\",\n",
    "          #\"learning_rate\" : 0.5,\n",
    "          'verbosity': 1,\n",
    "          'max_depth': 5,\n",
    "          #'num_leaves': 32,\n",
    "#           \"min_data_in_leaf\":2500,\n",
    "         }\n",
    "lgbtrain2 = lgb.Dataset(X_new_items_train, label=y_new_items_train, weight=w_new_items_train, \n",
    "                        categorical_feature=cat_feats)\n",
    "\n",
    "model_new_items = lgb.train(params2,\n",
    "                  lgbtrain2,\n",
    "                  model_new_items.best_iteration,\n",
    "                  valid_sets = [lgbtrain2], \n",
    "                  verbose_eval=5,\n",
    "                  early_stopping_rounds=5,\n",
    "#                   fobj=objective,\n",
    "                  feval=feval,\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predicting \"common\" items at test time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns == train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "LightGBMError",
     "evalue": "The number of features in data (28) is not the same as it was in training data (27).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-d6c1ec7544e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'orderSum'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"orderSum\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfinal_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape, **kwargs)\u001b[0m\n\u001b[1;32m   2411\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnum_iteration\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2412\u001b[0m             \u001b[0mnum_iteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2413\u001b[0;31m         return predictor.predict(data, num_iteration,\n\u001b[0m\u001b[1;32m   2414\u001b[0m                                  \u001b[0mraw_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_leaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2415\u001b[0m                                  data_has_header, is_reshape)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape)\u001b[0m\n\u001b[1;32m    533\u001b[0m             \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pred_for_csc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m             \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pred_for_np2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__pred_for_np2d\u001b[0;34m(self, mat, num_iteration, predict_type)\u001b[0m\n\u001b[1;32m    621\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0minner_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__pred_for_csr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36minner_predict\u001b[0;34m(mat, num_iteration, predict_type, preds)\u001b[0m\n\u001b[1;32m    592\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Wrong length of pre-allocated predict array\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m             \u001b[0mout_num_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m             _safe_call(_LIB.LGBM_BoosterPredictForMat(\n\u001b[0m\u001b[1;32m    595\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m                 \u001b[0mptr_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_safe_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \"\"\"\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecode_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLGBM_GetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLightGBMError\u001b[0m: The number of features in data (28) is not the same as it was in training data (27)."
     ]
    }
   ],
   "source": [
    "y_test = test['orderSum']\n",
    "X_test = test.drop(columns=[\"orderSum\"])\n",
    "final_predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predicting new items at test time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_new_items_predictions = model_new_items.predict(X_new_items_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mergin' predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert test[\"itemID\"].is_monotonic_increasing\n",
    "new_items_idx = X_test[\"itemID\"].isin(first_fortnight_item.query('group_backwards == 1')['itemID'])\n",
    "final_predictions[new_items_idx] = final_new_items_predictions\n",
    "final_predictions[final_predictions < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_score(final_predictions, y_test.values, infos['simulationPrice']) / 10 ** 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Items that are new in the test week**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions[new_items_idx] = 0\n",
    "final_predictions[final_predictions < 0] = 0\n",
    "baseline_score(final_predictions, y_test.values, infos['simulationPrice']) / 10 ** 6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
