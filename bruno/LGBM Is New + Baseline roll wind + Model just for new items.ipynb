{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#LGBM---New-Feature-+-Baseline-Rolling-Window\" data-toc-modified-id=\"LGBM---New-Feature-+-Baseline-Rolling-Window-1\">LGBM - New Feature + Baseline Rolling Window</a></span><ul class=\"toc-item\"><li><span><a href=\"#Defining-metrics\" data-toc-modified-id=\"Defining-metrics-1.1\">Defining metrics</a></span></li><li><span><a href=\"#Building-our-dataset\" data-toc-modified-id=\"Building-our-dataset-1.2\">Building our dataset</a></span></li><li><span><a href=\"#Feature-building\" data-toc-modified-id=\"Feature-building-1.3\">Feature building</a></span></li><li><span><a href=\"#Maximum-error\" data-toc-modified-id=\"Maximum-error-1.4\">Maximum error</a></span></li><li><span><a href=\"#Dataset-Splitting-(Train-until-week-3-/-Val.-week-2/-Test-week-1)\" data-toc-modified-id=\"Dataset-Splitting-(Train-until-week-3-/-Val.-week-2/-Test-week-1)-1.5\">Dataset Splitting (Train until week 3 / Val. week 2/ Test week 1)</a></span></li></ul></li><li><span><a href=\"#HOLY-FUCK\" data-toc-modified-id=\"HOLY-FUCK-2\">HOLY FUCK</a></span></li><li><span><a href=\"#FUCK-THE-ORIGINAL-MODEL,-LET'S-JUST-PREDICT-THE-NEW-ITEMS\" data-toc-modified-id=\"FUCK-THE-ORIGINAL-MODEL,-LET'S-JUST-PREDICT-THE-NEW-ITEMS-3\">FUCK THE ORIGINAL MODEL, LET'S JUST PREDICT THE NEW ITEMS</a></span></li><li><span><a href=\"#HAHAHAHAHAHAHAHAHAHAHAHA\" data-toc-modified-id=\"HAHAHAHAHAHAHAHAHAHAHAHA-4\">HAHAHAHAHAHAHAHAHAHAHAHA</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Utilities\" data-toc-modified-id=\"Utilities-4.0.1\">Utilities</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM - New Feature + Baseline Rolling Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0v  1.0v.zip\r\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from utils import *\n",
    "import sys\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from datetime import datetime\n",
    "\n",
    "NUMBER_OF_LAGS = 4\n",
    "\n",
    "sys.path.append(\"../main/datasets/\")\n",
    "!ls  ../main/datasets/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline_score function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_score(prediction, target, simulatedPrice):\n",
    "    prediction = prediction.astype(int)\n",
    "\n",
    "    return np.sum((prediction - np.maximum(prediction - target, 0) * 1.6)  * simulatedPrice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feval(prediction, dtrain):\n",
    "    \n",
    "    prediction = prediction.astype(int)\n",
    "    target = dtrain.get_label()\n",
    "\n",
    "    simulatedPrice = dtrain.get_weight()\n",
    "    \n",
    "    return 'feval', np.sum((prediction - np.maximum(prediction - target, 0) * 1.6)  * simulatedPrice), True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building our dataset\n",
    "This notebook makes this step cleaner than the previous versions. So It'll be tidier and shorter than before!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity checks... (10463, 3) (10463, 8) (2181955, 5)\n"
     ]
    }
   ],
   "source": [
    "infos, items, orders = read_data(\"../main/datasets/\")\n",
    "print(\"Sanity checks...\", infos.shape, items.shape, orders.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing our time signatures\n",
    "process_time(orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset_builder(orders, items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adding 'is_new'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell adds a feature responsible for indicating if in the current week\n",
    "# a given item has its first appearance.\n",
    "orders_sorted_by_week = orders.sort_values('group_backwards', ascending=False)\n",
    "weeks_grouped_by_items = orders_sorted_by_week.groupby('itemID', as_index=False)\n",
    "items_first_appearance = weeks_grouped_by_items.first()[['itemID', 'group_backwards']]\n",
    "\n",
    "items_first_appearance.rename(columns={'group_backwards':'first_appearance'}, inplace=True)\n",
    "\n",
    "df['is_new'] = 0\n",
    "\n",
    "df = pd.merge(df, items_first_appearance, left_on=['itemID'], right_on=['itemID'], how='left', validate='m:1')\n",
    "\n",
    "df.loc[df['first_appearance'] == df['group_backwards'], 'is_new'] = 1\n",
    "df.drop(columns=['first_appearance'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cumulative sale by category**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage_accum_cat_3 feature...\n",
    "df = cumulative_sale_by_category(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Time Encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding our weeks as a series of sines and cosines...\n",
    "# This function will consider our period as a semester in a year,\n",
    "# so we can try other types of time encoding later!\n",
    "df = time_encoder(df, 'group_backwards', 26)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lags and diffs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell lags and diffs our feature 'orderSum'\n",
    "shifting = df.copy()\n",
    "\n",
    "for i in range(1, NUMBER_OF_LAGS + 1):\n",
    "    # Carrying the data of weeks t-1\n",
    "    shifting[f'orderSum_{i}'] = shifting.groupby('itemID')['orderSum'].shift(i)\n",
    "\n",
    "    \n",
    "    # Getting the difference of the orders and promotions between weeks t-1 and t-2...\n",
    "    shifting[f'orderSum_diff_{i}'] = shifting.groupby('itemID')[f'orderSum_{i}'].diff()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rolling window \"orderSum\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 56.1 s, sys: 362 ms, total: 56.4 s\n",
      "Wall time: 56.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# This cell creates rolling-window features based on 'orderSum' in our dataset!\n",
    "item_group = shifting.groupby([\"itemID\", \"group_backwards\"]).agg({'orderSum':'sum'})\n",
    "\n",
    "# We'll .shift(-1) because it sorts our \"group_backwards\", \n",
    "# so doing .shift(1) would cause a HUGE dataleak.\n",
    "aux_shifting = item_group.groupby('itemID')[['orderSum']].shift(-1)\n",
    "\n",
    "aux_shifting.sort_values(['itemID', 'group_backwards'], ascending=[True, False], inplace=True)\n",
    "\n",
    "for i in range(3):\n",
    "    rolled_window = aux_shifting.groupby(['itemID'], as_index=False)[['orderSum']].rolling(2 ** i).mean()\n",
    "    rolled_window.rename(columns={'orderSum':f\"orderSum_mean_rolled_{i}\"}, inplace=True)\n",
    "    shifting = pd.merge(shifting, rolled_window, left_on=['itemID', 'group_backwards'], right_on=['itemID', 'group_backwards'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGBM Says on docs that it automatically handles zero values as NaN,\n",
    "# so we'll keep this standard...\n",
    "shifting.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum error\n",
    "The maximum error we could get in this dataset would be just guessing the mean of our sales from weeks 1 to 12, and that's what the cell below is computing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guessing the mean of 'orderSum' for all items in target 118.20105838913783\n"
     ]
    }
   ],
   "source": [
    "worst_possible_prediction = shifting.loc[shifting.group_backwards > 1]['orderSum'].mean()\n",
    "prediction = np.full(shifting.loc[shifting.group_backwards == 1]['orderSum'].shape, worst_possible_prediction) # Array filled with the mean...\n",
    "target = shifting.loc[shifting.group_backwards == 1]['orderSum']\n",
    "print(\"Guessing the mean of 'orderSum' for all items in target\", mse(target, prediction) ** 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Splitting (Train until week 3 / Val. week 2/ Test week 1)\n",
    "All my experiments will use weeks 13 to 3 as a train set, week 2 as our validation set and week 1 as a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = shifting.loc[shifting.group_backwards >= 3]\n",
    "val = shifting.loc[shifting.group_backwards == 2]\n",
    "test = shifting.loc[shifting.group_backwards == 1]\n",
    "\n",
    "weights = infos.set_index('itemID')['simulationPrice'].to_dict()\n",
    "\n",
    "w_train = train['itemID'].map(weights)\n",
    "w_val = val['itemID'].map(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I recommend to the other members of the team keeping the\n",
    "# datatypes of our datasets as Pandas DataFrames instead of Numpy,\n",
    "# since It will easier to use Boosting Analysis frameworks\n",
    "y_train = train['orderSum']\n",
    "y_val = val['orderSum']\n",
    "X_train = train.drop(columns=[\"orderSum\"])\n",
    "X_val = val.drop(columns=[\"orderSum\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [
     0,
     16
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bcoelho/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "[5]\ttraining's rmse: 39.4147\ttraining's feval: 5.28139e+06\tvalid_1's rmse: 44.5538\tvalid_1's feval: 303195\n",
      "[10]\ttraining's rmse: 38.5596\ttraining's feval: 8.13172e+06\tvalid_1's rmse: 43.6461\tvalid_1's feval: 607847\n",
      "[15]\ttraining's rmse: 38.2531\ttraining's feval: 8.88644e+06\tvalid_1's rmse: 43.3013\tvalid_1's feval: 719913\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's rmse: 38.2505\ttraining's feval: 8.92272e+06\tvalid_1's rmse: 43.2983\tvalid_1's feval: 721535\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "#           \"objective\" : \"poisson\",\n",
    "          \"objective\" : \"l1\",\n",
    "          \"metric\" :\"rmse\",\n",
    "          \"learning_rate\" : 0.5,\n",
    "          'verbosity': 1,\n",
    "          'max_depth': 6,\n",
    "          'num_leaves': 32,\n",
    "          \"min_data_in_leaf\":3000,\n",
    "         }\n",
    "\n",
    "lgbtrain = lgb.Dataset(X_train, label = y_train, weight=w_train, \n",
    "                       categorical_feature=[2, 3, 5, 6, 7, 9])\n",
    "lgbvalid = lgb.Dataset(X_val, label = y_val, weight=w_val, categorical_feature=[2, 3, 5, 6, 7, 9])\n",
    "\n",
    "num_round = 1000\n",
    "model = lgb.train(params,\n",
    "                  lgbtrain,\n",
    "                  num_round,\n",
    "                  valid_sets = [lgbtrain, lgbvalid], \n",
    "                  verbose_eval=5,\n",
    "                  early_stopping_rounds=5,\n",
    "#                   fobj=objective,\n",
    "                  feval=feval,\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a second model just for the new items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemID</th>\n",
       "      <th>group_backwards</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   itemID  group_backwards\n",
       "0       1               12\n",
       "1       2                9\n",
       "2       3               13\n",
       "3       4               12\n",
       "4       5               13"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weekpair is negative, so this works:\n",
    "first_fortnight_item = orders.sort_values(\"group_backwards\",\n",
    "                                     ascending=False)\\\n",
    "                          .groupby([\"itemID\"])[\"group_backwards\"].first()\n",
    "first_fortnight_item = first_fortnight_item.reset_index()\n",
    "first_fortnight_item.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8385, 727, 728)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2 = pd.merge(first_fortnight_item, train, on=[\"itemID\", \"group_backwards\"],\n",
    "                  how=\"inner\", validate=\"1:1\")\n",
    "val2 = pd.merge(first_fortnight_item, val, on=[\"itemID\", \"group_backwards\"],\n",
    "                  how=\"inner\", validate=\"1:1\")\n",
    "test2 = pd.merge(first_fortnight_item, test, on=[\"itemID\", \"group_backwards\"],\n",
    "                  how=\"inner\", validate=\"1:1\")\n",
    "\n",
    "# Check we didn't make mistakes...\n",
    "assert len(train2) + len(val2) + len(test2) == len(first_fortnight_item)\n",
    "assert len(first_fortnight_item.query(\"group_backwards >= 3\")) == len(train2)\n",
    "assert len(first_fortnight_item.query(\"group_backwards == 2\")) == len(val2)\n",
    "assert len(first_fortnight_item.query(\"group_backwards == 1\")) == len(test2)\n",
    "\n",
    "len(train2), len(val2), len(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_train2 = train2['itemID'].map(weights)\n",
    "w_val2 = val2['itemID'].map(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train2 = train2['orderSum']\n",
    "y_val2 = val2['orderSum']\n",
    "y_test2 = test2['orderSum']\n",
    "# Maybe other features don't make sense\n",
    "X_train2 = train2.drop(columns=[\"orderSum\", \"itemID\", \"is_new\"])\n",
    "X_val2 = val2.drop(columns=[\"orderSum\", \"itemID\", \"is_new\"])\n",
    "X_test2 = test2.drop(columns=[\"orderSum\", \"itemID\", \"is_new\"])\n",
    "# Make sure to change the categorical features if you drop more cols\n",
    "cat_feats = [1, 2, 4, 5, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>category1</th>\n",
       "      <th>category2</th>\n",
       "      <th>category3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   brand  manufacturer  category1  category2  category3\n",
       "0      0             1          1          1          1\n",
       "1      0             2          1          2          1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2.iloc[:2, cat_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "[5]\ttraining's rmse: 75.2973\ttraining's feval: 6.71152e+06\tvalid_1's rmse: 91.8662\tvalid_1's feval: 844086\n",
      "[10]\ttraining's rmse: 69.0586\ttraining's feval: 1.02511e+07\tvalid_1's rmse: 84.3397\tvalid_1's feval: 1.03846e+06\n",
      "[15]\ttraining's rmse: 64.8813\ttraining's feval: 1.22334e+07\tvalid_1's rmse: 83.8511\tvalid_1's feval: 1.10257e+06\n",
      "[20]\ttraining's rmse: 62.4726\ttraining's feval: 1.32229e+07\tvalid_1's rmse: 84.796\tvalid_1's feval: 1.14428e+06\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's rmse: 64.3179\ttraining's feval: 1.24865e+07\tvalid_1's rmse: 83.3976\tvalid_1's feval: 1.11743e+06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bcoelho/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    }
   ],
   "source": [
    "params2 = {\n",
    "#           \"objective\" : \"poisson\",\n",
    "          #\"objective\" : \"l1\",\n",
    "          \"objective\" : \"l2\", # L2 works MUCH BETTER than L1\n",
    "          \"metric\" :\"rmse\",\n",
    "          #\"learning_rate\" : 0.5,\n",
    "          'verbosity': 1,\n",
    "          'max_depth': 5,\n",
    "          #'num_leaves': 32,\n",
    "          \"min_data_in_leaf\":3,\n",
    "         }\n",
    "lgbtrain2 = lgb.Dataset(X_train2, label=y_train2, weight=w_train2, \n",
    "                        categorical_feature=cat_feats)\n",
    "lgbvalid2 = lgb.Dataset(X_val2, label=y_val2, weight=w_val2, \n",
    "                        categorical_feature=cat_feats)\n",
    "\n",
    "num_round = 1000\n",
    "model2_val = lgb.train(params2,\n",
    "                  lgbtrain2,\n",
    "                  num_round,\n",
    "                  valid_sets = [lgbtrain2, lgbvalid2], \n",
    "                  verbose_eval=5,\n",
    "                  early_stopping_rounds=5,\n",
    "#                   fobj=objective,\n",
    "                  feval=feval,\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What about on our test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds2 = model2_val.predict(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1049579.91"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_items = test2[\"itemID\"]\n",
    "# Check to make sure itemIDs are in the correct order\n",
    "if not new_items.is_monotonic_increasing:\n",
    "    raise ValueError(\"ItemIDs not increasing! this will break the infos order!\")\n",
    "\n",
    "prices_new_items = infos.query(\"itemID in @new_items\")[\"simulationPrice\"]\n",
    "assert len(y_test2) == len(prices_new_items)\n",
    "baseline_score(preds2, y_test2.values, prices_new_items.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOLY FUCK\n",
    "\n",
    "\n",
    "# FUCK THE ORIGINAL MODEL, LET'S JUST PREDICT THE NEW ITEMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = shifting.loc[shifting.group_backwards >= 2]\n",
    "test = shifting.loc[shifting.group_backwards == 1]\n",
    "\n",
    "w_train = train['itemID'].map(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9112, 728)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2 = pd.merge(first_fortnight_item, train, on=[\"itemID\", \"group_backwards\"],\n",
    "                  how=\"inner\", validate=\"1:1\")\n",
    "test2 = pd.merge(first_fortnight_item, test, on=[\"itemID\", \"group_backwards\"],\n",
    "                  how=\"inner\", validate=\"1:1\")\n",
    "\n",
    "# Check we didn't make mistakes...\n",
    "assert len(train2) + len(test2) == len(first_fortnight_item)\n",
    "assert len(first_fortnight_item.query(\"group_backwards >= 2\")) == len(train2)\n",
    "assert len(first_fortnight_item.query(\"group_backwards == 1\")) == len(test2)\n",
    "\n",
    "len(train2), len(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_train2 = train2['itemID'].map(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train2 = train2['orderSum']\n",
    "y_test2 = test2['orderSum']\n",
    "# Maybe other features don't make sense\n",
    "X_train2 = train2.drop(columns=[\"orderSum\", \"itemID\", \"is_new\"])\n",
    "X_test2 = test2.drop(columns=[\"orderSum\", \"itemID\", \"is_new\"])\n",
    "# Make sure to change the categorical features if you drop more cols\n",
    "cat_feats = [1, 2, 4, 5, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>category1</th>\n",
       "      <th>category2</th>\n",
       "      <th>category3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   brand  manufacturer  category1  category2  category3\n",
       "0      0             1          1          1          1\n",
       "1      0             2          1          2          1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2.iloc[:2, cat_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "[5]\ttraining's rmse: 76.4994\ttraining's feval: 7.31874e+06\n",
      "[10]\ttraining's rmse: 69.7218\ttraining's feval: 1.11889e+07\n",
      "[15]\ttraining's rmse: 65.9111\ttraining's feval: 1.31721e+07\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[16]\ttraining's rmse: 65.3554\ttraining's feval: 1.34485e+07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bcoelho/.local/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    }
   ],
   "source": [
    "lgbtrain2 = lgb.Dataset(X_train2, label=y_train2, weight=w_train2, \n",
    "                        categorical_feature=cat_feats)\n",
    "model2 = lgb.train(params2,\n",
    "                  lgbtrain2,\n",
    "                  model2_val.best_iteration,\n",
    "                  valid_sets = [lgbtrain2], \n",
    "                  verbose_eval=5,\n",
    "                  early_stopping_rounds=5,\n",
    "                  feval=feval,\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions2 = model2.predict(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1056532.0159999998"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_items = test2[\"itemID\"]\n",
    "# Check to make sure itemIDs are in the correct order\n",
    "if not new_items.is_monotonic_increasing:\n",
    "    raise ValueError(\"ItemIDs not increasing! this will break the infos order!\")\n",
    "\n",
    "prices_new_items = infos.query(\"itemID in @new_items\")[\"simulationPrice\"]\n",
    "assert len(y_test2) == len(prices_new_items)\n",
    "baseline_score(final_predictions2, y_test2.values, prices_new_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HAHAHAHAHAHAHAHAHAHAHAHA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Legal! Vamos agora usar o model2 para predizer items novos e o model normal para os items não novos...\n",
    "\n",
    "E juntar os dois\n",
    "\n",
    "Mas vamos manter a estrutura de treino do model (mais pq to sem tempo pra testar coisas melhoras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Só preciso retreinar o model original final então:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os dados de train agora são o treino TREINO\n",
    "y_train = train['orderSum']\n",
    "X_train = train.drop(columns=[\"orderSum\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "[5]\ttrain's rmse: 39.566\ttrain's feval: 6.51117e+06\n",
      "[10]\ttrain's rmse: 39.1716\ttrain's feval: 7.95597e+06\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[11]\ttrain's rmse: 39.1691\ttrain's feval: 7.97428e+06\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "          \"objective\" : \"l1\",\n",
    "          \"metric\" :\"rmse\",\n",
    "          \"learning_rate\" : 0.5,\n",
    "          'verbosity': 1,\n",
    "          'max_depth': 7,\n",
    "          'num_leaves': 15,\n",
    "          \"min_data_in_leaf\":3500,\n",
    "         }\n",
    "\n",
    "lgbtrain = lgb.Dataset(X_train, label = y_train, weight=w_train, categorical_feature=[2, 3, 5, 6, 7, 9])\n",
    "\n",
    "model = lgb.train(params,\n",
    "                  lgbtrain,\n",
    "                  model.best_iteration,\n",
    "                  valid_sets = [lgbtrain], \n",
    "                  valid_names = ['train'],\n",
    "                  verbose_eval=5,\n",
    "                  early_stopping_rounds=5,\n",
    "                  feval=feval,\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test['orderSum']\n",
    "X_test = test.drop(columns=[\"orderSum\"])\n",
    "final_predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert test[\"itemID\"].is_monotonic_increasing\n",
    "new_items_idx = test[\"itemID\"].isin(new_items)\n",
    "final_predictions[new_items_idx] = final_predictions2\n",
    "final_predictions[final_predictions < 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78125, 0.5    , 0.5    , ..., 0.     , 0.     , 0.     ])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1140288.454"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_score(final_predictions, y_test.values, infos['simulationPrice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old value was ~600 thousand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5rc1"
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
