{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewing sharpley values  from dora xgboost 2 model with data leak removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obs: i remove the rows with items with total zero sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../dora/models/\")\n",
    "from utils import read_data, process_time, merge_data, promo_detector, promotionAggregation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "import xgboost as xgb\n",
    "from datetime import datetime\n",
    "\n",
    "NUMBER_OF_LAGS = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing our dataset\n",
    "These steps were already seen on ```../pre-processing-features``` notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity checks... (10463, 3) (10463, 8) (2181955, 5)\n"
     ]
    }
   ],
   "source": [
    "infos, items, orders = read_data(\"../main/datasets/\")\n",
    "print(\"Sanity checks...\", infos.shape, items.shape, orders.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing our time signatures, \n",
    "# adding our promotion feature \n",
    "# and aggregating our data by weeks...\n",
    "process_time(orders)\n",
    "orders = promo_detector(orders)\n",
    "df = promotionAggregation(orders, items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareOrders(orders, items):\n",
    "    \"\"\"This function is responsible for adding in our 'orders' dataframe\n",
    "    the items that were not sold. THIS IS NOT MODULARIZED, THUS YOU\n",
    "    SHOULD CHANGE THE CODE TO BETTER SUIT YOUR DATASET FEATURES\n",
    "    \"\"\"\n",
    "    \n",
    "    df = orders.copy()\n",
    "\n",
    "    new_rows = []\n",
    "    weeks_database = orders['group_backwards'].unique()\n",
    "\n",
    "    for idd in df['itemID'].unique():\n",
    "        orders_id = df[df.itemID == idd]\n",
    "        example = orders_id.iloc[0]\n",
    "\n",
    "        # finding weeks without itemID sales\n",
    "        weeks_id = orders_id['group_backwards'].unique()\n",
    "        weeks_without_id = np.setdiff1d(weeks_database, weeks_id)\n",
    "\n",
    "        # creating new row\n",
    "        for w in weeks_without_id:\n",
    "            new_rows.append({'itemID': idd,\n",
    "                             'group_backwards': w,\n",
    "                             'salesPrice_mean': 0,\n",
    "                             'customerRating': example['customerRating'],\n",
    "                             'category1': example['category1'],\n",
    "                             'category2': example['category2'],\n",
    "                             'category3': example['category3'],\n",
    "                             'recommendedRetailPrice': example['recommendedRetailPrice'],\n",
    "                             'orderSum': 0,\n",
    "                             'manufacturer': example['manufacturer'],\n",
    "                             'brand': example['brand'],\n",
    "                             'promotion_mean': 0\n",
    "                             })\n",
    "    df = df.append(new_rows)\n",
    "    df = df.sort_values(['group_backwards', 'itemID'], ascending=[False, True], ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39515\n",
      "127920\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "df = prepareOrders(df, items)\n",
    "print(len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_backwards</th>\n",
       "      <th>itemID</th>\n",
       "      <th>orderSum</th>\n",
       "      <th>promotion_mean</th>\n",
       "      <th>salesPrice_mean</th>\n",
       "      <th>brand</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>customerRating</th>\n",
       "      <th>category1</th>\n",
       "      <th>category2</th>\n",
       "      <th>category3</th>\n",
       "      <th>recommendedRetailPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>14.040000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>7.840000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127915</th>\n",
       "      <td>1</td>\n",
       "      <td>10450</td>\n",
       "      <td>34</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>53.555625</td>\n",
       "      <td>182.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>36.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127916</th>\n",
       "      <td>1</td>\n",
       "      <td>10459</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>180.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>56.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127917</th>\n",
       "      <td>1</td>\n",
       "      <td>10460</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>163.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127918</th>\n",
       "      <td>1</td>\n",
       "      <td>10462</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>180.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>166.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127919</th>\n",
       "      <td>1</td>\n",
       "      <td>10463</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>154.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127920 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        group_backwards  itemID  orderSum  promotion_mean  salesPrice_mean  \\\n",
       "0                    13       1         0          0.0000         0.000000   \n",
       "1                    13       2         0          0.0000         0.000000   \n",
       "2                    13       3         1          0.0000        14.040000   \n",
       "3                    13       4         0          0.0000         0.000000   \n",
       "4                    13       5         2          0.0000         7.840000   \n",
       "...                 ...     ...       ...             ...              ...   \n",
       "127915                1   10450        34          0.1875        53.555625   \n",
       "127916                1   10459         0          0.0000         0.000000   \n",
       "127917                1   10460         0          0.0000         0.000000   \n",
       "127918                1   10462         0          0.0000         0.000000   \n",
       "127919                1   10463         0          0.0000         0.000000   \n",
       "\n",
       "        brand  manufacturer  customerRating  category1  category2  category3  \\\n",
       "0         0.0           1.0            4.38        1.0        1.0        1.0   \n",
       "1         0.0           2.0            3.00        1.0        2.0        1.0   \n",
       "2         0.0           3.0            5.00        1.0        3.0        1.0   \n",
       "3         0.0           2.0            4.44        1.0        2.0        1.0   \n",
       "4         0.0           2.0            2.33        1.0        1.0        1.0   \n",
       "...       ...           ...             ...        ...        ...        ...   \n",
       "127915  182.0         227.0            0.00        8.0       44.0        8.0   \n",
       "127916  180.0         253.0            0.00        8.0       44.0        8.0   \n",
       "127917    0.0         253.0            0.00        8.0       44.0        8.0   \n",
       "127918  180.0         253.0            0.00        8.0       44.0        8.0   \n",
       "127919    0.0         253.0            0.00        8.0       44.0        8.0   \n",
       "\n",
       "        recommendedRetailPrice  \n",
       "0                         8.84  \n",
       "1                        16.92  \n",
       "2                        15.89  \n",
       "3                        40.17  \n",
       "4                        17.04  \n",
       "...                        ...  \n",
       "127915                   36.78  \n",
       "127916                   56.57  \n",
       "127917                  163.81  \n",
       "127918                  166.97  \n",
       "127919                  154.82  \n",
       "\n",
       "[127920 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell lags and diffs our features 'orderSum' and \"promotion\"\n",
    "\n",
    "shifting = df.copy()\n",
    "\n",
    "for i in range(1,NUMBER_OF_LAGS):\n",
    "\n",
    "    # Carrying the data of weeks t-1\n",
    "    shifting[f'orderSum_{i}'] = shifting.groupby('itemID')['orderSum'].shift(i)\n",
    "    shifting[f'promotion_mean_{i}'] = shifting.groupby('itemID')['promotion_mean'].shift(i)\n",
    "    \n",
    "    # Getting the difference of the orders and promotions between weeks t-1 and t-2...\n",
    "    shifting[f'orderSum_diff_{i}'] = shifting.groupby('itemID')[f'orderSum_{i}'].diff()\n",
    "    shifting[f'promotion_mean_diff_{i}'] = shifting.groupby('itemID')[f'promotion_mean_{i}'].diff()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum error\n",
    "The maximum error we could get in this dataset would be just guessing the mean of our sales from weeks 1 to 12, and that's what the cell below is computing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guessing the mean of 'orderSum' for all items in target 93.14493040998501\n"
     ]
    }
   ],
   "source": [
    "worst_possible_prediction = shifting.loc[shifting.group_backwards < 13]['orderSum'].mean()\n",
    "prediction = np.full(shifting.loc[shifting.group_backwards == 13]['orderSum'].shape, worst_possible_prediction) # Array filled with the mean...\n",
    "target = shifting.loc[shifting.group_backwards == 13]['orderSum']\n",
    "print(\"Guessing the mean of 'orderSum' for all items in target\", mse(target, prediction) ** 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Splitting\n",
    "All my experiments will use weeks 13 to 3 as a train set, week 2 as our validation set and week 1 as a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = shifting.loc[shifting.group_backwards >= 3]\n",
    "val = shifting.loc[shifting.group_backwards == 2]\n",
    "test = shifting.loc[shifting.group_backwards == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I recommend to the other members of the team keeping the\n",
    "# datatypes of our datasets as Pandas DataFrames instead of Numpy,\n",
    "# since It will easier to use Boosting Analysis frameworks\n",
    "y_train = train['orderSum']\n",
    "y_val = val['orderSum']\n",
    "X_train = train.drop(columns=[\"orderSum\"])\n",
    "X_val = val.drop(columns=[\"orderSum\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:107.15226\tval-rmse:114.37853\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 5 rounds.\n",
      "[1]\ttrain-rmse:106.40302\tval-rmse:114.00581\n",
      "[2]\ttrain-rmse:105.66099\tval-rmse:113.64217\n",
      "[3]\ttrain-rmse:104.92551\tval-rmse:113.28590\n",
      "[4]\ttrain-rmse:104.19418\tval-rmse:112.92827\n",
      "[5]\ttrain-rmse:103.47201\tval-rmse:112.59444\n",
      "[6]\ttrain-rmse:102.75311\tval-rmse:112.27349\n",
      "[7]\ttrain-rmse:102.04147\tval-rmse:111.95448\n",
      "[8]\ttrain-rmse:101.33382\tval-rmse:111.64027\n",
      "[9]\ttrain-rmse:100.63448\tval-rmse:111.33965\n",
      "[10]\ttrain-rmse:99.94049\tval-rmse:111.05751\n",
      "[11]\ttrain-rmse:99.25253\tval-rmse:110.77846\n",
      "[12]\ttrain-rmse:98.56931\tval-rmse:110.51157\n",
      "[13]\ttrain-rmse:97.89185\tval-rmse:110.25754\n",
      "[14]\ttrain-rmse:97.21864\tval-rmse:110.00870\n",
      "[15]\ttrain-rmse:96.55033\tval-rmse:109.76379\n",
      "[16]\ttrain-rmse:95.88757\tval-rmse:109.53152\n",
      "[17]\ttrain-rmse:95.22805\tval-rmse:109.28062\n",
      "[18]\ttrain-rmse:94.57433\tval-rmse:109.04216\n",
      "[19]\ttrain-rmse:93.92550\tval-rmse:108.81081\n",
      "[20]\ttrain-rmse:93.28211\tval-rmse:108.58920\n",
      "[21]\ttrain-rmse:92.64363\tval-rmse:108.37850\n",
      "[22]\ttrain-rmse:92.01010\tval-rmse:108.18457\n",
      "[23]\ttrain-rmse:91.38075\tval-rmse:107.97855\n",
      "[24]\ttrain-rmse:90.75557\tval-rmse:107.79395\n",
      "[25]\ttrain-rmse:90.13503\tval-rmse:107.61771\n",
      "[26]\ttrain-rmse:89.52006\tval-rmse:107.44302\n",
      "[27]\ttrain-rmse:88.90990\tval-rmse:107.24235\n",
      "[28]\ttrain-rmse:88.30537\tval-rmse:107.07595\n",
      "[29]\ttrain-rmse:87.70685\tval-rmse:106.91693\n",
      "[30]\ttrain-rmse:87.11261\tval-rmse:106.73344\n",
      "[31]\ttrain-rmse:86.52297\tval-rmse:106.57669\n",
      "[32]\ttrain-rmse:85.93802\tval-rmse:106.42886\n",
      "[33]\ttrain-rmse:85.35747\tval-rmse:106.29560\n",
      "[34]\ttrain-rmse:84.78258\tval-rmse:106.13622\n",
      "[35]\ttrain-rmse:84.20916\tval-rmse:105.99924\n",
      "[36]\ttrain-rmse:83.64098\tval-rmse:105.86837\n",
      "[37]\ttrain-rmse:83.07696\tval-rmse:105.71837\n",
      "[38]\ttrain-rmse:82.51674\tval-rmse:105.61120\n",
      "[39]\ttrain-rmse:81.96209\tval-rmse:105.52206\n",
      "[40]\ttrain-rmse:81.41201\tval-rmse:105.41770\n",
      "[41]\ttrain-rmse:80.86560\tval-rmse:105.30016\n",
      "[42]\ttrain-rmse:80.32494\tval-rmse:105.21465\n",
      "[43]\ttrain-rmse:79.78786\tval-rmse:105.12914\n",
      "[44]\ttrain-rmse:79.25553\tval-rmse:105.03591\n",
      "[45]\ttrain-rmse:78.72688\tval-rmse:104.95329\n",
      "[46]\ttrain-rmse:78.20216\tval-rmse:104.89864\n",
      "[47]\ttrain-rmse:77.68349\tval-rmse:104.80544\n",
      "[48]\ttrain-rmse:77.16822\tval-rmse:104.75325\n",
      "[49]\ttrain-rmse:76.65779\tval-rmse:104.70066\n",
      "[50]\ttrain-rmse:76.15099\tval-rmse:104.65611\n",
      "[51]\ttrain-rmse:75.64876\tval-rmse:104.57989\n",
      "[52]\ttrain-rmse:75.14990\tval-rmse:104.54253\n",
      "[53]\ttrain-rmse:74.65338\tval-rmse:104.51651\n",
      "[54]\ttrain-rmse:74.16276\tval-rmse:104.45983\n",
      "[55]\ttrain-rmse:73.67481\tval-rmse:104.42165\n",
      "[56]\ttrain-rmse:73.19111\tval-rmse:104.39858\n",
      "[57]\ttrain-rmse:72.71094\tval-rmse:104.35602\n",
      "[58]\ttrain-rmse:72.23463\tval-rmse:104.34445\n",
      "[59]\ttrain-rmse:71.76152\tval-rmse:104.31995\n",
      "[60]\ttrain-rmse:71.29274\tval-rmse:104.31507\n",
      "[61]\ttrain-rmse:70.82611\tval-rmse:104.30078\n",
      "[62]\ttrain-rmse:70.36505\tval-rmse:104.29977\n",
      "[63]\ttrain-rmse:69.90585\tval-rmse:104.31322\n",
      "[64]\ttrain-rmse:69.45095\tval-rmse:104.30771\n",
      "[65]\ttrain-rmse:68.99854\tval-rmse:104.32317\n",
      "[66]\ttrain-rmse:68.54954\tval-rmse:104.33545\n",
      "[67]\ttrain-rmse:68.10483\tval-rmse:104.36127\n",
      "Stopping. Best iteration:\n",
      "[62]\ttrain-rmse:70.36505\tval-rmse:104.29977\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(X_train, y_train)\n",
    "dval = xgb.DMatrix(X_val, y_val)\n",
    "\n",
    "param = {'max_depth':32, 'eta':0.01, 'objective':'reg:squarederror' }\n",
    "num_round = 600\n",
    "bst = xgb.train(param, dtrain,\n",
    "                num_round, early_stopping_rounds = 5,\n",
    "                evals = [(dtrain, 'train'), (dval, 'val')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predicting at test time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test['orderSum']\n",
    "X_test = xgb.DMatrix(test.drop(columns=[\"orderSum\"]))\n",
    "final_predictions = bst.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saving our model in disk**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now().strftime(\"%d-%m-%Y-%Hh%Mm%Ss\")\n",
    "modelName = 'xgb-' + now\n",
    "bst.save_model(modelName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sharpley values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Too slow, i will try with the google collab latter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting feature_perturbation = \"tree_path_dependent\" because no background data was given.\n"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "explainer = shap.TreeExplainer(bst)\n",
    "shap_values = explainer.shap_values(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### looking average impact of every feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_test, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### overview of every feature influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(\"orderSum_0\", shap_values, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## conclusions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- orderSum_0 is basically the only important feature, and that because it value is the same as the answer, the model has data leak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- be careful with print(database), it doesn't show all the columns, the print below does not have orderSum_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train)\n",
    "print(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None\n",
    "display(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
