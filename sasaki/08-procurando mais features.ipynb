{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "from catboost import CatBoostRegressor, Pool, MetricVisualizer\n",
    "from sasaki_features import add_feature_position_month\n",
    "from datetime import datetime\n",
    "\n",
    "sys.path.append(\"../dora/models/\")\n",
    "from utils import  promo_detector, promotionAggregation\n",
    "\n",
    "sys.path.append(\"../main\")\n",
    "from utils import read_data, process_time, merge_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infos, items, orders = read_data(\"../main/datasets/\")\n",
    "\n",
    "orders_columns = set(orders.columns)\n",
    "print(orders_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_time(orders)\n",
    "orders2 = promo_detector(orders)\n",
    "orders2 = promotionAggregation(orders2, items)\n",
    "\n",
    "orders_columns2 = set(orders2.columns)\n",
    "print(orders_columns2 - orders_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing item with sale only in group_backwards ==1 or 2 \n",
    "#because it can cause dataleak\n",
    "id_in_test = orders2.query('group_backwards <= 2')['itemID'].unique()\n",
    "id_in_train = orders2.query('group_backwards >= 3')['itemID'].unique()\n",
    "\n",
    "remove =  set(id_in_test) - set(id_in_train)\n",
    "orders2 = orders2[~orders2.itemID.isin(remove)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rows = []\n",
    "weeks_database = orders2['group_backwards'].unique()\n",
    "\n",
    "\n",
    "#features with same value for pair ('group', 'itemID')\n",
    "from_example=['category1','category2','category3',\n",
    "              'customerRating','recommendedRetailPrice',\n",
    "              'manufacturer','brand']\n",
    "    \n",
    "for idd in orders2['itemID'].unique():\n",
    "    orders_id = orders2[orders2.itemID == idd]\n",
    "    example = orders_id.iloc[0]\n",
    "\n",
    "    # finding weeks without itemID sales\n",
    "    weeks_id = orders_id['group_backwards'].unique()\n",
    "    weeks_without_id = np.setdiff1d(weeks_database, weeks_id)\n",
    "\n",
    "    # creating new row\n",
    "    for w in weeks_without_id:\n",
    "        \n",
    "        \n",
    "        row = {'itemID': idd,\n",
    "                         'group_backwards': w,\n",
    "                         'salesPrice_mean': 0,\n",
    "                         'orderSum': 0,\n",
    "                         'promotion_mean': 0\n",
    "              }\n",
    "        for f in from_example:\n",
    "            row[f] = example[f]\n",
    "        \n",
    "        new_rows.append(row)\n",
    "#  Adding rows in every week with the IDs of the\n",
    "# items that were never sold.\n",
    "\n",
    "orders2 = orders2.append(new_rows)  \n",
    "orders2 = orders2.sort_values(['group_backwards', 'itemID'], ascending=[False, True], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New features 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders3 = add_feature_position_month(orders2)\n",
    "\n",
    "\n",
    "orders_aux = orders.query('group_backwards >= 3')\n",
    "nDays = orders_aux['days'].nunique()\n",
    "nWeek = orders_aux['week_backwards'].nunique()\n",
    "nGroup = orders_aux['group_backwards'].nunique()\n",
    "\n",
    "newInfo = items[['itemID']].copy()\n",
    "\n",
    "#how many days in average the item is sold in day/week/pair\n",
    "newInfo['freq_day'] = orders_aux.groupby('itemID', as_index=False)['days'].nunique()/nDays\n",
    "newInfo['freq_week'] = orders_aux.groupby('itemID', as_index=False)['week_backwards'].nunique()/nWeek\n",
    "newInfo['freq_group'] = orders_aux.groupby('itemID', as_index=False)['group_backwards'].nunique()/nGroup\n",
    "\n",
    "\n",
    "\n",
    "orders_aux = orders3.query('group_backwards >= 3')\n",
    "\n",
    "#minimun and maximum sales in a pair\n",
    "#too much zeros, trying for last 4 pairs\n",
    "newInfo['min_sale'] = orders_aux.groupby(['itemID'])['orderSum'].min()\n",
    "newInfo['max_sale'] = orders_aux.groupby(['itemID'])['orderSum'].max()\n",
    "\n",
    "\n",
    "\n",
    "#minimun and maximum sales in a group recent\n",
    "order_recent = orders3.query('group_backwards >= 3 & group_backwards <= 7')\n",
    "newInfo['min_sale_rec'] = order_recent.groupby(['itemID'])['orderSum'].min()\n",
    "newInfo['max_sale_rec'] = order_recent.groupby(['itemID'])['orderSum'].max()\n",
    "\n",
    "\n",
    "orders3 = pd.merge(orders3,newInfo,on=['itemID'])\n",
    "\n",
    "orders_columns3 = set(orders3.columns)\n",
    "print(orders_columns3 - orders_columns2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shift\n",
    "### added the feature salesPrice_mean_ from older pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders4 = orders3.copy()\n",
    "\n",
    "for i in range(1, 3):\n",
    "    # Carrying the data of weeks t-1\n",
    "    orders4[f'orderSum_{i}'] = orders4.groupby('itemID')['orderSum'].shift(i)\n",
    "    orders4[f'promotion_mean_{i}'] = orders4.groupby('itemID')['promotion_mean'].shift(i)\n",
    "    orders4[f'salesPrice_mean_{i}'] = orders4.groupby('itemID')['salesPrice_mean'].shift(i)\n",
    "    \n",
    "    # Getting the difference of the orders and promotions between weeks t-1 and t-2...\n",
    "    orders4[f'orderSum_diff_{i}'] = orders4.groupby('itemID')[f'orderSum_{i}'].diff()\n",
    "    orders4[f'promotion_mean_diff_{i}'] = orders4.groupby('itemID')[f'promotion_mean_{i}'].diff()\n",
    "    orders4[f'salesPrice_mean_diff_{i}'] = orders4.groupby('itemID')[f'salesPrice_mean_{i}'].diff()\n",
    "\n",
    "orders4 =orders4.fillna(np.inf)\n",
    "\n",
    "orders_columns4 = set(orders4.columns)\n",
    "print(orders_columns4 - orders_columns3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## new features 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tentando ordenar certas features categoricas\n",
    "#estou usando como metrica vendas totais medias entre itemID de mesma categoria\n",
    "def ordanalize_colum(order_g2, colum):\n",
    "    aaa = order_g2.copy()\n",
    "    order_g2 = order_g2.query('group_backwards >= 3')\n",
    "    \n",
    "    aux = order_g2.groupby(colum,as_index=False).agg({'orderSum' : ['sum'],'itemID' : ['count']})\n",
    "    \n",
    "    #calculando a metrica para cada item diferente da coluna\n",
    "    aux[f'avg_sales_{colum}'] = aux[( 'orderSum',   'sum')] / aux[( 'itemID', 'count')]\n",
    "    aux = aux[[colum,f'avg_sales_{colum}']]\n",
    "    aux.columns = [colum,f'avg_sales_{colum}']\n",
    "    \n",
    "    \n",
    "    #ordenando a coluna\n",
    "    aux = aux.sort_values(by=f'avg_sales_{colum}')\n",
    "    aux[f'{colum}_order'] = range(len(aux))\n",
    "\n",
    "    #print(aux)\n",
    "    return pd.merge(aaa,aux, how='left',on=[colum])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders5 = ordanalize_colum(orders4, 'category3')\n",
    "orders5 = ordanalize_colum(orders5, 'brand')\n",
    "orders5 = ordanalize_colum(orders5, 'manufacturer')\n",
    "\n",
    "orders_columns5 = set(orders5.columns)\n",
    "print(orders_columns5 - orders_columns4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class custom_obj(object):\n",
    "    def __iter__(self):\n",
    "        return iter('custom')\n",
    "    \n",
    "    def get_final_error(self, error, weight):\n",
    "    \n",
    "        return error\n",
    "\n",
    "    def is_max_optimal(self):\n",
    "        return False\n",
    "\n",
    "    def evaluate(self, approxes, target, weight):\n",
    "        approx = approxes[0]\n",
    "\n",
    "        error_sum = 0.0\n",
    "        weight_sum = 0.0\n",
    "\n",
    "        for prediction,t,w in zip(approx, target, weight):\n",
    "            \n",
    "            weight_sum += w\n",
    "            \n",
    "            error_sum += -1* (prediction - (np.maximum(prediction - t, 0) * 1.6))  * w\n",
    "\n",
    "        return error_sum, weight_sum\n",
    "    def calc_ders_range(self, approxes, targets, weights):\n",
    "        pred = np.array(approxes)\n",
    "        target = np.array(targets)\n",
    "        weight = np.array(weights)\n",
    "        \n",
    "        \n",
    "        der1 = -2 *weight* (pred - (np.maximum(pred - target, 0) * 1.6)) * (1 - (pred > target) * 1.6)\n",
    "        der2 = -2 *weight* (1 - (pred > target) * 1.6) ** 2\n",
    "\n",
    "        return list(zip(der1,der2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders6 = orders5.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders6 = orders6.drop(columns=['avg_sales_category3', 'avg_sales_brand', 'avg_sales_manufacturer'])\n",
    "#piorou bastante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders6 = orders6.drop(columns=['manufacturer_order', 'category3_order', 'brand_order'])\n",
    "# parece nao fazer diferença (melhorou 40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders6 = orders6.drop(columns=['freq_day','freq_week','freq_group'])\n",
    "#pode melhorar (melhorou 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#orders6 = orders6.drop(columns=['posM_f_group', 'posM_m_group', 'posM_l_group'])\n",
    "#piorou um pouco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders6 = orders6.drop(columns=['min_sale_rec', 'max_sale_rec','min_sale','max_sale'])\n",
    "#pode melhorar um pouco (melhorou 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(orders6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorical features\n",
    "cat_features = ['brand','manufacturer','category1','category2','category3']\n",
    "\n",
    "#passing to integer\n",
    "for f in cat_features:\n",
    "    orders6[f] = orders6[f].map(lambda x : int(x))  \n",
    "\n",
    "    \n",
    "weight =pd.merge(orders6, infos[[\"itemID\", \"simulationPrice\"]], \n",
    "                     on=\"itemID\", validate=\"m:1\")\n",
    "weightt = weight[[\"itemID\",\"group_backwards\",\"simulationPrice\"]]\n",
    "\n",
    "test = orders6.query('group_backwards == 1')\n",
    "val = orders6.query('group_backwards == 2')\n",
    "train = orders6.query('group_backwards >= 3')\n",
    "\n",
    "\n",
    "\n",
    "train_pool = Pool(\n",
    "    data= train.drop(columns=[\"orderSum\"]), \n",
    "    label= train['orderSum'], \n",
    "    weight= weightt.query('group_backwards >= 3') ,\n",
    "    cat_features= cat_features\n",
    ")\n",
    "\n",
    "validation_pool = Pool(\n",
    "    data= val.drop(columns=[\"orderSum\"]), \n",
    "    label= val['orderSum'], \n",
    "    weight= weightt.query('group_backwards == 2'),\n",
    "    cat_features= cat_features\n",
    ")\n",
    "\n",
    "params = {'iterations': 1000, \n",
    "         'loss_function':'RMSE',\n",
    "         'use_best_model': True,\n",
    "         'early_stopping_rounds': 30,\n",
    "}\n",
    "\n",
    "params2= {'loss_function':custom_obj(),\n",
    "         'iterations': 200, \n",
    "         'eval_metric':custom_obj(),\n",
    "         'use_best_model': True,\n",
    "         'early_stopping_rounds': 30,\n",
    "         'subsample':1,\n",
    "         }\n",
    "\n",
    "\n",
    "params3= {'loss_function':'RMSE',\n",
    "         'iterations': 1000, \n",
    "         'eval_metric':custom_obj(),\n",
    "         'early_stopping_rounds': 30,\n",
    "         'use_best_model': True,\n",
    "         }\n",
    "\n",
    "model=CatBoostRegressor(**params) \n",
    "model.fit(train_pool,eval_set=validation_pool , verbose=False)\n",
    "\n",
    "#model2=CatBoostRegressor(**params2) \n",
    "#model2.fit(train_pool,eval_set=validation_pool , verbose=False)\n",
    "\n",
    "model3=CatBoostRegressor(**params3) \n",
    "model3.fit(train_pool,eval_set=validation_pool , verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pool = Pool(test.drop(columns=[\"orderSum\"]),\n",
    "                 weight= test['salesPrice_mean'],\n",
    "                 cat_features= cat_features) \n",
    "\n",
    "#items never sold will have 0 demandPrediction\n",
    "not_sold_items = items[np.logical_not(\n",
    "    items.itemID.isin(sorted(orders2['itemID'].unique())))]\n",
    "not_sold_items['demandPrediction'] = [0 for _ in range(len(not_sold_items))]\n",
    "not_sold_items = not_sold_items[[\"itemID\", \"demandPrediction\"]]\n",
    "\n",
    "def get_pred(modelo, nome):\n",
    "    preds = modelo.predict(test_pool)\n",
    "\n",
    "    #all prediction need to be positive and integer\n",
    "    sold_items = test.copy()\n",
    "    preds = [max(x,0) for x in preds ]\n",
    "    sold_items['demandPrediction'] = preds\n",
    "    sold_items = sold_items[[\"itemID\", \"demandPrediction\"]]\n",
    "\n",
    "\n",
    "\n",
    "    #to kagle csv\n",
    "    final = pd.concat([sold_items, not_sold_items])\n",
    "    final[\"demandPrediction\"] = final[\"demandPrediction\"].astype(np.uint8)\n",
    "    final = final.sort_values(['itemID'],  ignore_index=True)\n",
    "    final.to_csv(f\"pred/{nome}.csv\", index=False, sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pred(model, 'cat_pos1')\n",
    "#get_pred(model2, 'cat2')\n",
    "get_pred(model3, 'cat_pos2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#np.array(model.get_feature_importance(prettified=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NAO USAR ESSA FEATURE; ALGUEM A PERDA DE -0.3 PARA -1 \n",
    "#(e por algum motivo foi a com maior importancia no modelo com ela usada)\n",
    "\n",
    "#average sales of items in the same category12\n",
    "\n",
    "#aux = order_g2.groupby(['category1','category2'],as_index=False).agg({'orderSum' : ['sum','count']})\n",
    "#aux['avg_sales_cat12'] = aux[( 'orderSum',   'sum')] / aux[( 'orderSum', 'count')]\n",
    "#aux = aux[['category1','category2','avg_sales_cat12']]\n",
    "#aux.columns = ['category1','category2','avg_sales_cat12']\n",
    "\n",
    "\n",
    "#order_g2= pd.merge(order_g2,aux, on=['category1','category2'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
