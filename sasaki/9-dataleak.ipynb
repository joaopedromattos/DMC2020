{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "from catboost import CatBoostRegressor, Pool, MetricVisualizer\n",
    "from sasaki_features import add_feature_position_month\n",
    "from datetime import datetime\n",
    "\n",
    "sys.path.append(\"../dora/models\")\n",
    "from utils import read_data, process_time, merge_data, promotionAggregation\n",
    "\n",
    "#TENTAR FEATURES NOS MODELOS DO JOAO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## some functions from dora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (por algum motivo eu nao consegui importar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_score(prediction, target, simulatedPrice):\n",
    "    prediction = prediction.astype(int)\n",
    "\n",
    "    return np.sum((prediction - np.maximum(prediction - target, 0) * 1.6)  * simulatedPrice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## importing orders and applying already made features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'days', 'salesPrice', 'time', 'order', 'itemID', 'days_backwards', 'group_backwards', 'week_backwards', 'transactID'}\n"
     ]
    }
   ],
   "source": [
    "infos, items, orders = read_data(\"../main/datasets/\")\n",
    "process_time(orders)\n",
    "\n",
    "orders_columns = set(orders.columns)\n",
    "print(orders_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding zero ordemSum rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'category2', 'brand', 'category1', 'category3', 'manufacturer', 'customerRating', 'orderSum', 'recommendedRetailPrice'}\n"
     ]
    }
   ],
   "source": [
    "# Aggregating our data by pairs...\n",
    "df = orders.groupby(['group_backwards', 'itemID'], as_index=False).agg({'order':'sum'}).rename(columns={'order':'orderSum'})\n",
    "\n",
    "# Building our dataset through multiindexing...\n",
    "multiIndex = pd.MultiIndex.from_product([range(13, 0, -1), items['itemID']], names=['group_backwards', 'itemID'])\n",
    "aux = pd.DataFrame(index=multiIndex)\n",
    "df = pd.merge(aux, df, left_on=['group_backwards', 'itemID'], right_on=['group_backwards', 'itemID'], how='left')\n",
    "df.fillna(0, inplace = True)\n",
    "\n",
    "# Gettin' informations about our items in our dataset...\n",
    "orders2 = pd.merge(df, items, left_on=['itemID'], right_on=['itemID']).sort_values('group_backwards', ascending=False)\n",
    "\n",
    "orders2_columns = set(orders2.columns)\n",
    "print(orders2_columns - orders_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136019\n"
     ]
    }
   ],
   "source": [
    "print(len(orders2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = set( orders['itemID'].unique() )\n",
    "all_ids = set(items['itemID'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New features 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders4 = add_feature_position_month(orders2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136019\n"
     ]
    }
   ],
   "source": [
    "print(len(orders4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply function without information from futures\n",
    "def apply_to_serie(data, function,extraParans={}):\n",
    "    \n",
    "    new_data = pd.DataFrame()\n",
    " \n",
    "    for time in data['group_backwards'].unique():\n",
    "        new_rows = function(data,time,**extraParans)\n",
    "        new_data = pd.concat([new_data, new_rows])\n",
    "        \n",
    "\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_feature_freq(data,time):\n",
    "    orders_aux = orders.query(f\"group_backwards >  {time}\")#remember, its backwards\n",
    "    \n",
    "    nDays = orders_aux['days'].nunique()\n",
    "    nWeek = orders_aux['week_backwards'].nunique()\n",
    "    nGroup = orders_aux['group_backwards'].nunique()\n",
    "\n",
    "    newInfo = items[['itemID']].copy()\n",
    "    newInfo[\"group_backwards\"] = time\n",
    "    \n",
    "    #how many days in average the item is sold in day/week/pair\n",
    "    newInfo['freq_day'] = orders_aux.groupby('itemID', as_index=False)['days'].nunique()/nDays\n",
    "    newInfo['freq_week'] = orders_aux.groupby('itemID', as_index=False)['week_backwards'].nunique()/nWeek\n",
    "    newInfo['freq_group'] = orders_aux.groupby('itemID', as_index=False)['group_backwards'].nunique()/nGroup\n",
    "    \n",
    "    current_time = data.query(f\"group_backwards == {time}\")\n",
    "    return pd.merge(current_time,newInfo, on=['itemID','group_backwards'], how=\"left\", validate=\"m:1\")\n",
    "\n",
    "orders4 = apply_to_serie(orders4,  add_feature_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136019\n"
     ]
    }
   ],
   "source": [
    "print(len(orders4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ordenando features categoricas usando como metrica \n",
    "#vendas totais medias entre itemID de mesma categoria\n",
    "def add_feature_ord_cat(data, time, category):\n",
    "    orders_aux = data.query(f\"group_backwards > {time}\")#remember, its backwards\n",
    "\n",
    "    newInfo = orders_aux.groupby(category,as_index=False).agg({'orderSum' : ['sum'],'itemID' : ['count']})\n",
    "    newInfo[\"group_backwards\"] = time\n",
    "    \n",
    "\n",
    "    #calculando a metrica para cada item diferente da coluna\n",
    "    newInfo[f'avg_sales_{category}'] = newInfo[( 'orderSum',   'sum')] / newInfo[( 'itemID', 'count')]\n",
    "    newInfo = newInfo[[category,\"group_backwards\", f'avg_sales_{category}']]\n",
    "    newInfo.columns = [category,\"group_backwards\", f'avg_sales_{category}']\n",
    "    \n",
    "    \n",
    "    current_time = data.query(f\"group_backwards == {time}\")\n",
    "    return pd.merge(current_time,newInfo, on=[category,'group_backwards'], how=\"left\", validate=\"m:1\")\n",
    "\n",
    "\n",
    "orders4 = apply_to_serie(orders4,  add_feature_ord_cat, extraParans={\"category\": \"category3\"})\n",
    "orders4 = apply_to_serie(orders4,  add_feature_ord_cat, extraParans={\"category\": \"brand\"})\n",
    "orders4 = apply_to_serie(orders4,  add_feature_ord_cat, extraParans={\"category\": \"manufacturer\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136019\n"
     ]
    }
   ],
   "source": [
    "print(len(orders4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_feature_min_max(data,time):\n",
    "    orders_aux = data.query(f'group_backwards > {time}')\n",
    "\n",
    "    newInfo = items[['itemID']].copy()\n",
    "    newInfo['group_backwards'] = time\n",
    "    \n",
    "    #minimun and maximum sales in a pair\n",
    "    #too much zeros, trying for last 4 pairs\n",
    "    newInfo['min_sale'] = orders_aux.groupby(['itemID'])['orderSum'].min()\n",
    "    newInfo['max_sale'] = orders_aux.groupby(['itemID'])['orderSum'].max()\n",
    "\n",
    "\n",
    "    #minimun and maximum sales in a group recent\n",
    "    order_recent = data.query(f'group_backwards > {time} & group_backwards < {time+4}')\n",
    "    newInfo['min_sale_rec'] = order_recent.groupby(['itemID'])['orderSum'].min()\n",
    "    newInfo['max_sale_rec'] = order_recent.groupby(['itemID'])['orderSum'].max()\n",
    "\n",
    "    current_time = data.query(f\"group_backwards == {time}\")\n",
    "    return pd.merge(current_time,newInfo, on=['itemID','group_backwards'], how=\"left\", validate=\"m:1\")\n",
    "\n",
    "orders4 = apply_to_serie(orders4,  add_feature_min_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136019\n"
     ]
    }
   ],
   "source": [
    "print(len(orders4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      group_backwards  itemID  orderSum  brand  manufacturer  customerRating  \\\n",
      "38                 12       1       2.0      0             1            4.38   \n",
      "1345               11       1     313.0      0             1            4.38   \n",
      "8053               10       1      35.0      0             1            4.38   \n",
      "9339                9       1       3.0      0             1            4.38   \n",
      "189                 8       1       1.0      0             1            4.38   \n",
      "9739                7       1       1.0      0             1            4.38   \n",
      "9712                6       1       2.0      0             1            4.38   \n",
      "6784                5       1     299.0      0             1            4.38   \n",
      "1290                4       1       3.0      0             1            4.38   \n",
      "9220                3       1      31.0      0             1            4.38   \n",
      "2790                2       1       0.0      0             1            4.38   \n",
      "189                 1       1       3.0      0             1            4.38   \n",
      "\n",
      "      category1  category2  category3  recommendedRetailPrice  ...  freq_day  \\\n",
      "38            1          1          1                    8.84  ...  0.083333   \n",
      "1345          1          1          1                    8.84  ...  0.076923   \n",
      "8053          1          1          1                    8.84  ...  0.150000   \n",
      "9339          1          1          1                    8.84  ...  0.222222   \n",
      "189           1          1          1                    8.84  ...  0.220588   \n",
      "9739          1          1          1                    8.84  ...  0.195122   \n",
      "9712          1          1          1                    8.84  ...  0.177083   \n",
      "6784          1          1          1                    8.84  ...  0.172727   \n",
      "1290          1          1          1                    8.84  ...  0.193548   \n",
      "9220          1          1          1                    8.84  ...  0.195652   \n",
      "2790          1          1          1                    8.84  ...  0.190789   \n",
      "189           1          1          1                    8.84  ...  0.174699   \n",
      "\n",
      "      freq_week  freq_group  avg_sales_category3  avg_sales_brand  \\\n",
      "38     0.500000    1.000000             6.114098        10.513188   \n",
      "1345   0.250000    0.500000             8.152770        10.596904   \n",
      "8053   0.500000    0.666667             7.714756        10.799694   \n",
      "9339   0.625000    0.750000             7.885080        10.740682   \n",
      "189    0.700000    0.800000             8.225672        13.695298   \n",
      "9739   0.666667    0.833333             8.436369        16.725886   \n",
      "9712   0.642857    0.857143             8.524097        17.209644   \n",
      "6784   0.625000    0.875000             8.469007        17.883720   \n",
      "1290   0.666667    0.888889             9.436521        19.158151   \n",
      "9220   0.700000    0.900000             9.464015        19.744553   \n",
      "2790   0.681818    0.909091             9.320301        20.136937   \n",
      "189    0.625000    0.833333             9.437694        20.710770   \n",
      "\n",
      "      avg_sales_manufacturer  min_sale  max_sale  min_sale_rec  max_sale_rec  \n",
      "38                  0.175000       NaN       NaN           NaN           NaN  \n",
      "1345                0.850000       NaN       NaN           NaN           NaN  \n",
      "8053               20.500000       NaN       NaN           NaN           NaN  \n",
      "9339               21.962500       NaN       NaN           NaN           NaN  \n",
      "189                17.875000       NaN       NaN           NaN           NaN  \n",
      "9739               15.979167       NaN       NaN           NaN           NaN  \n",
      "9712               14.035714       NaN       NaN           NaN           NaN  \n",
      "6784               12.500000       NaN       NaN           NaN           NaN  \n",
      "1290               19.122222       NaN       NaN           NaN           NaN  \n",
      "9220               18.480000       NaN       NaN           NaN           NaN  \n",
      "2790               18.054545       NaN       NaN           NaN           NaN  \n",
      "189                19.433333       NaN       NaN           NaN           NaN  \n",
      "\n",
      "[12 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "ola = orders4[orders4.group_backwards != 13]\n",
    "ola = ola[ola.min_sale.isnull()]\n",
    "print(ola)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add feature first appearance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding first apperance\n",
    "not_zero_order = orders4.query('orderSum != 0')\n",
    "first_appearance = not_zero_order.groupby('itemID',as_index=False)['group_backwards'].max()#remenber backwards\n",
    "first_appearance.columns = ['itemID','first_appearance']\n",
    "\n",
    "orders4 = pd.merge(orders4, first_appearance, on=\"itemID\",how=\"left\", validate=\"m:1\")\n",
    "\n",
    "#putting in relation with the current timestamp\n",
    "#positive means that the itemID was never sold\n",
    "#negative means that the itemID was already sold\n",
    "orders4['first_appearance'] = orders4['group_backwards'] - orders4['first_appearance'] \n",
    "\n",
    "#removing dataleak\n",
    "func = lambda x : np.nan if x >= 0 else x\n",
    "orders4['first_appearance'] = orders4['first_appearance'].apply(func)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'freq_day', 'avg_sales_manufacturer', 'min_sale_rec', 'posM_f_group', 'first_appearance', 'max_sale', 'max_sale_rec', 'posM_l_group', 'freq_group', 'avg_sales_brand', 'freq_week', 'avg_sales_category3', 'min_sale', 'posM_m_group'}\n"
     ]
    }
   ],
   "source": [
    "orders4_columns = set(orders4.columns)\n",
    "print(orders4_columns - orders2_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74609\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "74609"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#freq feature has lots of nan; just checking if there is a error\n",
    "print(len(first_appearance[first_appearance.first_appearance == 1]) * 13 + \\\n",
    "len(first_appearance[first_appearance.first_appearance == 2]) * 12 + \\\n",
    "len(first_appearance[first_appearance.first_appearance == 3]) * 11 + \\\n",
    "len(first_appearance[first_appearance.first_appearance == 4]) * 10 + \\\n",
    "len(first_appearance[first_appearance.first_appearance == 5]) * 9 + \\\n",
    "len(first_appearance[first_appearance.first_appearance == 6]) * 8 + \\\n",
    "len(first_appearance[first_appearance.first_appearance == 7]) * 7 + \\\n",
    "len(first_appearance[first_appearance.first_appearance == 8]) * 6 + \\\n",
    "len(first_appearance[first_appearance.first_appearance == 9]) * 5 + \\\n",
    "len(first_appearance[first_appearance.first_appearance == 10]) * 4 + \\\n",
    "len(first_appearance[first_appearance.first_appearance == 11]) * 3 + \\\n",
    "len(first_appearance[first_appearance.first_appearance == 12]) * 2 + \\\n",
    "len(first_appearance[first_appearance.first_appearance == 13]) * 1 + \\\n",
    "len(all_ids - valid_ids) * 13 )\n",
    "\n",
    "display(orders4.freq_day.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shift\n",
    "### added the feature salesPrice_mean_ from older pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'orderSum_1', 'orderSum_diff_1', 'orderSum_diff_2', 'orderSum_2'}\n"
     ]
    }
   ],
   "source": [
    "orders5 = orders4.copy()\n",
    "\n",
    "for i in range(1, 3):\n",
    "    # Carrying the data of weeks t-1\n",
    "    orders5[f'orderSum_{i}'] = orders5.groupby('itemID')['orderSum'].shift(i)\n",
    "    \n",
    "    # Getting the difference of the orders and promotions between weeks t-1 and t-2...\n",
    "    orders5[f'orderSum_diff_{i}'] = orders5.groupby('itemID')[f'orderSum_{i}'].diff()\n",
    "\n",
    "orders5 =orders5.fillna(np.inf)\n",
    "\n",
    "orders5_columns = set(orders5.columns)\n",
    "print(orders5_columns - orders4_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['group_backwards', 'itemID', 'orderSum', 'brand', 'manufacturer',\n",
      "       'customerRating', 'category1', 'category2', 'category3',\n",
      "       'recommendedRetailPrice', 'posM_f_group', 'posM_m_group',\n",
      "       'posM_l_group', 'freq_day', 'freq_week', 'freq_group',\n",
      "       'avg_sales_category3', 'avg_sales_brand', 'avg_sales_manufacturer',\n",
      "       'min_sale', 'max_sale', 'min_sale_rec', 'max_sale_rec',\n",
      "       'first_appearance', 'orderSum_1', 'orderSum_diff_1', 'orderSum_2',\n",
      "       'orderSum_diff_2'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(orders5.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class custom_obj(object):\n",
    "    def __iter__(self):\n",
    "        return iter('custom')\n",
    "    \n",
    "    def get_final_error(self, error, weight):\n",
    "    \n",
    "        return error\n",
    "\n",
    "    def is_max_optimal(self):\n",
    "        return False\n",
    "\n",
    "    def evaluate(self, approxes, target, weight):\n",
    "        approx = approxes[0]\n",
    "\n",
    "        error_sum = 0.0\n",
    "        weight_sum = 0.0\n",
    "\n",
    "        for prediction,t,w in zip(approx, target, weight):\n",
    "            \n",
    "            weight_sum += w\n",
    "            \n",
    "            error_sum += -1* (prediction - (np.maximum(prediction - t, 0) * 1.6))  * w\n",
    "\n",
    "        return error_sum, weight_sum\n",
    "    def calc_ders_range(self, approxes, targets, weights):\n",
    "        pred = np.array(approxes)\n",
    "        target = np.array(targets)\n",
    "        weight = np.array(weights)\n",
    "        \n",
    "        \n",
    "        der1 = -2 *weight* (pred - (np.maximum(pred - target, 0) * 1.6)) * (1 - (pred > target) * 1.6)\n",
    "        der2 = -2 *weight* (1 - (pred > target) * 1.6) ** 2\n",
    "\n",
    "        return list(zip(der1,der2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['group_backwards', 'itemID', 'orderSum', 'brand', 'manufacturer',\n",
       "       'customerRating', 'category1', 'category2', 'category3',\n",
       "       'recommendedRetailPrice', 'posM_f_group', 'posM_m_group',\n",
       "       'posM_l_group', 'freq_day', 'freq_week', 'freq_group',\n",
       "       'avg_sales_category3', 'avg_sales_brand', 'avg_sales_manufacturer',\n",
       "       'min_sale', 'max_sale', 'min_sale_rec', 'max_sale_rec',\n",
       "       'first_appearance', 'orderSum_1', 'orderSum_diff_1', 'orderSum_2',\n",
       "       'orderSum_diff_2'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "orders6 = orders5.copy()\n",
    "\n",
    "display(orders6.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorical features\n",
    "cat_features = ['brand','manufacturer','category1','category2','category3']\n",
    "\n",
    "#passing to integer\n",
    "for f in cat_features:\n",
    "    orders6[f] = orders6[f].map(lambda x : int(x))\n",
    "    \n",
    "weight =pd.merge(orders6, infos[[\"itemID\", \"simulationPrice\"]], \n",
    "                     on=\"itemID\", validate=\"m:1\")\n",
    "weightt = weight[[\"itemID\",\"group_backwards\",\"simulationPrice\"]]\n",
    "\n",
    "params = {'iterations': 200, \n",
    "         'loss_function':'RMSE',\n",
    "         'use_best_model': True,\n",
    "         'early_stopping_rounds': 30,\n",
    "}\n",
    "\n",
    "params2= {'loss_function':custom_obj(),\n",
    "         'iterations': 200, \n",
    "         'eval_metric':custom_obj(),\n",
    "         'use_best_model': True,\n",
    "         'early_stopping_rounds': 30,\n",
    "         'subsample':1,\n",
    "         }\n",
    "\n",
    "\n",
    "params3= {'loss_function':'RMSE',\n",
    "         'iterations': 200, \n",
    "         'eval_metric':custom_obj(),\n",
    "         'early_stopping_rounds': 30,\n",
    "         'use_best_model': True,\n",
    "         }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADD NOT SOLD ITEMS IF YOUR MODEL DONT PREDICT ALL\n",
    "def get_pred(modelo,test, nome):\n",
    "    \n",
    "    \n",
    "    test_pool = Pool(test.drop(columns=[\"orderSum\"]),\n",
    "                 weight= test['recommendedRetailPrice'],\n",
    "                 cat_features= cat_features\n",
    "    ) \n",
    "        \n",
    "    preds = modelo.predict(test_pool)\n",
    "\n",
    "    #all prediction need to be positive and integer\n",
    "    sold_items = test.copy()\n",
    "    preds = [max(x,0) for x in preds ]\n",
    "    sold_items['demandPrediction'] = preds\n",
    "    sold_items = sold_items[[\"itemID\", \"demandPrediction\"]]\n",
    "\n",
    "    sold_items[\"demandPrediction\"] = sold_items[\"demandPrediction\"].astype(np.uint8)\n",
    "\n",
    "    #to kagle csv\n",
    "    return sold_items.sort_values(['itemID'],  ignore_index=True)\n",
    "    #final.to_csv(f\"pred/{nome}.csv\", index=False, sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(data, not_drop_columns):\n",
    "    \n",
    "    new_features = list(orders5_columns - orders2_columns)\n",
    "    for colum in not_drop_columns :\n",
    "        new_features.remove(colum)\n",
    "    \n",
    "    data = data.drop(columns=new_features)\n",
    "    \n",
    "    test = data.query('group_backwards == 1')\n",
    "    val = data.query('group_backwards == 2')\n",
    "    train = data.query('group_backwards >= 3')\n",
    "\n",
    "\n",
    "    train_pool = Pool(\n",
    "        data= train.drop(columns=[\"orderSum\"]), \n",
    "        label= train['orderSum'], \n",
    "        weight= weightt.query('group_backwards >= 3') ,\n",
    "        cat_features= cat_features\n",
    "    )\n",
    "    \n",
    "    validation_pool = Pool(\n",
    "        data= val.drop(columns=[\"orderSum\"]), \n",
    "        label= val['orderSum'], \n",
    "        weight= weightt.query('group_backwards == 2'),\n",
    "        cat_features= cat_features\n",
    "    )\n",
    "    \n",
    "    \n",
    "    \n",
    "    model=CatBoostRegressor(**params) \n",
    "    model.fit(train_pool,eval_set=validation_pool , verbose=False)\n",
    "    \n",
    "    #model2=CatBoostRegressor(**params2) \n",
    "    #model2.fit(train_pool,eval_set=validation_pool , verbose=False)\n",
    "    \n",
    "    model3=CatBoostRegressor(**params3) \n",
    "    model3.fit(train_pool,eval_set=validation_pool , verbose=False)\n",
    "    \n",
    "    \n",
    "    target = test['orderSum'].values\n",
    "    predct1 =get_pred(model,test, 'cat_pos1')['demandPrediction'].values\n",
    "    predct3 =get_pred(model3,test, 'cat_pos1')['demandPrediction'].values\n",
    "    \n",
    "    score1 = baseline_score(predct1, target, infos['simulationPrice'])\n",
    "    score3 = baseline_score(predct3, target, infos['simulationPrice'])\n",
    "    \n",
    "    return score1, score3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'freq_day', 'avg_sales_manufacturer', 'min_sale_rec', 'posM_f_group', 'first_appearance', 'max_sale', 'max_sale_rec', 'orderSum_diff_1', 'posM_l_group', 'freq_group', 'avg_sales_brand', 'orderSum_1', 'avg_sales_category3', 'freq_week', 'min_sale', 'orderSum_diff_2', 'posM_m_group', 'orderSum_2'}\n"
     ]
    }
   ],
   "source": [
    "print(orders5_columns - orders2_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-2558694.946000001, -2363689.0980000007)\n",
      "(-2850372.1780000012, -6256618.284000002)\n",
      "(-2883996.318000001, -5860836.592000001)\n"
     ]
    }
   ],
   "source": [
    "print(get_result(orders6,[]))#all new features\n",
    "\n",
    "print(get_result(orders6, list(orders5_columns - orders2_columns)))#no new features\n",
    "\n",
    "print(get_result(orders6, ['posM_f_group', 'posM_m_group','posM_l_group']))#position in month\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-2485403.892000001, -4908763.1000000015)\n",
      "(-2685173.580000001, -5860836.592000001)\n",
      "(-2472589.696000001, -5860836.592000001)\n",
      "(-2589885.846000001, -6097441.118000001)\n",
      "(-2562921.090000001, -1906474.5280000004)\n"
     ]
    }
   ],
   "source": [
    "print(get_result(orders6, ['first_appearance']))#'first_appearance'\n",
    "\n",
    "print(get_result(orders6, ['freq_day','freq_group','freq_week']))#frequency\n",
    "\n",
    "print(get_result(orders6, ['avg_sales_brand','avg_sales_manufacturer','avg_sales_category3']))#avg sales\n",
    "\n",
    "print(get_result(orders6, ['min_sale','max_sale','max_sale_rec','min_sale_rec']))#min max\n",
    "\n",
    "print(get_result(orders6, ['max_sale_rec','min_sale_rec']))#min max recent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_result(orders6, ['salesPrice_mean_1','salesPrice_mean_diff_1','salesPrice_mean_2','salesPrice_mean_diff_2']))\n",
    "\n",
    "print(get_result(orders6, ['promotion_mean_1','promotion_mean_2','promotion_mean_diff_1','promotion_mean_diff_2']))\n",
    "\n",
    "print(get_result(orders6, ['orderSum_1','orderSum_2','orderSum_diff_1','orderSum_diff_2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_result(orders6, ['salesPrice_mean_1','salesPrice_mean_diff_1','salesPrice_mean_2','salesPrice_mean_diff_2',\n",
    "                          'first_appearance','min_sale','max_sale','max_sale_rec','min_sale_rec',\n",
    "                          'orderSum_1','orderSum_2','orderSum_diff_1','orderSum_diff_2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
